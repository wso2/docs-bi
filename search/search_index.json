{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"WSO2 Integrator: BI is a low-code integration solution built on Ballerina, enabling fast and efficient integration development with minimal coding. The WSO2 Integrator: BI extension for Visual Studio Code (VS Code) provides a familiar, AI-assisted environment that streamlines tasks and enhances accuracy, accelerating digital transformation efforts.          Get Started \ud83d\ude80 <ul> <li> Quick Start Guide </li> <li> Install WSO2 Integrator: BI </li> <li> Develop Integration as API </li> <li> Develop Automation </li> <li> Develop File Integration </li> <li> Develop Event Integration </li> <li> Develop AI Agent </li> </ul> Developer Guides \ud83d\udee0\ufe0f  <ul> <li> Design the Integrations </li> <li> Data Mapping </li> <li> Testing </li> <li> Debugging &amp; Troubleshooting </li> <li> Protocols and Connectors </li> <li> Integration Tools </li> <li> Migration Tools </li> <li> Other Tools </li> </ul> AI \ud83e\udd16 <ul> <li> AI Agents and other Gen AI Integrations </li> <li> AI for Integration </li> </ul> Integration Guides \ud83d\udcda <ul> <li> AI Agents and other Gen AI Integrations </li> <li> Integration as API </li> <li> File Integration </li> </ul> Deploy \u2699\ufe0f <ul> <li> Overview </li> <li> Deploy to Devant </li> <li> Containerized Deployment </li> <li> VM-based Deployment </li> <li> Managing Configurations </li> <li> Capacity Planning </li> </ul> Observability and Monitoring \ud83d\udcc8  <ul> <li> Overview </li> <li> Monitoring with WSO2 Integrator: ICP </li> <li> Observability with Devant </li> <li> Supported Observability Tools and Platforms </li> </ul> References \ud83d\udcd6 <ul> <li> Enterprise Integration Patterns </li> <li> System requirements </li> <li> AI Usage and Data Handling Guidelines </li> </ul> Community &amp; Support \u2753 <ul> <li> GitHub </li> <li> Discord </li> <li> Enterprise Support </li> <li> Release Note </li> </ul>"},{"location":"page-not-found/","title":"Page not found","text":"<p>Try one of the navigation links above or use the search engine in the top right corner.</p>"},{"location":"wso2-integrator-bi-release-notes/","title":"About major Release","text":""},{"location":"wso2-integrator-bi-release-notes/#whats-new-in-wso2-integrator-bi-130-release","title":"What's new in WSO2 Integrator: BI 1.3.0 release?","text":"<p>WSO2 Integrator: BI 1.3.0 introduces the following features and enhancements:</p> New Welcome Page<p>A completely redesigned welcome page now supports advanced project creation options, including organization name and version information.</p> Migration Tooling Support<p>Comprehensive tooling for importing Mule and Tibco projects, enabling seamless migration to WSO2 Integrator: BI integrations. This reduces migration complexity and accelerates the transition from Mule and Tibco-based solutions.</p> AI Integration<p>Advanced AI capabilities, including document generation, enhanced knowledge-base management, smarter agent creation, and improved AI suggestions. New chunking tools (Chunker, Dataloader) and reusable model providers streamline agent development and knowledge workflows. Enhanced RAG (Retrieval-Augmented Generation) and improved template management are also included.</p> New Expression Editor<p>The expression editor has been redesigned to open below the input box, providing intuitive support for creating values, using variables, calling functions, and referencing configurable values.</p> Improved Data Mapper<p>Performance improvements for large, deeply nested records, a more intuitive design, and a new expression editor simplify data transformations. The Data Mapper now supports enums/unions, constants, nested arrays, optional fields, and transformation function mappings, making complex scenarios more manageable.</p> Connector Page<p>Introduced support for importing private connectors from a user's private organization in Ballerina Central. Local Connectors are now called Custom Connectors, with a new tab-based UI and improved project switching for a more seamless and efficient workflow.</p> GraphQL Upgrades<p>Expanded GraphQL support with advanced configurations at both service and field levels, including context and metadata handling. These upgrades enable more sophisticated integrations and greater control over data flow.</p> Type Diagram Optimization<p>Optimized views for diagrams with high node counts, including node deletion and support for read-only types via TypeEditor, providing better type management.</p> Improved User Experience<p>Comprehensive UX improvements, including collapsible node palette groupings, a cleaner UI, better connector flows, and improved record rendering.</p>"},{"location":"wso2-integrator-bi-release-notes/#fixed-issues","title":"Fixed issues","text":"<ul> <li>WSO2 Integrator: BI Issues</li> </ul>"},{"location":"wso2-integrator-bi-release-notes/#whats-new-in-wso2-integrator-bi-120-release","title":"What's new in WSO2 Integrator: BI 1.2.0 release?","text":"Enhanced Inline Data Mapper<p>The Inline Data Mapper was redesigned for a better user experience, featuring AI-driven mapping suggestions and a new sub-mapping form for complex data transformations.</p> Data Mapper Improvements<p>Improved search, label positioning, and performance. The Data Mapper now refreshes automatically when code changes. Multiple bugs in mapping generation and type resolution were fixed, resulting in a more robust transformation experience.</p> Advanced AI Capabilities<p>Added low-code support for advanced RAG (Retrieval-Augmented Generation) workflows. Integrated Anthropic's Claude Sonnet v4 for code generation. Introduced a Vector Knowledge Base node for RAG workflows and new configuration options for default AI model providers in the Flow Diagram.</p> AI Copilot<p>Upgraded the AI Copilot to use ballerina/ai packages, streamlining flows for greater user-friendliness and agent capability. Resolved re-rendering bugs and authentication flow issues for a smoother AI experience.</p> Editor &amp; IDE Improvements<p>Added a new VSCode setting to manage Sequence Diagram visibility and an option to include the current organization in search results. Improved state management, addressed UI freezing, and enhanced project handling in multi-root workspaces for a more stable development environment.</p>"},{"location":"wso2-integrator-bi-release-notes/#fixed-issues_1","title":"Fixed issues","text":"<ul> <li>WSO2 Integrator: BI Issues</li> </ul>"},{"location":"wso2-integrator-bi-release-notes/#whats-new-in-wso2-integrator-bi-110-release","title":"What's new in WSO2 Integrator: BI 1.1.0 release?","text":"Configurable Editor Redesign<p>Complete redesign of the configuration editor with a modern UI/UX and improved functionality, making configuration management more intuitive and efficient.</p> Type Editor &amp; Diagram Upgrades<p>The type editor was revamped for better feature discoverability and user experience. Type Diagram and GraphQL designer now offer improved visual presentation and clarity.</p> Data Mapper Enhancements<p>Fixed issues when working with complex data types from imported modules. Improved visualization of array types and nested data structures for more accurate data mapping.</p> Bundled Language Server<p>The Ballerina Language Server is now bundled with the extension, eliminating separate installation requirements and significantly improving startup performance.</p> AI Copilot<p>Enhanced AI file upload support with additional file types for improved analysis. Signature Help now displays documentation for a better developer experience during code completion. Enhanced service resource creation with a comprehensive validation system.</p> HTTP Response UX Improvements<p>Introduced a new user experience for creating HTTP responses, including support for selecting status code response types and defining custom headers.</p> IDE &amp; Extension Stability<p>Refactored artifacts management and navigation. Resolved extension startup and activation issues for reliable performance. Improved state management and project handling in multi-root workspaces.</p>"},{"location":"wso2-integrator-bi-release-notes/#fixed-issues_2","title":"Fixed issues","text":"<ul> <li>WSO2 Integrator: BI Issues</li> </ul>"},{"location":"deploy/deploy-to-devant/","title":"Deploy to Devant","text":"<p>Devant is a powerful IPaaS with first-class AI support. Incorporate AI agents into the integrations you build in low-code and pro-code, and move away from siloed systems to intelligent digital experiences with Devant by WSO2\u2014the AI iPaaS that your AI Agents can call 'home'. BI provides a seamless integration experience with Devant. You can deploy your integrations to Devant with just a few clicks.</p>"},{"location":"deploy/deploy-to-devant/#step-1-login-and-create-a-project-in-devant","title":"Step 1: Login and Create a project in Devant","text":"<ul> <li> <p>Navigate to the Visualizer view by clicking on the BI icon on the sidebar.</p> </li> <li> <p>On the right hand side, under <code>Deployment Options</code> select <code>Deploy to Devant</code>.</p> </li> </ul> <p></p> <ul> <li>Login to Devant organization and create a project</li> </ul> <p> </p>"},{"location":"deploy/deploy-to-devant/#step-2-initialize-the-source-as-a-git-repository-and-push-the-changes","title":"Step 2: Initialize the source as a Git repository and push the changes","text":"<p>Go to the <code>Source Control</code> view and follow the steps to create a Git repository and commit your changes.</p> <p> </p>"},{"location":"deploy/deploy-to-devant/#step-3-create-the-integration-on-devant","title":"Step 3: Create the integration on Devant","text":"<p>Once the source is pushed to GitHub, you can configure the build details and create the integration in Devant.</p> <p></p>"},{"location":"deploy/deploy-to-devant/#step-4-view-the-integration-on-devant","title":"Step 4: View the integration on Devant","text":"<p>Once the integration is deployed to Devant, the <code>Deployment Options</code> panel displays a <code>View in Devant</code> link. This opens the Devant overview page, where you can view logs, update configurations, test the integration, promote it to higher environments, and perform many other management tasks.</p> <p></p>"},{"location":"deploy/managing-configurations/","title":"Managing Configurations","text":"<p>Configurability in WSO2 Integrator: BI allows users to modify integration behavior using external inputs without changing the source code. It is powered by Ballerina\u2019s built-in support for configurable variables, enabling runtime configuration of module-level values.</p> <p>Consider the following step-by-step guide to configuring a Ballerina package that contains an HTTP service.</p>"},{"location":"deploy/managing-configurations/#step-1-create-an-http-service-using-the-default-configurations","title":"Step 1: Create an HTTP service using the default configurations","text":""},{"location":"deploy/managing-configurations/#step-2-create-required-types-and-configurable-variables","title":"Step 2: Create required types and configurable variables","text":"<ul> <li> <p>Create a type <code>Greeting</code> that holds the greeting information.</p> </li> <li> <p>Create a configurable variable to hold the greeting to be sent when invoking the API endpoint. This can be done by adding a <code>Configuration</code> in <code>WSO2 Integrator: BI</code> design view.</p> </li> </ul> <p></p>"},{"location":"deploy/managing-configurations/#step-3-run-the-integration","title":"Step 3: Run the integration","text":"<ul> <li>You'll be prompted to create a <code>Config.toml</code>. This file can contain the greeting information. This allows configuring the values externally during the runtime.</li> </ul> <p>This concept of configurables can be used to hold environment specific variables that needs to be updated at the time of execution.</p>"},{"location":"deploy/overview/","title":"Overview","text":""},{"location":"deploy/overview/#deployment-options","title":"Deployment Options","text":"<p>WSO2 Integrator: BI supports flexible deployment models that can be grouped into two main categories:</p> <ol> <li> <p>Environment-Based Deployment</p> <ul> <li> <p>Local Deployment:  Ideal for development and testing, this mode allows you to run integrations directly on your local machine using the built-in runtime. It offers quick feedback loops, easier debugging, and is often used in early stages of integration development.</p> </li> <li> <p>Cloud Deployment:  Designed for scalable, production-grade environments, this option allows BI built integrations to be deployed in private or public cloud infrastructures. It integrates seamlessly with cloud-native tools for monitoring, auto-scaling, load balancing, and resilience.</p> </li> </ul> </li> <li> <p>Infrastructure-Based Deployment</p> <ul> <li> <p>VM-Based Deployment:  Suited for on-premises or tightly controlled environments, BI built integrations can be deployed on virtual machines using traditional infrastructure provisioning. This model provides full control over the runtime environment but may require more manual effort in scaling and management.</p> </li> <li> <p>Containerized Deployment:  Best for modern, automated environments, BI built integrations run in Docker containers or on Kubernetes clusters. This mode enables improved portability, orchestration, and tight integration with CI/CD pipelines for continuous delivery and infrastructure automation.</p> </li> </ul> </li> </ol> Note<p>Use local and VM-based deployments for early-stage development, PoCs, or controlled environments. Move to containerized or cloud deployments for scalability, high availability, and production readiness. Each option can be adapted to meet your performance, availability, and operational needs.</p>"},{"location":"deploy/overview/#deployment-patterns","title":"Deployment Patterns","text":"<p>To address different architectural and operational requirements, WSO2 Integrator: BI supports both centralized and decentralized deployment patterns:</p> <ul> <li> <p>Centralized Deployment: Consolidates multiple BI artifacts into a single deployable unit. This pattern simplifies deployment, reduces resource consumption, and is ideal for tightly coupled integration solutions.</p> </li> <li> <p>Decentralized Deployment: Each BI component is packaged and deployed independently. This allows teams to iterate and release components separately, improving agility and scalability in microservice-oriented environments.</p> </li> </ul> <p>You can choose a pattern based on your team's workflows, size of the integration solution, and deployment control requirements.</p>"},{"location":"deploy/overview/#hot-deployment-strategies","title":"Hot Deployment Strategies","text":"<p>Hot deployments refer to the process of updating or redeploying software components with zero downtime and maintaining high availability in production systems.</p> <p>Here the hot deployment strategy works by orchestrating multiple service instances through a NGINX load balancer, allowing you to update and restart services without interrupting user traffic. The load balancer automatically routes requests away from instances undergoing updates and back to them once they are healthy again.</p>"},{"location":"deploy/overview/#common-load-balancing-strategies","title":"Common Load Balancing Strategies:","text":""},{"location":"deploy/overview/#1-active-active","title":"1. Active-Active","text":"<p>All instances actively serve traffic simultaneously. NGINX uses passive health monitoring through <code>max_fails</code> and <code>fail_timeout</code> directives. When an instance fails to respond successfully <code>max_fails</code> times within the <code>fail_timeout</code> window, NGINX temporarily removes it from the load balancing pool.</p> <p>This passive approach relies on actual client requests to detect server failures, meaning the load balancer only discovers problems when real traffic encounters them. Passive monitoring is reactive and depends on the natural flow of requests to identify unhealthy servers. The default load balancing method is round-robin, distributing requests evenly across all available servers, though this can be changed to other algorithms like least connections or IP hash based on application requirements.</p> <p>Failed requests are automatically retried on other available instances, as a fault tolerance mechanism.</p>"},{"location":"deploy/overview/#nginx-configuration","title":"NGINX configuration","text":"<pre><code>events {}\n\nhttp {\nupstream backend {\nserver 127.0.0.1 max_fails=3 fail_timeout=30s;\nserver 127.0.0.2 max_fails=3 fail_timeout=30s;\n}\n\nserver {\nlocation / {\nproxy_pass http://backend;\n}\n}\n}\n</code></pre>"},{"location":"deploy/overview/#2-active-active-with-health-checks","title":"2. Active-Active (With health checks)","text":"<p>This configuration requires NGINX Plus, which supports active health checks. NGINX proactively polls a specified health endpoint (e.g., /health) on each instance to determine availability.</p> <p>Unlike passive health checks that only detect failures when client requests fail, active health checks continuously monitor server health in the background, providing faster failure detection and more reliable service availability. This proactive approach allows NGINX to remove unhealthy servers from the pool before they impact user requests, significantly reducing the mean time to detection and improving overall system reliability.</p>"},{"location":"deploy/overview/#nginx-configuration_1","title":"NGINX configuration","text":"<pre><code>events {}\n\nhttp {\nupstream backend {\nserver 127.0.0.1 max_fails=3 fail_timeout=30s;\nserver 127.0.0.2 max_fails=3 fail_timeout=30s;\n}\n\nserver {\nlisten 80;\nlocation / {\nproxy_pass http://backend;\nhealth_check uri=/health interval=5s;\n}\n}\n}\n</code></pre>"},{"location":"deploy/overview/#3-active-passive","title":"3. Active-Passive","text":"<p>Primary server handles all traffic, backup only activates on failure. The backup server remains idle until the primary fails, ensuring you always have a failover target.</p> <p>When the primary server fails to send a response, the load balancer immediately redirects the request to backup server. This failover process is automatic and transparent to the client, occurring within milliseconds of detecting the failure. The backup server must be pre-configured with identical application code and dependencies.</p> <p>Nginx tracks failed requests against <code>max_fails</code> threshold and after reaching threshold, server is marked as unavailable for <code>fail_timeout</code> duration. And then keep sending request to one of the backup servers. Once a server is marked as unavailable, Nginx will not attempt to send requests to it until the <code>fail_timeout</code> period expires, ensuring that the backup server handles all incoming traffic consistently. If multiple backup servers are configured, Nginx will select the first available backup server in the order they are defined, maintaining the single-active-server principle of active-passive architecture.</p> <p>After <code>fail_timeout</code> period, Nginx attempts to route traffic back to primary server. If successful, primary server resumes active role and backup servers return to standby mode. This recovery process is gradual and intelligent - Nginx sends a small number of test requests to the recovered primary server before fully transitioning traffic back. If the primary server successfully handles these test requests without errors, it regains its active status and the backup server automatically transitions back to standby mode. However, if the primary server continues to fail during the recovery attempt, it remains marked as unavailable for another <code>fail_timeout</code> period, and the backup server continues to handle all traffic until the next recovery cycle.</p>"},{"location":"deploy/overview/#nginx-configuration_2","title":"NGINX configuration","text":"<pre><code>events {}\n\nhttp {\nupstream backend {\nserver 127.0.0.1 max_fails=3 fail_timeout=30s;\nserver 127.0.0.2 max_fails=3 fail_timeout=30s;\n}\n\nserver {\nlisten 80;\n\nlocation / {\nproxy_pass http://backend;\n}\n}\n}\n</code></pre> Best Practice<p>Ensure identical configurations across all instances and automate deployments for consistency.</p> <p>You can visit the following sections to get an understanding on the possible deployment and configuration options.</p> <ul> <li>Deploy to Devant</li> <li>Containerized Deployment</li> <li>VM-based Deployment</li> <li>Managing Configurations</li> </ul>"},{"location":"deploy/capacity-planning/overview/","title":"Capacity Planning for WSO2 Integrator: BI","text":"<p>This section provides an overview of the performance characteristics and capacity planning considerations for WSO2 Integrator: BI when deployed in a cloud environment. The performance reports linked below detail the results of various integration scenarios under specific load conditions.</p> <p>The tests were conducted on the following AWS EC2 instance configuration:</p> Description Value EC2 Instance type c5.large CPUs 2 Thread(s) per core 2 Core(s) per socket 1 Socket(s) 1 Processor model name Intel(R) Xeon(R) Platinum 8124M CPU @ 3.00GHz System Memory 4 GiB Storage 8G nvme0n1 Operating System Ubuntu 18.04.6 LTS Kernel version 5.4.0-1094-aws"},{"location":"deploy/capacity-planning/overview/#performance-reports","title":"Performance reports","text":"<p>Explore the detailed performance reports for various integration types:</p> <ul> <li>Performance report for REST Services (HTTP and HTTPS) </li> </ul>"},{"location":"deploy/capacity-planning/performance-report-for-rest-services/","title":"Performance report for REST services (HTTP and HTTPS)","text":""},{"location":"deploy/capacity-planning/performance-report-for-rest-services/#overview","title":"Overview","text":"Test Scenarios Description Passthrough HTTP service (h1c -&gt; h1c) An HTTP Service, which forwards all requests to an HTTP back-end service. Passthrough HTTPS service (h1 -&gt; h1) An HTTPS Service, which forwards all requests to an HTTPS back-end service. JSON to XML transformation HTTP service An HTTP Service, which transforms JSON requests to XML and then forwards all requests to an HTTP back-end service. JSON to XML transformation HTTPS service An HTTPS Service, which transforms JSON requests to XML and then forwards all requests to an HTTPS back-end service. HTTP/2 client and server downgrade service (h2 -&gt; h2) An HTTP/2(with TLS) server accepts requests from an HTTP/1.1(with TLS) client and the HTTP/2(with TLS) client sends requests to an HTTP/1.1(with TLS) back-end service. Both the upstream and downstream connections are downgraded to HTTP/1.1(with TLS). <p>Our test client is Apache JMeter. We test each scenario for a fixed duration of time. We split the test results into warm-up and measurement parts and use the measurement part to compute the performance metrics.</p> <p>A majority of test scenarios use a Netty based back-end service, which echoes back any request posted to it after a specified period of time.</p> <p>Note</p> <p>The code and instructions for running these tests are provided here.</p>"},{"location":"deploy/capacity-planning/performance-report-for-rest-services/#performance-metrics","title":"Performance metrics","text":"<p>We run the performance tests under different numbers of concurrent users, message sizes (payloads), and back-end service delays.</p> <p>The main performance metrics:</p> <ol> <li>Throughput: The number of requests that the Ballerina service processes during a specific time interval (e.g., per second).</li> <li>Response Time: The end-to-end latency for an operation of invoking a Ballerina service. The complete distribution of response times was recorded.</li> </ol> <p>In addition to the above metrics, we measure the load average and several memory-related metrics.</p>"},{"location":"deploy/capacity-planning/performance-report-for-rest-services/#test-parameters","title":"Test parameters","text":"<p>The following are the test parameters.</p> Test Parameter Description Values Scenario Name The name of the test scenario. Refer to the above table. Heap Size The amount of memory allocated to the application 2G Concurrent Users The number of users accessing the application at the same time. 100, 200, 500, 1000 Message Size (Bytes) The request payload size in Bytes. 500, 1000, 10000 Back-end Delay (ms) The delay added by the back-end service. 0 <p>The duration of each test is 1200 seconds. The warm-up period is 600 seconds. The measurement results are collected after the warm-up period.</p> <p>A c5.large Amazon EC2 instance was used to install Ballerina.</p> <p>The following are the measurements collected from each performance test conducted for a given combination of test parameters.</p> Measurement Description Error % Percentage of requests with errors Average Response Time (ms) The average response time of a set of results Standard Deviation of Response Time (ms) The \u201cStandard Deviation\u201d of the response time. 99th Percentile of Response Time (ms) 99% of the requests took no more than this time. The remaining samples took at least as long as this Throughput (Requests/sec) The throughput measured in requests per second. Average Memory Footprint After Full GC (M) The average memory consumed by the application after a full garbage collection event."},{"location":"deploy/capacity-planning/performance-report-for-rest-services/#test-results","title":"Test results","text":"<p>The following is the summary of performance test results collected for the measurement period.</p> Scenario Name Concurrent Users Message Size (Bytes) Back-end Service Delay (ms) Error % Throughput (Requests/sec) Average Response Time (ms) Standard Deviation of Response Time (ms) 99th Percentile of Response Time (ms) Passthrough HTTP service (h1c -&gt; h1c) 100 500 0 0 8935.69 11.13 4.78 26 Passthrough HTTP service (h1c -&gt; h1c) 100 1000 0 0 9341.58 10.65 4.97 26 Passthrough HTTP service (h1c -&gt; h1c) 100 10000 0 0 6358.34 15.66 6.52 36 Passthrough HTTP service (h1c -&gt; h1c) 200 500 0 0 10719.1 18.59 6.93 37 Passthrough HTTP service (h1c -&gt; h1c) 200 1000 0 0 9108.9 21.89 7.25 43 Passthrough HTTP service (h1c -&gt; h1c) 200 10000 0 0.01 6348.51 31.42 134.77 78 Passthrough HTTP service (h1c -&gt; h1c) 500 500 0 0 8706.5 57.35 15.55 96 Passthrough HTTP service (h1c -&gt; h1c) 500 1000 0 0 8946.24 55.81 14.4 92 Passthrough HTTP service (h1c -&gt; h1c) 500 10000 0 0.01 6393.06 78.11 25.5 145 Passthrough HTTP service (h1c -&gt; h1c) 1000 500 0 0 8665.7 115.29 24.02 172 Passthrough HTTP service (h1c -&gt; h1c) 1000 1000 0 0 8944.47 111.69 19.91 165 Passthrough HTTP service (h1c -&gt; h1c) 1000 10000 0 0.01 6296.27 158.68 41.14 263 JSON to XML transformation HTTP service 100 500 0 0 1590.82 62.8 252.15 138 JSON to XML transformation HTTP service 100 1000 0 0 998.79 100.05 379 188 JSON to XML transformation HTTP service 100 10000 0 0 84.2 1186.62 521.64 1903 JSON to XML transformation HTTP service 200 500 0 0 1498.83 133.35 180.62 295 JSON to XML transformation HTTP service 200 1000 0 0.02 1001.07 199.77 693.66 397 JSON to XML transformation HTTP service 200 10000 0 0 70.63 2823.67 1185.64 4479 JSON to XML transformation HTTP service 500 500 0 0 1478.51 338.23 237.25 747 JSON to XML transformation HTTP service 500 1000 0 0 905.56 552.17 340.06 1175 JSON to XML transformation HTTP service 500 10000 0 99.16 15.89 29911.92 1485.55 31103 JSON to XML transformation HTTP service 1000 500 0 0 1445.42 691.67 373.82 1551 JSON to XML transformation HTTP service 1000 1000 0 0 885.2 1128.63 1467.77 2239 JSON to XML transformation HTTP service 1000 10000 0 0 59.63 16479.55 5309.9 24959 Passthrough HTTPS service (h1 -&gt; h1) 100 500 0 0 8282.45 12.02 5.67 28 Passthrough HTTPS service (h1 -&gt; h1) 100 1000 0 0 7676.52 12.97 6.39 31 Passthrough HTTPS service (h1 -&gt; h1) 100 10000 0 0 4405.6 22.63 38.69 70 Passthrough HTTPS service (h1 -&gt; h1) 200 500 0 0 8298.14 24.04 9.49 53 Passthrough HTTPS service (h1 -&gt; h1) 200 1000 0 0 8185.02 24.37 9.6 53 Passthrough HTTPS service (h1 -&gt; h1) 200 10000 0 0.01 4314.93 46.26 12.9 97 Passthrough HTTPS service (h1 -&gt; h1) 500 500 0 0 7631.44 65.43 18.17 111 Passthrough HTTPS service (h1 -&gt; h1) 500 1000 0 0 7322.7 68.2 18.11 114 Passthrough HTTPS service (h1 -&gt; h1) 500 10000 0 0.01 4187 119.3 29.12 226 Passthrough HTTPS service (h1 -&gt; h1) 1000 500 0 0 7257.55 137.64 30.77 207 Passthrough HTTPS service (h1 -&gt; h1) 1000 1000 0 0 7213.92 138.47 30.72 209 Passthrough HTTPS service (h1 -&gt; h1) 1000 10000 0 0.01 4076.18 245.27 59.83 439 JSON to XML transformation HTTPS service 100 500 0 0 1507.24 66.28 337.13 158 JSON to XML transformation HTTPS service 100 1000 0 0 967.15 103.32 311.01 206 JSON to XML transformation HTTPS service 100 10000 0 2 83.65 1181 4156.47 30079 JSON to XML transformation HTTPS service 200 500 0 0 1380.33 144.81 192.98 349 JSON to XML transformation HTTPS service 200 1000 0 0.04 897.78 222.73 1027.82 501 JSON to XML transformation HTTPS service 200 10000 0 2.27 76.57 2602.91 4886.23 30079 JSON to XML transformation HTTPS service 500 500 0 0 1505.97 332.02 446.28 1663 JSON to XML transformation HTTPS service 500 1000 0 0 881.78 566.83 1394.24 1159 JSON to XML transformation HTTPS service 500 10000 0 100 21.33 22693.11 11309.03 42495 JSON to XML transformation HTTPS service 1000 500 0 0 1424.83 701.47 591.2 3487 JSON to XML transformation HTTPS service 1000 1000 0 0 806.11 1239.02 1167.47 3215 JSON to XML transformation HTTPS service 1000 10000 0 0 61.55 15956.62 4774.51 24319 HTTP/2 client and server downgrade service (h2 -&gt; h2) 100 500 0 0 8289.32 12.01 5.58 28 HTTP/2 client and server downgrade service (h2 -&gt; h2) 100 1000 0 0 7675.18 12.97 6.07 30 HTTP/2 client and server downgrade service (h2 -&gt; h2) 100 10000 0 0 4327.11 23.03 6.94 49 HTTP/2 client and server downgrade service (h2 -&gt; h2) 200 500 0 0 7626.89 26.16 8.86 52 HTTP/2 client and server downgrade service (h2 -&gt; h2) 200 1000 0 0 8012.4 24.89 9.59 54 HTTP/2 client and server downgrade service (h2 -&gt; h2) 200 10000 0 0.04 4206.28 47.46 13.18 100 HTTP/2 client and server downgrade service (h2 -&gt; h2) 500 500 0 0 7562.06 66.03 18.66 113 HTTP/2 client and server downgrade service (h2 -&gt; h2) 500 1000 0 0 7174.09 69.61 17.7 114 HTTP/2 client and server downgrade service (h2 -&gt; h2) 500 10000 0 0 4113.17 121.44 33.72 253 HTTP/2 client and server downgrade service (h2 -&gt; h2) 1000 500 0 0 7462.01 133.86 36.73 218 HTTP/2 client and server downgrade service (h2 -&gt; h2) 1000 1000 0 0 7202.02 138.7 35.71 221 HTTP/2 client and server downgrade service (h2 -&gt; h2) 1000 10000 0 0.01 4017.91 248.82 61.31 447 <p>Note</p> <p>Ballerina Swan Lake 2201.12.4 was used for testing with default configurations. Your results may vary depending on the Ballerina version and configuration used.</p>"},{"location":"deploy/containerized-deployment/deploy-as-docker-image/","title":"Deploy as a Docker Image","text":"<p>This guide explains how to deploy an integration as a Docker image.</p> <ul> <li>Navigate to the Visualizer view by clicking on the BI icon on the sidebar.</li> <li>Click on the Deploy with Docker under the Deployment Options section in the right panel.</li> <li> <p>Click Create Docker Image button.      </p> </li> <li> <p>The integration will be built as a Docker image and the image will be available in the local Docker registry.</p> </li> </ul>"},{"location":"deploy/containerized-deployment/deploy-on-kubernetes/","title":"Deploy on Kubernetes","text":"<p>This guide explains how to deploy an integration in a Kubernetes cluster.</p>"},{"location":"deploy/containerized-deployment/deploy-on-kubernetes/#step-1-enable-kubernetes-artifact-build","title":"Step 1: Enable Kubernetes artifact build","text":"<pre><code>- Navigate to the Visualizer view by clicking on the BI icon on the sidebar.\n- Go to the `Explorer` view and add the following to `Ballerina.toml` to enable building artifacts for Kubernetes.\n\n```toml\n[build-options]\ncloud = \"k8s\"\n```\n\n- Specify the container image details by creating a `Cloud.toml` file.\n\n```\n[container.image]\nrepository=\"wso2inc\" # Docker hub repository name.\nname=\"greeter\" # container name\ntag=\"latest\"\n```\n\n&lt;a href=\"https://wso2.github.io/docs-bi/assets/img/deploy/update-k8s-cnfigs.gif\"&gt;&lt;img src=\"https://wso2.github.io/docs-bi/assets/img/deploy/update-k8s-cnfigs.gif\" alt=\"Update k8s build configurations\" width=\"70%\"&gt;&lt;/a&gt;</code></pre>"},{"location":"deploy/containerized-deployment/deploy-on-kubernetes/#step-2-build-the-artifacts","title":"Step 2: Build the artifacts","text":"<pre><code>Go to the terminal in VSCode and build the executable using `bal build`. You'll get an output as follows.\n\n```\n    Compiling source\n            example/greeter:0.1.0\n\n    Generating executable\n\n    Generating artifacts\n\n            @kubernetes:Service\n            @kubernetes:ConfigMap\n            @kubernetes:Secret\n            @kubernetes:Deployment\n            @kubernetes:HPA\n\n    Building the docker image\n\n    Execute the below command to deploy the Kubernetes artifacts: \n            kubectl apply -f /home/example/greeter/target/kubernetes/greeter\n```\n\n&lt;a href=\"https://wso2.github.io/docs-bi/assets/img/deploy/build-k8s-artifacts.gif\"&gt;&lt;img src=\"https://wso2.github.io/docs-bi/assets/img/deploy/build-k8s-artifacts.gif\" alt=\"Build k8s artifacts\" width=\"70%\"&gt;&lt;/a&gt;\n\n???+ Info\n    This generates the cloud artifacts inside the `target/` directory.</code></pre>"},{"location":"deploy/containerized-deployment/deploy-on-kubernetes/#step-3-push-the-docker-image","title":"Step 3:  Push the Docker image","text":"<pre><code>Execute the command below to push the created Docker image into Docker Hub for the cluster to get access to the previously built container.\n```\n$ docker push wso2inc/greeter:latest\n```\n\n???+ Note\n    Replace `wso2inc` with your repository name.\n\nYou view the output below.\n\n```\nThe push refers to repository [docker.io/wso2inc/greeter]\nlatest: digest: sha256:c1acf5165848d70c347a970d6b5c32f63669cdbb0d4c1daca2c91cfbe32f61b2 size: 13718\n```</code></pre>"},{"location":"deploy/containerized-deployment/deploy-on-kubernetes/#step-4-deploy-on-kubernetes","title":"Step 4:  Deploy on Kubernetes","text":"<pre><code>Execute the command below to deploy the application into the Kubernetes cluster.\n\n```\n$ kubectl apply -f /home/example/greeter/target/kubernetes/greeter\n```\nYou view the output below.\n\n```ballerina\nservice/greeter-svc created\ndeployment.apps/greeter-deployment created\nhorizontalpodautoscaler.autoscaling/greeter-hpa created\n```</code></pre>"},{"location":"deploy/containerized-deployment/overview/","title":"Introduction to Containerized Deployment","text":"<p>Integrations developed with BI can be deployed using modern containerization technologies, such as Docker and Kubernetes, enabling consistent, scalable, and portable application deployments across environments.</p> <p>Containerized deployment simplifies the process of packaging your integration artifacts along with their dependencies into a lightweight, self-contained image. This image can be run on any platform that supports containers, eliminating environmental inconsistencies and easing the transition from development to production.</p> <p>There are two primary approaches to containerized deployment:</p> <ul> <li> <p>Docker Deployment:   Ideal for local development, testing, or simple production environments. The integration runtime is encapsulated in a Docker image, which can be built, run, and managed using standard Docker tools.</p> </li> <li> <p>Kubernetes Deployment:   Suitable for orchestrating containerized applications at scale. Kubernetes provides advanced capabilities like auto-scaling, service discovery, rolling updates, and self-healing, making it the preferred choice for cloud-native and enterprise-grade deployments.</p> </li> </ul> <p>Containerized deployment ensures:</p> <ul> <li>Environment consistency across development, testing, and production.</li> <li>Faster deployment cycles and simplified updates.</li> <li>Better resource utilization and scalability.</li> <li>Easier integration with CI/CD pipelines and cloud infrastructure.</li> </ul> <p>In the following sections, you will learn how to package and deploy your BI projects using Docker and Kubernetes, along with best practices and configuration options.</p> <ul> <li>Deploy as Docker Image</li> <li>Deploy on Kubernetes</li> </ul>"},{"location":"deploy/vm-based-deployment/centralized-deployment/","title":"Centralized Deployment","text":"<p>Managing a large number of BI artifacts across different environments can become complex over time. Each integration flow or service, if deployed independently, can lead to higher operational overhead and increased resource consumption. Centralized deployment simplifies this by bundling all related integration artifacts into a single deployable unit, enabling more efficient resource utilization and streamlined deployments. This approach is ideal when multiple integration solutions need to be deployed and managed together across environments.</p> <p>Centralized deployment typically involves two repositories:</p>"},{"location":"deploy/vm-based-deployment/centralized-deployment/#source-repository-ci","title":"Source Repository (CI)","text":"<p>Typically, a single integration can consist of multiple components, each implemented as a separate BI project. These components can represent distinct functionalities or services that collectively form the complete integration solution. By organizing the integration into multiple projects, the source repository ensures modularity, reusability, and easier maintenance. Each project can be developed, tested, and published independently, allowing teams to work on different components in parallel while maintaining a clear separation of concerns.</p> <p>The source repository is responsible for the continuous integration (CI) process, which includes:</p>"},{"location":"deploy/vm-based-deployment/centralized-deployment/#steps-in-the-ci-process","title":"Steps in the CI Process:","text":""},{"location":"deploy/vm-based-deployment/centralized-deployment/#step-1-prepare-server-environment","title":"Step 1: Prepare Server Environment","text":"<pre><code>- Provision the VM or Bare Metal Server.\n- Ensure the server meets the hardware requirements for your application (CPU, memory, disk space, etc.).\n- Configure the server OS (Linux is recommended for production).</code></pre>"},{"location":"deploy/vm-based-deployment/centralized-deployment/#step-2-install-prerequisites","title":"Step 2: Install prerequisites","text":"<pre><code> - Visual Studio Code: Install &lt;a href=\"https://code.visualstudio.com/\"&gt;Visual Studio Code&lt;/a&gt; if you don't have it already.\n - WSO2 Integrator: BI Extension: Install the WSO2 Integrator: BI extension. Refer to &lt;a href=\"../install-wso2-integrator-bi/\"&gt;Install WSO2 Integrator: BI&lt;/a&gt; for detailed instructions.</code></pre>"},{"location":"deploy/vm-based-deployment/centralized-deployment/#step-3-create-and-implement-bi-projects","title":"Step 3: Create and Implement BI Projects","text":"<pre><code>- Create a new integration project using the BI VS Code extension.\n- Implement business logic using the drag-and-drop designer or by writing Ballerina/DSL code.\n\n???+ Tip\n    Use shared modules or libraries for common logic and avoid duplication.</code></pre>"},{"location":"deploy/vm-based-deployment/centralized-deployment/#step-4-add-tests","title":"Step 4: Add Tests","text":"<pre><code> - Use the `Test Explorer` to create integration tests for services and connectors.</code></pre>"},{"location":"deploy/vm-based-deployment/centralized-deployment/#step-5-build-the-artifacts","title":"Step 5: Build the Artifacts","text":"<pre><code> - Package the project using the BI toolchain to generate deployable `.zip` or `.jar` artifacts.</code></pre>"},{"location":"deploy/vm-based-deployment/centralized-deployment/#step-6-publish-artifacts","title":"Step 6: Publish Artifacts","text":"<pre><code>- Push the generated artifacts to a shared artifact repository (e.g., GitHub Packages, Nexus, or internal registry).\n\n???+ Tip\n    Automate the above CI steps using GitHub Actions or your preferred CI tool.</code></pre>"},{"location":"deploy/vm-based-deployment/centralized-deployment/#deployment-repository-cd","title":"Deployment Repository (CD)","text":"<p>The deployment repository acts as the central hub for production-ready integration artifacts. It collects and consolidates the required applications from one or more source repositories, enabling centralized configuration and deployment. This repository streamlines the deployment process by orchestrating the integration of these applications and preparing them for deployment to the target environment. By centralizing deployment management, it simplifies configuration, enhances maintainability, and ensures consistency across environments.</p>"},{"location":"deploy/vm-based-deployment/centralized-deployment/#steps-in-the-cd-process","title":"Steps in the CD Process:","text":""},{"location":"deploy/vm-based-deployment/centralized-deployment/#step-1-prepare-the-runtime-environment","title":"Step 1: Prepare the Runtime Environment","text":"<pre><code>- Provision a server or containerized environment (e.g., Kubernetes, Docker).\n- Install WSO2 Integrator runtime.\n- Ensure external dependencies (databases, message brokers, etc.) are configured.</code></pre>"},{"location":"deploy/vm-based-deployment/centralized-deployment/#step-2-fetch-and-consolidate-artifacts","title":"Step 2: Fetch and Consolidate Artifacts","text":"<pre><code>- Go to the terminal on VSCode and install the `Ballerina consolidate packages` tool\n\n```\n$ bal tool pull consolidate-packages\n```\n\n- Pull integration artifacts from the source/artifact repositories to create a consolidated project\n\n```\n$ bal consolidate-packages new --package-path &lt;consolidated-project-path&gt; &lt;comma-separated-list-of-package-names&gt;\n```\n\n???+ Tip\n    Visit the [Consolidate-packages tool](/learn/consolidate-packages-tool) for more information on how to consolidate Ballerina packages.</code></pre>"},{"location":"deploy/vm-based-deployment/centralized-deployment/#step-3-add-integration-tests-to-the-consolidated-project","title":"Step 3: Add integration tests to the consolidated project","text":"<pre><code>- Use the `Test Explorer` of BI to write and execute tests for the consolidated project.</code></pre>"},{"location":"deploy/vm-based-deployment/centralized-deployment/#step-4-create-the-executable-jar-for-the-project","title":"Step 4: Create the executable JAR for the project","text":"<pre><code>- Navigate to the Visualizer view by clicking on the BI icon on the sidebar.\n- Click on the **Deploy on VM** under the **Deployment Options** section in the right panel.\n- Click **Create Executable** button.       \n    &lt;a href=\"https://wso2.github.io/docs-bi/assets/img/deploy/build-jar.gif\"&gt;&lt;img src=\"https://wso2.github.io/docs-bi/assets/img/deploy/build-jar.gif\" alt=\"Build JAR\" width=\"70%\"&gt;&lt;/a&gt; \n- The integration will be built as an executable JAR, and the JAR file will be available in the `target\\bin` directory of the project.</code></pre> <p>The generated Ballerina artifact can be deployed to the target environment, configuring necessary environment variables and system settings.</p>"},{"location":"deploy/vm-based-deployment/de-centralized-deployment/","title":"De-centralized Deployment","text":"<p>The de-centralized deployment offers a straightforward approach, ideal for simpler applications or when direct control over individual deployments is preferred. In this method, BI artifacts are developed and published to a registry (a storage location for deployable components). The deployment process retrieves these artifacts and deploys them to the target environment, ensuring all necessary dependencies and configurations are included.</p>"},{"location":"deploy/vm-based-deployment/de-centralized-deployment/#continuous-integration-ci","title":"Continuous Integration (CI)","text":"<p>Continuous Integration (CI) in de-centralized deployment streamlines development by automating the building, testing, and publishing of individual BI artifacts, ensuring faster feedback and fewer integration issues.</p> <p>The following steps outline the CI process of the de-centralized deployment:</p>"},{"location":"deploy/vm-based-deployment/de-centralized-deployment/#step-1-prepare-the-server-environment","title":"Step 1: Prepare the Server Environment","text":"<ul> <li>Provision the VM or Bare Metal Server.</li> <li>Ensure the server meets the hardware requirements for your application (CPU, memory, disk space, etc.).</li> <li>Configure the server OS (Linux is recommended for production).</li> </ul>"},{"location":"deploy/vm-based-deployment/de-centralized-deployment/#step-2-install-prerequisites","title":"Step 2: Install prerequisites","text":"<pre><code> - Visual Studio Code: Install &lt;a href=\"https://code.visualstudio.com/\"&gt;Visual Studio Code&lt;/a&gt; if you don't have it already.\n - WSO2 Integrator: BI Extension: Install the WSO2 Integrator: BI extension. Refer to &lt;a href=\"../install-wso2-integrator-bi/\"&gt;Install WSO2 Integrator: BI&lt;/a&gt; for detailed instructions.</code></pre>"},{"location":"deploy/vm-based-deployment/de-centralized-deployment/#step-3-create-and-implement-bi-projects","title":"Step 3: Create and Implement BI Projects","text":"<pre><code>- Create a new integration project using the BI VS Code extension.\n- Implement business logic using the drag-and-drop designer or by writing Ballerina/DSL code.\n\n???+ Tip\n    Use shared modules or libraries for common logic and avoid duplication.</code></pre>"},{"location":"deploy/vm-based-deployment/de-centralized-deployment/#step-4-add-integration-tests-to-the-consolidated-project","title":"Step 4: Add integration tests to the consolidated project","text":"<pre><code>- Use the `Test Explorer` of BI to write and execute tests for the consolidated project.</code></pre>"},{"location":"deploy/vm-based-deployment/de-centralized-deployment/#step-5-create-the-executable-jar-for-the-project","title":"Step 5: Create the executable JAR for the project","text":"<pre><code>- Navigate to the Visualizer view by clicking on the BI icon on the sidebar.\n- Click on the **Deploy on VM** under the **Deployment Options** section in the right panel.\n- Click **Create Executable** button.       \n    &lt;a href=\"https://wso2.github.io/docs-bi/assets/img/deploy/build-jar.gif\"&gt;&lt;img src=\"https://wso2.github.io/docs-bi/assets/img/deploy/build-jar.gif\" alt=\"Build JAR\" width=\"70%\"&gt;&lt;/a&gt; \n- The integration will be built as an executable JAR and the JAR file will be available in the `target\\bin` directory of the project.</code></pre>"},{"location":"deploy/vm-based-deployment/de-centralized-deployment/#step-6-publish-the-artifacts-to-the-registry","title":"Step 6: Publish the artifacts to the registry.","text":""},{"location":"deploy/vm-based-deployment/de-centralized-deployment/#continuous-deployment-cd","title":"Continuous Deployment (CD)","text":"<p>The Continuous Deployment (CD) process in a de-centralized setup involves automating the deployment of Ballerina artifacts to the target environment. This typically involves using a deployment workflow or pipeline to retrieve the built artifacts from the registry, configure the target environment, deploy the application, and verify its successful deployment.</p>"},{"location":"deploy/vm-based-deployment/deploy-on-vm-as-executable-jar/","title":"Deploy on a VM as an Executable JAR","text":"<p>This guide explains how to deploy an integration as an executable JAR file.</p> <ul> <li>Navigate to the Visualizer view by clicking on the BI icon on the sidebar.</li> <li>Click on the Deploy on VM under the Deployment Options section in the right panel.</li> <li> <p>Click Create Executable button.      </p> </li> <li> <p>The integration will be built as an executable JAR and the JAR file will be available in the <code>target\\bin</code> directory of the project.</p> </li> </ul>"},{"location":"deploy/vm-based-deployment/github-action-for-cicd/","title":"GitHub Action for CICD","text":""},{"location":"deploy/vm-based-deployment/github-action-for-cicd/#github-action-for-cicd-integration","title":"GitHub Action for CI/CD integration","text":"<p>The Ballerina GitHub Action enables seamless automation of CI/CD workflows for WSO2 Integrator: BI projects hosted on GitHub. This action can be used to build and push Ballerina packages that serve as integration artifacts in WSO2 Integrator: BI.</p> <p>The following sample GitHub Actions workflow demonstrates how to automate the build and publish process for a Ballerina-based integration using WSO2 Integrator: BI. The workflow uses the Ballerina GitHub Action to build the integration and publish it to Ballerina Central.</p> <pre><code>name: Ballerina publish example\n\non: [workflow_dispatch]\n\njobs:\nbuild:\n\nruns-on: ubuntu-latest\n\nsteps:\n- name: Checkout\nuses: actions/checkout@v1\n\n- name: Ballerina Build\nuses: ballerina-platform/ballerina-action@master\nwith:\nargs: pack\n\n- name: Ballerina Push\nuses: ballerina-platform/ballerina-action@master\nwith:\nargs: push env: BALLERINA_CENTRAL_ACCESS_TOKEN: ${{ secrets.BallerinaToken }}\n</code></pre>"},{"location":"deploy/vm-based-deployment/overview/","title":"Introduction to VM-based Deployment","text":"<p>Integrations developed with BI can be deployed on virtual machines (VMs), offering a flexible and familiar option for organizations operating in traditional IT environments or requiring fine-grained control over their infrastructure.</p> <p>VM-based deployment involves provisioning virtualized compute resources\u2014either on-premises or in the cloud\u2014and manually configuring the environment to host the BI runtime and its dependencies. This approach is well-suited for setups where containerization is not feasible or where integration with existing VM-based infrastructure is required.</p> <p>There are two common scenarios for VM-based deployment:</p> <ul> <li> <p>On-Premises VMs:   Ideal for environments with strict data residency, security, or compliance requirements. Organizations can deploy and manage BI on VMs running in a controlled internal network.</p> </li> <li> <p>Cloud-hosted VMs:   Suitable for leveraging cloud scalability while maintaining control over the OS and runtime environment. Popular platforms like AWS EC2, Azure Virtual Machines, or Google Compute Engine allow BI to run within customized VM instances.</p> </li> </ul> <p>VM-based deployment offers:</p> <ul> <li>Greater control over operating system, networking, and runtime configurations.</li> <li>Compatibility with legacy systems and hybrid infrastructure models.</li> <li>Easier adoption for teams already using VM-based workflows.</li> <li>A viable alternative where containerization is restricted or unsupported.</li> </ul> <p>In the following sections, you will learn how to set up, configure, and manage BI deployments on virtual machines, including environment preparation, runtime installation, and deployment automation strategies.</p> <ul> <li>Centralized Deployment</li> <li>De-centralized Deployment</li> <li>Deploy on VM as Executable Jar</li> <li>GitHub Action for CICD</li> </ul>"},{"location":"developer-guides/create-a-project/","title":"Create a Project","text":"<p>A project in WSO2 Integrator: BI is the foundational workspace where you define, organize, and manage all your integration artifacts\u2014such as services, data mappings, and connections.</p> <p>Follow the steps below to create your first integration project using WSO2 Integrator: BI.</p>"},{"location":"developer-guides/create-a-project/#steps-to-create-an-integration-project","title":"Steps to Create an Integration Project","text":"<ol> <li> <p>Launch Visual Studio Code with the WSO2 Integrator: BI extension enabled.</p> <p>Info</p> <p>If you have not installed the extension, follow the Install WSO2 Integrator: BI guide.</p> </li> <li> <p>Open the BI Extension</p> <p>Click the BI icon on the Activity Bar of the VS Code editor. This opens the WSO2 Integrator: BI view.</p> <p></p> </li> <li> <p>Create a New Integration Project</p> <p>Click on Create New Integration in the BI view.</p> <p></p> </li> <li> <p>Name and Choose Location for Your Project</p> <p>Enter a suitable name for your integration project and select a location to save it.</p> <p></p> <p>Expected outcome: A new integration project folder is created at your chosen location.</p> </li> <li> <p>Access the BI Home Page</p> <p>Once the project is created, the BI home page will open automatically in VS Code.</p> <p></p> <p>Expected outcome: You should see the BI home page, ready for you to start developing integration artifacts.</p> </li> </ol> <p>Now, you can start creating your integration by developing artifacts. See the WSO2 Integrator: BI Artifacts to learn about the integration artifacts.</p> <p>Additionally, you can enhance your experience by incorporating AI-powered assistance with BI Copilot.</p>"},{"location":"developer-guides/data-mapping/","title":"Data Mapping","text":"<p>This guide shows how to build an integration that transforms a JSON payload into a different JSON structure using WSO2 Integrator: BI Data Mapper. You will create an HTTP service with a single resource (<code>transform</code>) to receive a JSON payload and return the transformed result.</p>"},{"location":"developer-guides/data-mapping/#step-1-create-a-new-integration-project","title":"Step 1: Create a new integration project","text":"<ol> <li>Click on the BI icon on the sidebar.</li> <li>Click on the Create New Integration button.</li> <li>Enter the integration name as <code>Transformer</code>.</li> <li>Select integration directory location by clicking on the Select Path button.</li> <li> <p>Click on the Create Integration button to create the integration project.  </p> <p></p> </li> </ol>"},{"location":"developer-guides/data-mapping/#step-2-create-an-http-service","title":"Step 2: Create an HTTP service","text":"<ol> <li>In the design view, click on the Add Artifact button.</li> <li>Select HTTP Service under the Integration as API category.</li> <li> <p>Click on the Create button to create the new service with the default configurations.</p> <p></p> </li> </ol>"},{"location":"developer-guides/data-mapping/#step-3-update-the-resource-method","title":"Step 3: Update the resource method","text":"<ol> <li>Click the <code>Edit Resource</code> button.</li> <li>Change the resource HTTP method to POST.</li> <li>Change the resource path to <code>transform</code>.</li> <li> <p>Add a new payload named <code>input</code> and click Create New Type to define the <code>Input</code> type.</p> <p></p> </li> <li> <p>Switch to Import mode and provide the following JSON to create the BI type named <code>Input</code>.</p> <pre><code>{\n\"user\": {\n\"firstName\": \"John\",\n\"lastName\": \"Doe\",\n\"email\": \"john.doe@example.com\",\n\"address\": {\n\"street\": \"123 Elm St\",\n\"city\": \"San Francisco\",\n\"state\": \"CA\",\n\"postalCode\": 94107\n},\n\"phoneNumbers\": [\"123-456-7890\", \"098-765-4321\"]\n},\n\"account\": {\n\"accountNumber\": \"A123456789\",\n\"balance\": 2500,\n\"lastTransaction\": \"2023-10-15T14:30:00Z\"\n}\n}\n</code></pre> <p></p> </li> <li> <p>Click Add to save the payload configuration.</p> </li> <li>Change the response body type of the <code>201</code> response to <code>Output</code>.</li> <li>To create the type named <code>Output</code>, click Create New Type within the Message Body Type editor.</li> <li> <p>Switch to Import mode and provide the following JSON to create the BI type named <code>Output</code>.</p> <pre><code>{\n\"fullName\": \"John Doe\",\n\"contactDetails\": {\n\"email\": \"john.doe@example.com\",\n\"primaryPhone\": \"123-456-7890\"\n},\n\"location\": {\n\"city\": \"San Francisco\",\n\"state\": \"CA\",\n\"zipCode\": \"94107\"\n},\n\"accountInfo\": {\n\"accountNumber\": \"A123456789\",\n\"balance\": 2500\n},\n\"transactionDate\":  \"2023-10-15T14:30:00Z\"\n}\n</code></pre> </li> <li> <p>Click Save to apply the response configuration.</p> </li> <li> <p>Finally, click Save to update the resource with the specified configurations. </p> <p></p> </li> </ol> <p>Resource Method</p> <p>To learn more about resources, see Ballerina Resources.</p> <p>Reusable vs inline data mappers</p> <p>There are two ways to create data mappers in WSO2 Integrator: BI. You can create reusable data mappers that can be used anywhere within the integration project, or inline data mappers that are specific to a particular resource or function. In this guide, Step 5 demonstrates how to create a reusable data mapper, and Step 6 (optional) demonstrates how to create an inline data mapper.</p>"},{"location":"developer-guides/data-mapping/#step-5-add-a-reusable-data-mapper","title":"Step 5: Add a reusable data mapper","text":"<ol> <li>Click on the <code>transform</code> resource to navigate to the resource implementation designer view.</li> <li>Hover over the arrow after start and click the \u2795 button to add a new action to the resource.</li> <li>Select Map Data from the node panel and click the Create Data Mapper button. </li> <li> <p>Fill in the required fields with the values below and click the <code>Create</code> button to create the data mapper.</p> Field Value Data Mapper Name <code>transformed</code> Inputs <code>Input input</code> Output <code>Output</code> <p></p> </li> <li> <p>Your newly created data mapper appears under Current Integration. Click it to add it to the sequence.</p> </li> <li>Set <code>payload</code> as the Input and <code>outputResult</code> as the Result, then save.</li> <li> <p>Click the kebab menu on the Map Data node and choose View to open the visual data mapper.</p> <p></p> </li> </ol>"},{"location":"developer-guides/data-mapping/#step-6-optional-add-an-inline-data-mapper","title":"Step 6 (Optional): Add an inline data mapper","text":"<ol> <li>Click on the <code>transform</code> resource to navigate to the resource implementation designer view.</li> <li>Hover over the arrow after start and click the \u2795 button to add a new action to the resource.</li> <li>Select Declare Variable from the node panel.</li> <li>Provide <code>output</code> as the Name and select <code>Output</code> as the Type.</li> <li> <p>Once you select the type, the Open in Data Mapper button appears. Click it to open the visual data mapper.</p> <p></p> <p></p> </li> </ol>"},{"location":"developer-guides/data-mapping/#step-7-create-mappings","title":"Step 7: Create mappings","text":"<p>Click a source field, then click the desired target field to create a mapping.</p>"},{"location":"developer-guides/data-mapping/#create-simple-mapping","title":"Create simple mapping","text":""},{"location":"developer-guides/data-mapping/#auto-mapping","title":"Auto mapping","text":"<p>Click the Auto Map button to automatically create mappings. The BI Copilot panel opens to assist you.</p> <p></p>"},{"location":"developer-guides/data-mapping/#many-to-one-mapping","title":"Many-to-one mapping","text":"<p>You can map multiple source fields to a single target field. For example, create the <code>fullName</code> field in the output by combining the <code>firstName</code> and <code>lastName</code> fields from the input.</p> <p></p>"},{"location":"developer-guides/data-mapping/#edit-mapping-expression","title":"Edit mapping expression","text":"<p>Click the <code>&lt;&gt;</code> button on any link, or use the context menu on any output field, to edit the mapping expression.</p> <p></p>"},{"location":"developer-guides/data-mapping/#array-mapping","title":"Array mapping","text":"<p>BI Data Mapper offers several ways to map arrays. You can map entire arrays, specific elements, or use functions to manipulate array data. To map the first phone number from the <code>phoneNumbers</code> array in the input to the <code>primaryPhone</code> field in the output, create a mapping from <code>phoneNumbers</code> to <code>primaryPhone</code> and pick \"Extract Single Element From Array\" to get the first element. </p> <p></p>"},{"location":"developer-guides/data-mapping/#step-8-return-the-transformed-payload","title":"Step 8: Return the transformed payload","text":"<ol> <li>After you complete the mappings, click the Go Back button to return to the resource designer view.</li> <li>Hover over the arrow after the Map Data node in the flow diagram and click the \u2795 button.</li> <li> <p>Select Return from the node panel. </p> <p></p> </li> <li> <p>Provide <code>outputResult</code> as the return expression.</p> </li> <li> <p>The final code looks like this. The source view can be accessed by clicking the <code>&lt;/&gt;</code> button in the top right corner. </p> <pre><code>import ballerina/http;\n\nlistener http:Listener httpDefaultListener = http:getDefaultListener();\n\nservice / on httpDefaultListener {\n    resource function post transform(@http:Payload Input payload) returns error|json|http:InternalServerError {\n        do {\n            Output outputResult = transform(payload);\n            return outputResult;\n        } on fail error err {\n            // handle error\n            return error(\"unhandled error\", err);\n        }\n    }\n}\n</code></pre> </li> </ol>"},{"location":"developer-guides/data-mapping/#step-9-run-the-integration","title":"Step 9: Run the integration","text":"<ol> <li>Click the Run button in the top-right corner to run the integration.</li> <li>Confirm the Test with Try it Client prompt. The integration starts running and serving at http://localhost:9090/transform.</li> <li> <p>Verify the integration by sending a POST request to the <code>/transform</code> endpoint with the following JSON payload.</p> <pre><code>curl -X POST \"http://localhost:9090/transform\" -H \"Content-Type: application/json\" -d '{\n    \"user\": {\n        \"firstName\": \"John\",\n        \"lastName\": \"Doe\",\n        \"email\": \"john.doe@example.com\",\n        \"address\": {\n            \"street\": \"123 Elm St\",\n            \"city\": \"San Francisco\",\n            \"state\": \"CA\",\n            \"postalCode\": 94107\n        },\n        \"phoneNumbers\": [\"123-456-7890\", \"098-765-4321\"]\n    },\n    \"account\": {\n        \"accountNumber\": \"A123456789\",\n        \"balance\": 2500,\n        \"lastTransaction\": \"2023-10-15T14:30:00Z\"\n    } \n}'\n</code></pre> </li> <li> <p>The response will be the transformed JSON payload. <pre><code>{\n\"fullName\": \"John Doe\",\n\"contactDetails\": {\n\"email\": \"john.doe@example.com\",\n\"primaryPhone\": \"123-456-7890\"\n},\n\"location\": {\n\"city\": \"San Francisco\",\n\"state\": \"CA\",\n\"zipCode\": \"94107\"\n},\n\"accountInfo\": {\n\"accountNumber\": \"A123456789\",\n\"balance\": 2500\n},\n\"transactionDate\":  \"2023-10-15T14:30:00Z\"\n}\n</code></pre></p> </li> </ol>"},{"location":"developer-guides/design-the-integrations/","title":"Design the Integrations","text":"<p>WSO2 Integrator: BI provides intuitive tools to design, analyze, and manage integration flows. Whether you're creating new integrations or reviewing existing ones, the visualizer offers a clear and structured view of system behavior to streamline development and maintenance.</p>"},{"location":"developer-guides/design-the-integrations/#design-view","title":"Design view","text":"<p>The Design View in BI provides an intuitive, visual interface for developing integration projects. It helps you model, understand, and manage integration flows without needing to write or view code directly.</p> <p>Design View helps you:</p> <ul> <li>Visually model complex integration logic.</li> <li>Quickly understand the structure and behavior of your integrations.</li> <li>Accelerate development with drag-and-drop simplicity and AI-powered assistance.</li> <li>Manage deployment and documentation from a unified interface.</li> </ul> <p></p> <p>Key areas of the design view are as follows. </p>"},{"location":"developer-guides/design-the-integrations/#project-explorer","title":"Project explorer","text":"<p>The left sidebar displays the structure of your integration project. It organizes key elements, including:</p> <ul> <li>Entry Points \u2013 Define how your integration is triggered (for example, HTTP services or events).</li> <li>Listeners \u2013 Define the underlying protocols or transports used to receive incoming requests or events.</li> <li>Connections \u2013 Represent external systems that the integration interacts with, such as APIs or databases.</li> <li>Types, Functions, and Data Mappers \u2013 Contain reusable definitions and logic for handling data.</li> <li>Configurations \u2013 Hold externalized values like API keys or secrets.</li> <li>Local Connectors \u2013 Include reusable custom components.</li> </ul>"},{"location":"developer-guides/design-the-integrations/#canvas","title":"Canvas","text":"<p>The central design panel provides a visual representation of the integration flow. Each element is represented as a node, showing how services, listeners, and connections interact with one another. You can view service endpoints and how data moves through the integration.</p>"},{"location":"developer-guides/design-the-integrations/#toolbar","title":"Toolbar","text":"<p>Located at the top of the canvas, the toolbar offers quick actions to:</p> <ul> <li>Generate parts of the integration using AI assistance.</li> <li>Add an Artifact to insert services, events, or other integration elements.</li> </ul>"},{"location":"developer-guides/design-the-integrations/#deployment-options","title":"Deployment options","text":"<p>The panel on the right shows available deployment methods and the status of current deployments. You can choose to:</p> <ul> <li>Deploy to WSO2 Devant.</li> <li>Deploy using Docker or on a virtual machine (VM).</li> <li>Enable the Integration Control Plane (ICP) to monitor and manage deployments.</li> </ul>"},{"location":"developer-guides/design-the-integrations/#readme-panel","title":"README panel","text":"<p>This panel provides contextual documentation about the integration. It\u2019s used to describe the integration\u2019s purpose, features, usage instructions, and external references such as GitHub repositories.</p>"},{"location":"developer-guides/design-the-integrations/#functionautomation-logic-view","title":"Function/Automation logic view","text":"<p>When working with Functions and Automations in BI, you can explore and edit the internal logic using two interactive visual modes\u2014Flow and Sequence. These modes provide complementary perspectives to help understand and manage the behavior of your logic components effectively.</p>"},{"location":"developer-guides/design-the-integrations/#flow-diagram","title":"Flow diagram","text":"<p>The Flow mode presents a high-level, graphical layout of the execution path. It emphasizes clarity by organizing actions vertically in the order in which they are executed.</p> <ul> <li>Shows each step, such as service calls, variable declarations, conditionals, and returns.</li> <li>Includes a visual Error Handler block for defining error management logic.</li> <li>Highlights the end-to-end logic in a simplified, linear format.</li> <li>Helps you quickly understand and edit the logic.</li> </ul> <p></p>"},{"location":"developer-guides/design-the-integrations/#editing-capabilities-in-the-flow-diagram","title":"Editing capabilities in the flow diagram","text":"<p>The Flow mode in BI provides an intuitive, interactive interface for visually editing integration logic. It allows you to design and refine integration flows by interacting directly with the diagram.</p> <p>Interaction Options on Hover</p> <p>When you hover over a connector line between two nodes, the following options become available:</p> <ul> <li>Use AI Assistance: Enter a prompt to generate the next set of nodes using AI assistance. This helps accelerate integration development with contextual suggestions.</li> <li>Add a Comment: Attach comments to document your flow design or explain decisions.</li> <li>Insert Artifacts: Add new artifacts (e.g., functions, conditions, connectors) from the artifact panel between connected nodes.</li> </ul> <p>Node-Level actions</p> <p>Each node in the flow diagram provides a menu with the following actions:</p> <ul> <li>Edit: Modify the operation or configuration of the node.</li> <li>Delete: Remove the node from the diagram.</li> <li>Add Breakpoint: Insert a breakpoint to pause execution at runtime for debugging.</li> <li>View Source: Open and inspect the corresponding source code of the node.</li> </ul> <p>These features make it easy to build, understand, and troubleshoot integrations in a highly visual way.</p> <p></p>"},{"location":"developer-guides/design-the-integrations/#sequence-mode","title":"Sequence mode","text":"<p>The Sequence mode offers a more structured, detailed view closer to traditional sequence diagrams and helps to understand integration behaviours. It emphasizes the sequence of message exchanges across different components in the system.</p> <ul> <li>Displays the flow of invocations between services, clients, and functions.</li> <li>Clearly represents input/output calls and the order of execution.</li> <li>Useful for analyzing integration logic from an operational or interaction standpoint.</li> </ul> <p></p>"},{"location":"developer-guides/design-the-integrations/#types-diagram","title":"Types diagram","text":"<p>The Types Diagram shows a clear visual of how types are defined and connected in the application, allowing for visually adding and editing types. It makes it easier to design data models and understand nested structures by showing their relationships graphically. You can open the Types diagram by clicking on a type in the left panel. </p> <p></p>"},{"location":"developer-guides/design-the-integrations/#source-code-view","title":"Source code view","text":"<p>In addition to the visual views, BI provides a source code view for directly editing the underlying Ballerina code.</p> <p>You can switch to this view by clicking the <code>&lt;/&gt;</code> icon located in the top-right corner of the editor interface. This opens the full source code corresponding to your integration logic.</p> Generate with AI<p>The underlying code is generated in Ballerina, a cloud-native programming language designed for integration. This view is especially useful for users who prefer text-based editing or need fine-grained control over the implementation.</p> <p>Changes made in the Design View or the Source Code View stay in sync, allowing for a seamless switch between visual and code-based development.</p> <p></p>"},{"location":"developer-guides/test-the-integrations/","title":"Testing","text":"<p>BI has a built-in robust test framework, which allows you to ensure that your applications are reliable. The Ballerina powered testframework provides support for assertions, data providers, mocking, and code coverage features, which enable programmers to write comprehensive tests.</p>"},{"location":"developer-guides/test-the-integrations/#test-a-simple-function","title":"Test a Simple Function","text":"<p>Follow the steps below to get started with testing in your BI project.</p> <p>1. Create a BI Project    Open WSO2 BI and create a new project.    Add an artifact of type <code>automation</code> to your project.</p> <p>2. Add a Sample Function    In the generated <code>main.bal</code> file, add the following function:</p> <pre><code>public function intAdd(int a, int b) returns int {\n    return a + b;\n}\n</code></pre> <p>3. Create a Unit Test    Navigate to the Testing extension from the left-hand navigation panel.    Create a new unit test and include an assertion to validate the output of the <code>intAdd</code> function.</p> <p>4. Run the Tests    Use the Run Test option to execute the newly added test case, or choose to run all the tests under the <code>DEFAULT_GROUP</code>.</p> <p></p> <p>For further details on the Ballerina testframework you can refer to Ballerina Testing Guide.</p>"},{"location":"developer-guides/try-the-integration/","title":"Try the Integration","text":"<p>Once you have completed building your integration with the WSO2 Integrator: BI, you can quickly test it right from the design interface. This section walks you through how to run and try your integration project using the built-in tooling.</p>"},{"location":"developer-guides/try-the-integration/#run-the-integration","title":"Run the integration","text":"<ol> <li> <p>Click Run on the top-right title bar of the editor.</p> <p></p> </li> <li> <p>If the required configuration values are missing, a prompt will appear as shown below, indicating that the <code>Config.toml</code> file is missing.</p> <p>You\u2019ll be given three options:</p> <ul> <li>Create Config.toml \u2013 Recommended to generate and populate the required configuration file.</li> <li>Run Anyway \u2013 Proceed without the config file (not recommended for integrations requiring config values).</li> <li>Cancel \u2013 Abort the run operation.</li> </ul> <p>Make sure to choose Create Config.toml and fill in the necessary values before continuing.</p> <p></p> </li> <li> <p>This will launch the integration terminal.</p> </li> </ol>"},{"location":"developer-guides/try-the-integration/#try-the-services","title":"Try the services","text":"<p>The Try It window on the right side of the BI interface provides a built-in way to test your HTTP services without leaving the development environment. </p> <p></p>"},{"location":"developer-guides/wso2-integrator-bi-artifacts/","title":"WSO2 Integrator: BI Artifacts","text":"<p>WSO2 Integrator: BI supports a range of artifact types that enable developers to build powerful, event-driven, API-based, and file-based integration solutions. Each artifact type defines how an integration is triggered and how it behaves in various runtime environments.</p> <p></p> <p>Below is an overview of the available artifact types in the BI.</p>"},{"location":"developer-guides/wso2-integrator-bi-artifacts/#automation","title":"Automation","text":"<p>Create an automation that can be triggered manually or scheduled to run periodically. Automations are ideal for time-based or on-demand processes such as data synchronization, report generation, or cleanup jobs.</p>"},{"location":"developer-guides/wso2-integrator-bi-artifacts/#ai-agent","title":"AI agent","text":"<p>Create an intelligent agent that can be accessed via chat or exposed as an API. AI Agents are useful when you want to embed LLM-backed reasoning or decision-making capabilities into your integration workflows.</p>"},{"location":"developer-guides/wso2-integrator-bi-artifacts/#integration-as-api","title":"Integration as API","text":"<p>Create an integration that exposes services over various protocols such as HTTP, GraphQL, or TCP. This artifact type is used when building services that must interact with external systems through standard APIs.</p>"},{"location":"developer-guides/wso2-integrator-bi-artifacts/#event-integration","title":"Event integration","text":"<p>Create an event-driven integration that is triggered by external events. These can include message brokers, third-party services, or cloud-based event sources.</p> <p>Supported event sources:</p> <ul> <li>Kafka</li> <li>RabbitMQ</li> <li>MQTT</li> <li>Azure Service Bus</li> <li>Salesforce</li> <li>GitHub</li> </ul>"},{"location":"developer-guides/wso2-integrator-bi-artifacts/#file-integration","title":"File integration","text":"<p>Create a file-based integration that reacts to the availability or changes in files within a file system or over FTP. This artifact type is useful for legacy systems or industries that rely on batch file exchanges.</p> <p>Supported file triggers:</p> <ul> <li>FTP services</li> <li>Directory services (local or mounted volumes)</li> </ul> <p>Each artifact type is designed to simplify the creation of integrations suited for a specific kind of use case or trigger. You can combine multiple artifacts within a single solution to cover a wide range of integration needs.</p>"},{"location":"developer-guides/ai-for-integration/build-an-http-service-with-wso2-copilot/","title":"Build an HTTP Service With BI Copilot","text":"<p>In this tutorial, you\u2019ll create an HTTP service to add key-value pairs to a Redis database. The integrated AI-assistant will help you generate the integration flow.</p>"},{"location":"developer-guides/ai-for-integration/build-an-http-service-with-wso2-copilot/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker installed on your machine.</li> </ul>"},{"location":"developer-guides/ai-for-integration/build-an-http-service-with-wso2-copilot/#step-1-create-a-new-integration-project","title":"Step 1: Create a new integration project","text":"<ol> <li>Click on the BI icon on the sidebar.</li> <li>Click on the Create New Integration button.</li> <li>Enter the project name as <code>RedisService</code>.</li> <li>Select project directory location by clicking on the Select Location button.</li> <li>Click on the Create New Integration button to create the integration project.</li> </ol>"},{"location":"developer-guides/ai-for-integration/build-an-http-service-with-wso2-copilot/#step-2-create-a-new-integration","title":"Step 2: Create a new integration","text":"<ol> <li>In the design view click on the Generate with AI button.</li> <li> <p>Enter the following prompt and press <code>Enter</code>:    <pre><code> Create an integration service with a base path of /cache and a POST resource at /add that accepts key-value pairs and adds them to Redis.\n</code></pre></p> <p></p> </li> <li> <p>Click on + Add to Integration button to add the generated integration to the project.</p> </li> <li> <p>The generated integration will look like below:  </p> <p></p> </li> </ol>"},{"location":"developer-guides/ai-for-integration/build-an-http-service-with-wso2-copilot/#step-3-add-a-resource-to-get-value","title":"Step 3: Add a resource to get value","text":"<ol> <li>Add the following prompt and press <code>Enter</code>:    <pre><code> Add a resource to get the value of a key from Redis.\n</code></pre></li> <li>Click on + Add to Integration button to add the generated integration to the project.</li> <li> <p>The generated integration will look like below:  </p> <p></p> </li> </ol>"},{"location":"developer-guides/ai-for-integration/build-an-http-service-with-wso2-copilot/#step-4-start-the-redis-server","title":"Step 4: Start the Redis server","text":"<ol> <li>Start the Redis server by running the following command:    <pre><code>docker run --name some-redis -d -p 6379:6379 redis\n</code></pre></li> <li> <p>The redis server will start on port <code>6379</code> without password protection. </p> <p></p> </li> </ol>"},{"location":"developer-guides/ai-for-integration/build-an-http-service-with-wso2-copilot/#step-6-configure-the-redis-client","title":"Step 6: Configure the Redis client","text":"<ol> <li>In the <code>Design View</code>, click on the Configure button on the top-right side.</li> <li>Set <code>redisHost</code> value to <code>localhost</code>.</li> <li>Set <code>redisPort</code> value to <code>6379</code>.   </li> </ol> <p>Note: No need to set the above values if the configurable variables are generated with default values.</p> <pre><code>  &lt;a href=\"https://wso2.github.io/docs-bi/assets/img/developer-guides/ai-for-integration/http-service-with-copilot/configuration.gif\"&gt;&lt;img src=\"https://wso2.github.io/docs-bi/assets/img/developer-guides/ai-for-integration/http-service-with-copilot/configuration.gif\" alt=\"Configurations\" width=\"70%\"&gt;&lt;/a&gt;</code></pre>"},{"location":"developer-guides/ai-for-integration/build-an-http-service-with-wso2-copilot/#step-5-generate-the-curl-commands","title":"Step 5: Generate the curl commands","text":"<ol> <li> <p>Add the following prompt and press <code>Enter</code> to generate the curl command to add key-value pairs to the Redis server.:    <pre><code> Generate a curl command to add key-value pairs to the Redis server.\n</code></pre></p> <p></p> </li> <li> <p>Add the following prompt and press <code>Enter</code> to generate the curl command to get the value of a key from the Redis server.:    <pre><code> Generate a curl command to get the value of a key from the Redis server.\n</code></pre></p> </li> </ol>"},{"location":"developer-guides/ai-for-integration/build-an-http-service-with-wso2-copilot/#step-6-test-the-integration","title":"Step 6: Test the integration","text":"<ol> <li>Click on the Run button to start the integration.</li> <li>Execute the generated <code>curl</code> commands to add a key-value pair.    <pre><code>   curl -X POST http://localhost:8080/cache/add \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"key\": \"BI\", \"value\": \"BI is an AI-assisted integration platform.\"}' \n</code></pre></li> <li>Execute the generated <code>curl</code> command to get the value of the key.    <pre><code>   curl http://localhost:8080/cache/get?key=BI\n</code></pre></li> <li>The response will be the value of the key <code>BI</code> stored in the Redis server.    <pre><code>BI is an AI-assisted integration platform.%\n</code></pre></li> </ol>"},{"location":"developer-guides/ai-for-integration/build-an-http-service-with-wso2-copilot/#step-7-stop-the-integration","title":"Step 7: Stop the integration","text":"<ol> <li>Click on the Stop button to stop the integration.</li> <li>Stop the Redis server by running the following command:    <pre><code>docker stop some-redis\n</code></pre></li> </ol>"},{"location":"developer-guides/debugging-and-troubleshooting/capturing-strand-dumps/","title":"Capturing Strand Dumps","text":"<p>The BI runtime can have unexpected behaviors due to user code errors, bugs, or issues with the running environment. These will result in memory leaks, CPU spinning, runtime hangs, performance degradation or crashing with various errors. This tool provides the capability to dump the status of currently running strands.</p>"},{"location":"developer-guides/debugging-and-troubleshooting/capturing-strand-dumps/#strand-dump","title":"Strand dump","text":"<p>Ballerina strand dump provides information on the available strands and strand groups during the execution of  a BI program. This can be used to:</p> <ul> <li> <p>troubleshoot runtime errors</p> </li> <li> <p>find data races, race conditions, livelocks, and deadlocks</p> </li> <li> <p>inspect strand and strand group status</p> </li> </ul> Note<p>Currently, this ability is only available in the operating systems in which the <code>SIGTRAP</code> POSIX signal is supported (<code>SIGTRAP</code> is not available on Windows).</p>"},{"location":"developer-guides/debugging-and-troubleshooting/capturing-strand-dumps/#get-the-strand-dump","title":"Get the strand dump","text":"<p>To get the strand dump when a BI program is running, you need to know the process ID (PID) of the BI  program. For that, you can use the <code>jps</code> tool. Then, you need to send the <code>SIGTRAP</code> signal to the process. The strand  dump will be produced to the standard output stream in the text format.</p> <p>For example, create a BI integration and copy the following content to the <code>main.bal</code> file via the file explorer view on VSCode.</p> <pre><code>import ballerina/lang.runtime;\nimport ballerina/io;\n\npublic function main() {\n    future&lt;int&gt; addResult = start addnum(1, 2);\n    int|error addition = wait addResult;\n    io:println(addition);\n}\n\nfunction addnum(int num1, int num2) returns int {\n\n    worker sender {\n        runtime:sleep(1000);\n        num1 -&gt; receiver;\n    }\n\n    worker receiver returns int {\n        int firstNum = &lt;- sender;\n        return num2 + firstNum;\n    }\n\n    int intResult = wait receiver;\n    return intResult;\n}\n</code></pre> <p>Run this BI project using <code>run</code> option in BI.</p> <pre><code>Compiling source\n    demo/strandDump:0.1.0\n\nRunning executable\n</code></pre> <p>Obtain its PID while the program is running. <pre><code>$ jps\n3408 Main\n28851 Jps\n28845 $_init\n</code></pre></p> <p>You get the PID for this program as 28845 because <code>$_init</code> is the main class of the Ballerina program.</p> Note<p>If you run the tests in a Ballerina package or a file using the <code>bal test</code> command, you need to get the PID of the process denoted by the <code>BTestMain</code> classname.</p> <p>To get the strand dump, send the <code>SIGTRAP</code> signal to that process. You can use the following CLI command. <pre><code>$ kill -SIGTRAP 28845\n</code></pre> or <pre><code>$ kill -5 28845\n</code></pre></p> <p>Then, the dump of the runtime strands will be emitted to the standard output stream of the Ballerina program.  For example, see the sample below. <pre><code>Ballerina Strand Dump [2022/10/12 12:08:02]\n===========================================\n\nTotal strand group count        :       5\nTotal strand count              :       5\nActive strand group count       :       2\nActive strand count             :       4\n\ngroup 4 [QUEUED]: [1]\n        strand 2 \"main\" [demo.strandDump.0:main] [WAITING]:\n                at      demo.strandDump.0.1.0:main(main.bal:6)\n\ngroup 5 [QUEUED]: [3]\n        strand 3 \"addResult\" [demo.strandDump.0:main][2] [WAITING]:\n                at      demo.strandDump.0.1.0:addnum(main.bal:22)\n\n        strand 4 \"sender\" [demo.strandDump.0:addnum][3] [BLOCKED]:\n                at      ballerina.lang.runtime.0.0.0:sleep(runtime.bal:61)\n                        demo.strandDump.0.1.0:$lambda$_0(main.bal:13)\n\n        strand 5 \"receiver\" [demo.strandDump.0:addnum][3] [BLOCKED ON WORKER MESSAGE RECEIVE]:\n                at      demo.strandDump.0.1.0:$lambda$_1(main.bal:18)\n\n===========================================\n</code></pre></p>"},{"location":"developer-guides/debugging-and-troubleshooting/capturing-strand-dumps/#output-format-and-available-details","title":"Output format and available details","text":"<p>The strand dump contains the following information.</p> <ul> <li> <p>the date and the time when the strand dump was obtained</p> </li> <li> <p>the total number of strand groups and strands created in the program</p> </li> <li> <p>the active number of strand groups and strands in the program</p> </li> </ul> <p>The details on the active strand groups and strands are given in the following format.</p> <p></p> Label Description Strand group ID A unique ID given to a particular strand group. A strand group comprises a set of strands that run on the same thread. Strand group state Current state of the strand group. For the available states, see Strand group states. The current number of strands in the strand group A strand group consists of one or more strands. Only one of them runs on a thread at a time. Strand ID A unique ID given to a particular strand. Strand name Name of the strand associated with the strand ID. This is optional and will be omitted if not available. Strand initiated module Name of the module, which created the strand. Strand initiated function Name of the function, which created the strand. Parent strand ID ID of the parent strand. This will be omitted if there is no parent strand. Strand state Current state of the strand. For the available states, see Strand states. Strand yielded location stack trace The stack trace, which points to the location where the strand is blocked (yielded). This is omitted if the state is <code>RUNNABLE</code> or <code>DONE</code>. A line in the stack trace is given by the format: <code>module name:function name(filename:line number)</code>"},{"location":"developer-guides/debugging-and-troubleshooting/capturing-strand-dumps/#strand-group-states","title":"Strand group states","text":"State Description RUNNABLE Strand group is ready to run or is currently running. QUEUED Strand group execution is blocked or completed or it comprises a new set of strands that are not yet scheduled to run."},{"location":"developer-guides/debugging-and-troubleshooting/capturing-strand-dumps/#strand-states","title":"Strand states","text":"State Description WAITING FOR LOCK Strand is waiting to acquire a lock. BLOCKED ON WORKER MESSAGE SEND Strand is blocked due to the <code>sync send</code> action. BLOCKED ON WORKER MESSAGE RECEIVE Strand is blocked due to the <code>receive</code> action. BLOCKED ON WORKER MESSAGE FLUSH Strand is blocked due to the <code>flush</code> action. WAITING Strand is blocked due to the <code>wait</code> action. BLOCKED Strand is blocked due to any other reason than the above. E.g., sleep, external function call, etc. RUNNABLE Strand is ready to run or is currently running. DONE Strand execution is completed."},{"location":"developer-guides/debugging-and-troubleshooting/debugging-within-the-editor/","title":"Debugging Within the Editor","text":"<p>BI provides multiple options to debug integrations, and the most convenient way is to use the <code>Debug Integration</code> option located in the top right corner of the editor.</p> <p>Follow these steps to quickly start a debug session.</p> <p>1. Open your BI project and navigate to the relevant integration flow.</p> <p>2. Add debug points by clicking on the required nodes in your integration flow.</p> <p>3. Start debugging by clicking the <code>Debug Integration</code> button on the top right corner of the editor.</p> <p>The program will pause at your debug points, allowing you to inspect variables, check the program status, and step through your integration logic interactively.</p> <p>This integrated debugging experience helps you quickly identify and resolve issues directly within your development environment.</p> <p></p> Note<p>For advanced scenarios, use the launch.json configuration file to launch debug sessions with additional settings, such as program arguments and environment variables. For details, see Debug using configurations.</p>"},{"location":"developer-guides/debugging-and-troubleshooting/overview/","title":"Debugging &amp; Troubleshooting","text":"<p>The Ballerina compiler is especially useful in BI development, where large-scale applications with complex logic are common, as it helps detect both syntax and semantic issues early in the coding process. However, it is difficult for the compiler to detect runtime errors like logical errors because they occur during the program execution after a successful compilation. This is where the dedicated debugging tooling support of Ballerina becomes important.</p>"},{"location":"developer-guides/debugging-and-troubleshooting/overview/#debugging-sessions","title":"Debugging sessions","text":"<p>BI offers three types of debugging sessions (i.e., program debugging, test debugging, and remote debugging). Debugging sessions can be initiated using CodeLens or configurations in a <code>launch.json file</code>. It also provides a <code>Debug Console</code> to view the output and perform various debugging scenarios.</p> <p>Refer to the following sections for more information on debugging sessions.</p> <ul> <li>Debugging Within Editor</li> <li>Remotely Debugging Integrations</li> </ul> Info<p>For more information on the debugging sessions and methods, go to Debugging Sessions.</p>"},{"location":"developer-guides/debugging-and-troubleshooting/overview/#debugging-features","title":"Debugging features","text":"<p>BI provides a range of powerful debugging features. You can set breakpoints with conditions and logpoints, pause and continue program execution for precise inspection, evaluate expressions at runtime, and view call stacks and strands. These features enhance the debugging experience, enabling effective troubleshooting and analysis of Ballerina code.</p> <p>You can set break points for a node in BI by  Clicking on the three dots that appear in right hand side of the node and select <code>Add Breakpoint</code> from the menu.</p> Info<p>For detailed information on the feature-rich debugging experience for troubleshooting BI applications, go to Debugging Features.</p>"},{"location":"developer-guides/debugging-and-troubleshooting/overview/#debugging-configurations","title":"Debugging configurations","text":"<p>The debugger allows you to create a <code>launch.json</code> file with default configurations for debugging BI programs. You can generate the file by following a few steps and then, modify the configurations to suit your needs. These configurations have specific attributes that can be edited to customize the debugging process so that you can set program arguments, command options, environment variables, run in a separate terminal, etc. Additionally, you can configure remote debugging by specifying the host address and port number. These configurations provide flexibility and control when debugging Ballerina code in VS Code.</p> Info<p>For more information on the debugging configurations, go to Debugging Configurations.</p>"},{"location":"developer-guides/debugging-and-troubleshooting/profiling-runtime-performance/","title":"Profiling Runtime Performance","text":"<p>Improvements in your BI implementation might be required to increase its runtime performance, minimize code execution times, increase throughput, and reduce latency. To do that, you need to identify performance bottlenecks, implications of concurrent executions, which code segments take longer to execute, and areas to improve performance. This can be done by using a profiler.</p> <p>Profiler is a tool that monitors the BI runtime and its operations such as function calls. It can be used to understand the behavior and troubleshoot the performance issues of a Ballerina program and optimize it.</p> Note<p>Profiler is an experimental feature, which supports only a limited set of functionality. The commands associated with the tool might change in future releases.</p>"},{"location":"developer-guides/debugging-and-troubleshooting/profiling-runtime-performance/#features","title":"Features","text":"<ul> <li> <p>Profile a local session of a BI program through offline instrumentation.</p> </li> <li> <p>Perform CPU profiling, which finds out where the CPU time is going.</p> </li> <li> <p>Generate a flame graph, which shows the function call stack and the execution times of each function call. It provides an interface for viewing runtime performance and the ability to search, diagnose, and find performance bottlenecks.</p> </li> </ul> Note<p>Profiling is a high-powered activity with a heavy overhead and can slow down your application.</p>"},{"location":"developer-guides/debugging-and-troubleshooting/profiling-runtime-performance/#profile-a-bi-program","title":"Profile a BI program","text":"<p>To profile a Ballerina package, you can use the <code>bal profile</code> CLI command inside the root directory of the BI project.</p> <p>Consider the following step-by-step guide to profile a Ballerina package.</p>"},{"location":"developer-guides/debugging-and-troubleshooting/profiling-runtime-performance/#step-1-create-a-bi-project","title":"Step 1: Create a BI project","text":"<ul> <li> <p>Create a BI project named <code>sort</code></p> </li> <li> <p>Go to the file explorer view and replace the contents of the <code>main.bal</code> file with the following Ballerina code, which creates an array of random integers, sorts them, and verifies the output.</p> </li> </ul> <pre><code>import ballerina/io;\nimport ballerina/random;\n\npublic function main() returns error? {\n    int[] arr = check createRandomIntArray(check float:pow(10, 2).cloneWithType(int));\n    int[] sortedArr = bubbleSort(arr);\n    boolean isSorted = isSortedArray(sortedArr);\n    io:println(\"Is the array sorted? \" + isSorted.toString());\n}\n\npublic isolated function bubbleSort(int[] arr) returns int[] {\n    int n = arr.length();\n    int temp = 0;\n    boolean swapped = false;\n    foreach int i in 0 ... n - 2 {\n        foreach int j in 1 ... n - 1 - i {\n            if (arr[j - 1] &gt; arr[j]) {\n                temp = arr[j - 1];\n                arr[j - 1] = arr[j];\n                arr[j] = temp;\n                swapped = true;\n            }\n        }\n        if (!swapped) {\n            break;\n        }\n    }\n    return arr;\n}\n\nisolated function isSortedArray(int[] sortedArr) returns boolean {\n    foreach int i in 0 ..&lt; sortedArr.length() - 1 {\n        if (sortedArr[i] &gt; sortedArr[i + 1]) {\n            return false;\n        }\n    }\n    return true;\n}\n\nisolated function createRandomIntArray(int size) returns int[]|error {\n    int[] array = [];\n    foreach int i in 0 ..&lt; size {\n        array.push(check random:createIntInRange(0, int:MAX_VALUE));\n    }\n    return array;\n}\n</code></pre>"},{"location":"developer-guides/debugging-and-troubleshooting/profiling-runtime-performance/#step-2-run-the-profiler-to-get-the-profile-details","title":"Step 2: Run the profiler to get the profile details","text":"<ul> <li>Run and profile the Ballerina package using the <code>bal profile</code> CLI command via the VSCode terminal.</li> </ul> <pre><code>$ bal profile\n</code></pre> <p>You view the output below.</p> <pre><code>Compiling source\n        profiler_demo/sort:0.1.0\n\nGenerating executable\n        target/bin/sort.jar\n\n================================================================================\nBallerina Profiler: Profiling...\n================================================================================\nNote: This is an experimental feature, which supports only a limited set of functionality.\n[1/6] Initializing...\n[2/6] Copying executable...\n[3/6] Performing analysis...\n[4/6] Instrumenting functions...\n \u25cb Instrumented module count: 31\n \u25cb Instrumented function count: 1016\n[5/6] Running executable...\nIs the array sorted? true\n[6/6] Generating output...\n \u25cb Execution time: 3 seconds \n \u25cb Output: target/bin/ProfilerOutput.html\n-------------------------------------------------------------------------------\n</code></pre>"},{"location":"developer-guides/debugging-and-troubleshooting/profiling-runtime-performance/#step-3-examine-the-profile-details","title":"Step 3: Examine the profile details","text":"<ul> <li>Open the <code>target/bin/ProfilerOutput.html</code> file using a web browser window to examine the Ballerina Profiler output to find the slow-running functions and performance bottlenecks, which can then be addressed to improve the program\u2019s overall performance.</li> </ul>"},{"location":"developer-guides/debugging-and-troubleshooting/profiling-runtime-performance/#ballerina-profiler-output-flame-graph-content-and-features","title":"Ballerina profiler output: Flame graph content and features","text":"<p>The flame graph generated by the Ballerina Profiler contains the following details.</p> <ul> <li> <p>Function call stack</p> </li> <li> <p>Time taken to execute each function and its percentage</p> </li> </ul> <p></p> <p>Flame graph also has the following features.</p> <ul> <li>Search a function.</li> </ul> <p></p> <ul> <li> <p>Clear the search.</p> </li> <li> <p>Click on a function call and zoom the view.</p> </li> </ul> <p></p> <ul> <li>Reset the view.</li> </ul>"},{"location":"developer-guides/debugging-and-troubleshooting/profiling-runtime-performance/#examine-the-output-and-find-performance-bottlenecks","title":"Examine the output and find performance bottlenecks","text":"<p>When you observe the flame graph generated by the Ballerina Profile for the above code, you can see the <code>bubbleSort</code> function has taken the most time to execute.</p> <p></p> <p>Let's try to optimize the sorting function to increase the performance of the Ballerina application.</p>"},{"location":"developer-guides/debugging-and-troubleshooting/profiling-runtime-performance/#optimize-the-ballerina-code","title":"Optimize the Ballerina code","text":"<p>In this example, you will use another sorting algorithm to reduce the time taken to execute the application. Replace the <code>main.bal</code> file with the code below, which uses the merge sort algorithm instead of the bubble sort algorithm for sorting.</p> <pre><code>import ballerina/io;\nimport ballerina/random;\n\npublic function main() returns error? {\n    int[] arr = check createRandomIntArray(check float:pow(10, 2).cloneWithType(int));\n    int[] sortedArr = mergeSort(arr);\n    boolean isSorted = isSortedArray(sortedArr);\n    io:println(\"Is the array sorted? \" + isSorted.toString());\n}\n\npublic isolated function mergeSort(int[] arr) returns int[] {\n    int n = arr.length();\n    int width = 1;\n    while (width &lt; n) {\n        int l = 0;\n        while (l &lt; n) {\n            int r = int:min(l + (width * 2 - 1), n - 1);\n            int m = int:min(l + width - 1, n - 1);\n            merge(arr, l, m, r);\n            l += width * 2;\n        }\n        width *= 2;\n    }\n    return arr;\n}\n\nisolated function merge(int[] a, int l, int m, int r) {\n    int n1 = m - l + 1;\n    int n2 = r - m;\n    int[] L = [];\n    int[] R = [];\n    foreach int i in int:range(0, n1, 1) {\n        L[i] = a[l + i];\n    }\n    foreach int i in int:range(0, n2, 1) {\n        R[i] = a[m + i + 1];\n    }\n    int i = 0;\n    int j = 0;\n    int k = l;\n    while (i &lt; n1 &amp;&amp; j &lt; n2) {\n        if L[i] &lt;= R[j] {\n            a[k] = L[i];\n            i += 1;\n        } else {\n            a[k] = R[j];\n            j += 1;\n        }\n        k += 1;\n    }\n    while (i &lt; n1) {\n        a[k] = L[i];\n        i += 1;\n        k += 1;\n    }\n    while (j &lt; n2) {\n        a[k] = R[j];\n        j += 1;\n        k += 1;\n    }\n}\n\nisolated function isSortedArray(int[] sortedArr) returns boolean {\n    foreach int i in 0 ..&lt; sortedArr.length() - 1 {\n        if (sortedArr[i] &gt; sortedArr[i + 1]) {\n            return false;\n        }\n    }\n    return true;\n}\n\nisolated function createRandomIntArray(int size) returns int[]|error {\n    int[] array = [];\n    foreach int i in 0 ..&lt; size {\n        array.push(check random:createIntInRange(0, int:MAX_VALUE));\n    }\n    return array;\n}\n</code></pre> <p>When you profile the code again, you can see that you have reduced the time taken for sorting substantially and have improved the performance of the application.</p> <p></p>"},{"location":"developer-guides/debugging-and-troubleshooting/profiling-runtime-performance/#profile-a-ballerina-service","title":"Profile a Ballerina service","text":"<p>Consider the following step-by-step guide to profile a BI project that contains an HTTP service.</p> <p>1. Create a new BI project and replace the <code>main.bal</code> file with the below code.</p> <pre><code>import ballerina/http;\n\ntype Country record {\n    string country;\n    int population;\n    string continent;\n    int cases;\n    int deaths;\n};\n\ntype Data record {|\n    string country;\n    string continent;\n    int population;\n    decimal caseFatalityRatio;\n|};\n\nhttp:Client diseaseEp = check new (\"https://disease.sh/v3\");\nfinal Country[] &amp; readonly countries;\n\nfunction init() returns error? {\n    countries = check diseaseEp-&gt;/covid\\-19/countries;\n}\n\nservice /covid19/countries on new http:Listener(8080) {\n    resource function get summary() returns json {\n        Data[] listResult = from var {country, continent, population, cases, deaths} in countries\n            where hasSignificantPopulation(population, deaths)\n            let decimal caseFatalityRatio = &lt;decimal&gt;deaths / &lt;decimal&gt;cases * 100\n            order by caseFatalityRatio descending\n            limit 1000\n            select {country, continent, population, caseFatalityRatio};\n        return getTopSortedValues(listResult);\n    }\n\n    isolated resource function get names() returns json {\n        return from var {country, population, deaths} in countries\n            where hasNonZeroPopulation(population, deaths)\n            select {country};\n    }\n}\n\nisolated function getTopSortedValues(Data[] listResult) returns json[] {\n    json[] sortedArray = listResult.sort(\"ascending\", getKey);\n    return getTopElements(sortedArray);\n}\n\nisolated function getTopElements(json[] sortedArray) returns json[] {\n    return from var i in sortedArray\n        limit 10\n        select i;\n}\n\nisolated function hasSignificantPopulation(int population, int deaths) returns boolean {\n    return population &gt;= 100 &amp;&amp; deaths &gt;= 10;\n}\n\nisolated function hasNonZeroPopulation(int population, int deaths) returns boolean {\n    return population &gt;= 0 &amp;&amp; deaths &gt;= 0;\n}\n\nisolated function getKey(record {|string country; string continent; int population; decimal caseFatalityRatio;|} recordVal) returns string {\n    return recordVal.country;\n}\n</code></pre> <p>2. Run the CLI command <code>bal profile</code> in the root directory to run the BI project and profile it. This will run the service while profiling it.</p> <pre><code>$ bal profile\nCompiling source\n        profiler_demo/covid19_stats:0.1.0\n\nGenerating executable\n        target/bin/covid19_stats.jar\n\n================================================================================\nBallerina Profiler: Profiling...\n================================================================================\nNote: This is an experimental feature, which supports only a limited set of functionality.\n[1/6] Initializing...\n[2/6] Copying executable...\n[3/6] Performing analysis...\n[4/6] Instrumenting functions...\n \u25cb Instrumented module count: 44\n \u25cb Instrumented function count: 2935\n[5/6] Running executable...\n</code></pre> <p>3. Send 10 requests to each resource endpoint using the <code>curl</code> command.</p> <pre><code>$ curl localhost:8080/covid19/countries/names\n</code></pre> <pre><code>$ curl localhost:8080/covid19/countries/summary\n</code></pre> <p>4. Stop the service by sending the <code>SIGINT</code> signal to the program. You can use <code>Ctrl+C</code> in the service running terminal to send the signal to it. This will stop both the  program and profiling it and will generate the profiler output.</p> <pre><code>[6/6] Generating output...\n \u25cb Execution time: 58 seconds \n \u25cb Output: target/bin/ProfilerOutput.html\n--------------------------------------------------------------------------------\n</code></pre> <p>5. Open the <code>target/bin/ProfilerOutput.html</code> file using a web browser to observe the flame graph generated by the profiler.</p> <p></p> <p>By observing the flame graph you can see that the <code>get summary</code> resource function takes more time than the <code>get names</code> resource function. You can use the profiler output data to improve the performance of the Ballerina service.</p>"},{"location":"developer-guides/debugging-and-troubleshooting/remote-debugging-integrations/","title":"Remote Debugging Integrations","text":"<p>You can debug an already running integration by attaching the debugger remotely. Follow the steps below to start a remote debug session:</p> <p>1. Go to the <code>Debug view</code>.</p> <ul> <li>Press Ctrl + Shift + D (or \u2318 + \u21e7 + D on macOS) to open the Debug view.</li> </ul> <p>2. Open the <code>launch.json</code> file and configure the <code>debuggeeHost</code> and <code>debuggeePort</code> attributes under the <code>Ballerina Remote</code> configuration section.</p> <p>3. Select the remote debug configuration.    In the upper left corner, choose <code>Ballerina Remote</code> from the configuration dropdown.</p> <p>4. Start the integration in debug mode.    Open a terminal and run the appropriate command for your scenario:</p> Command Description <code>bal run --debug &lt;DEBUGGEE_PORT&gt; &lt;BAL_FILE_PATH/PACKAGE_PATH&gt;</code> Debug a Ballerina package or file <code>bal run --debug &lt;DEBUGGEE_PORT&gt; &lt;EXECUTABLE_JAR_FILE_PATH&gt;</code> Debug a Ballerina executable JAR <code>bal test --debug &lt;DEBUGGEE_PORT&gt; &lt;PACKAGE_PATH&gt;</code> Debug Ballerina tests <p>Once started, you should see output similar to:</p> <pre><code>Listening for transport dt_socket at address: 5005\n</code></pre> <p>5. Start the debug session.    Click the <code>Start Debugging</code> icon in the upper left of the editor.    You can now debug your running integration, and debug output will appear in the <code>DEBUG CONSOLE</code>.</p>"},{"location":"developer-guides/protocols-and-connectors/build-custom-connectors/","title":"Build Custom Connectors","text":"<p>APIs power many of the digital services we use daily such as notifications, SMS alerts, reminders, and transactions. These services often expose hundreds of operations via their APIs, making manual coding of client logic tedious and error-prone.</p> <p>To simplify this, BI allows you to generate custom connectors automatically from a valid OpenAPI specification. </p>"},{"location":"developer-guides/protocols-and-connectors/build-custom-connectors/#steps-to-generate-a-custom-connector","title":"Steps to generate a custom connector","text":"<ol> <li> <p>Select Add Custom Connector from the left-hand panel</p> <p></p> </li> <li> <p>Click on Generate a connector</p> <p></p> </li> <li> <p>Name and Select OpenAPI Spec file</p> <p></p> </li> </ol>"},{"location":"developer-guides/protocols-and-connectors/overview-of-connectors/","title":"Overview of Connectors","text":"<p>BI supports a wide range of prebuilt connectors to enable seamless integration across databases, messaging systems, cloud services, SaaS platforms, and networking protocols. These connectors are built using the Ballerina language and allow you to interact with external systems with minimal effort, improving development speed and reducing integration complexity.</p> <p>The following categories summarize the available connectors.</p>"},{"location":"developer-guides/protocols-and-connectors/overview-of-connectors/#network-connectors","title":"\ud83c\udf10 Network Connectors","text":"<p>BI provides multiple connectors to interact over common network protocols such as HTTP, TCP, or FTP. Frequently used options include HTTP (<code>ballerina/http</code>), GraphQL (<code>ballerina/graphql</code>), WebSocket (<code>ballerina/websocket</code>), and FTP (<code>ballerina/ftp</code>). These allow you to expose services or connect to remote endpoints using a variety of communication protocols.</p>"},{"location":"developer-guides/protocols-and-connectors/overview-of-connectors/#database-connectors","title":"\ud83d\uddc3\ufe0f Database Connectors","text":"<p>To handle structured and unstructured data, BI offers connectors to popular relational and NoSQL databases. Some examples include MySQL (<code>ballerinax/mysql</code>), MongoDB (<code>ballerinax/mongodb</code>), MS SQL Server (<code>ballerinax/mssql</code>), and Redis (<code>ballerinax/redis</code>). Additional connectors exist for other specialized or cloud-native databases.</p>"},{"location":"developer-guides/protocols-and-connectors/overview-of-connectors/#messaging-connectors","title":"\ud83d\udce9 Messaging Connectors","text":"<p>BI includes support for various message brokers and streaming platforms. Popular messaging connectors include Kafka Consumer and Producer (<code>ballerinax/kafka</code>) and RabbitMQ (<code>ballerinax/rabbitmq</code>). These connectors help implement asynchronous communication patterns for scalable system designs.</p>"},{"location":"developer-guides/protocols-and-connectors/overview-of-connectors/#cloud-connectors","title":"\u2601\ufe0f Cloud Connectors","text":"<p>Connectors are available for accessing storage, queueing, and database services in cloud environments. Common options include Amazon S3 (<code>ballerinax/aws.s3</code>), Gmail (<code>ballerinax/googleapis.gmail</code>), and Google Calendar (<code>ballerinax/googleapis.gcalendar</code>). BI also supports many other connectors for cloud-native services across different providers.</p>"},{"location":"developer-guides/protocols-and-connectors/overview-of-connectors/#saas-connectors","title":"\ud83e\udde9 SaaS Connectors","text":"<p>BI provides connectors for integrating with widely used SaaS platforms. These enable smooth data flow between your integration and business-critical tools like Salesforce (<code>ballerinax/salesforce</code>), Twilio (<code>ballerinax/twilio</code>), GitHub (<code>ballerinax/github</code>), and Stripe (<code>ballerinax/stripe</code>). Many additional SaaS connectors are available to meet your integration needs.</p>"},{"location":"developer-guides/protocols-and-connectors/overview-of-connectors/#using-connectors-in-bi","title":"Using Connectors in BI","text":"<p>To use a connector in your integration:</p> <ol> <li>Add it from the left panel under Connectors.</li> <li>Configure authentication and connection parameters in the connector setup view.</li> <li>Use drag-and-drop or inline coding to invoke operations exposed by the connector.</li> </ol> <p>Each connector simplifies access to complex services through a well-defined, auto-documented interface.</p>"},{"location":"developer-guides/protocols-and-connectors/supported-protocols/","title":"Supported Protocols","text":"Protocol Description Documentation HTTP HTTP client/server functionalities to produce and consume HTTP APIs <ul> <li> HTTP client </li> <li> HTTP listener </li> </ul> gRPC gRPC client/server functionalities to produce and consume gRPC APIs <ul> <li> gRPC client </li> <li> gRPC listener </li> </ul> WebSocket WebSocket client/server functionalities to produce and consume WebSocket APIs <ul> <li> WebSocket client </li> <li> WebSocket listener </li> </ul> WebSub APIs for the functionalities of the WebSub subscriber <ul><li> WebSub listener</li></ul> WebSubHub APIs for the functionalities of the WebSubHub and WebSub publisher <ul><li> WebSubHub listener </li><li> WebSubHub publsiher client GraphQL GraphQL client/server functionalities to produce and consume GraphQL APIs <ul> <li> GraphQL client </li> <li> GraphQL listener </li> </ul> TCP Send and receive messages to/from another application process (local or remote) over the connection-oriented TCP protocol <ul> <li> TCP client </li> <li> TCP listener </li> </ul> FTP/SFTP FTP/SFTP client/server functionalities to facilitate file handling in a remote file system <ul> <li> FTP client </li> <li> FTP listener </li> </ul> SMTP Send emails via the SMTP protocol using the SMTP client <ul> <li> SMTP client </li> </ul> POP3 Receive emails via the POP3 protocol using both clients and services <ul> <li> POP3 client </li> <li> POP3 listener </li> </ul> IMAP4 Receive emails via the IMAP4 protocol using both clients and services <ul> <li> IMAP4 client </li> <li> IMAP4 listener </li> </ul> JMS Send and receive messages by connecting to a JMS provider <ul> <li> Message producer </li> <li> Message consumer </li> <li> Message listener </li> </ul> AMQP Send and receive messages by connecting to the RabbitMQ server <ul> <li> RabbitMQ client </li> <li> RabbitMQ listener </li> </ul> AWS SQS Perform operations related to queues and messages by connecting to AWS SQS <ul> <li> AWS SQS client </li> </ul> MQTT Publish and subscribe messages by connecting to an MQTT server <ul> <li> MQTT client </li> <li> MQTT listener </li> </ul> SOAP Send and receive messages by connecting to a SOAP service <ul> <li> SOAP client </li> </ul>"},{"location":"developer-guides/tools/integration-tools/edi-tool/","title":"EDI Tool","text":"<p>The EDI tool provides the below set of command line tools to work with EDI files in BI.</p>"},{"location":"developer-guides/tools/integration-tools/edi-tool/#install-the-tool","title":"Install the tool","text":"<p>Execute the command in VSCode terminal below to pull the EDI tool from Ballerina Central.</p> <pre><code>$ bal tool pull edi\n</code></pre>"},{"location":"developer-guides/tools/integration-tools/edi-tool/#usage","title":"Usage","text":"<p>The tool supports three main usages, as follows:</p> <ul> <li>Code generation: Generate Ballerina records and parser functions for a given EDI schema.</li> <li>Package generation: Generates Ballerina records, parser functions, utility methods, and a REST connector for a given collection of EDI schemas and organizes those as a Ballerina package.</li> <li>Schema conversion: Convert various EDI schema formats to Ballerina EDI schema format.</li> </ul>"},{"location":"developer-guides/tools/integration-tools/edi-tool/#define-the-edi-schema","title":"Define the EDI schema","text":"<p>Prior to utilizing the EDI tools, it is crucial to define the structure of the EDI data meant for import. Developers have the option to utilize the Ballerina EDI Schema Specification for guidance. This specification outlines the essential components required to describe an EDI schema, encompassing attributes such as name, delimiters, segments, field definitions, components, sub-components, and additional configuration options.</p> <p>As an illustrative example, consider the following EDI schema definition for a <code>simple order</code>, assumed to be stored as <code>schema.json</code>:</p> <pre><code>{\n\"name\": \"SimpleOrder\",\n\"delimiters\" : {\"segment\" : \"~\", \"field\" : \"*\", \"component\": \":\", \"repetition\": \"^\"},\n\"segments\" : [\n{\n\"code\": \"HDR\",\n\"tag\" : \"header\",\n\"minOccurances\": 1,\n\"fields\" : [{\"tag\": \"code\"}, {\"tag\" : \"orderId\"}, {\"tag\" : \"organization\"}, {\"tag\" : \"date\"}]\n},\n{\n\"code\": \"ITM\",\n\"tag\" : \"items\",\n\"maxOccurances\" : -1,\n\"fields\" : [{\"tag\": \"code\"}, {\"tag\" : \"item\"}, {\"tag\" : \"quantity\", \"dataType\" : \"int\"}]\n}\n]\n}\n</code></pre> <p>This schema can be employed to parse EDI documents featuring one HDR segment, mapped to the <code>header</code>, and any number of ITM segments, mapped to <code>items</code>. The HDR segment incorporates three <code>fields</code>, corresponding to orderId, organization, and date. Each ITM segment comprises two fields, mapped to item and quantity.</p> <p>Below is an example of an EDI document that can be parsed using the aforementioned schema. Let's assume that the following EDI information is saved in a file named <code>sample.edi</code>:</p> <p><pre><code>HDR*ORDER_1201*ABC_Store*2008-01-01~\nITM*A-250*12~\nITM*A-45*100~\nITM*D-10*58~\nITM*K-80*250~\nITM*T-46*28~\n</code></pre> If you already have an existing X12, EDIFACT, or ESL schema file, you can convert it to the Ballerina EDI schema using the EDI tool's schema-conversion capabilities.</p>"},{"location":"developer-guides/tools/integration-tools/edi-tool/#code-generation","title":"Code generation","text":"<p>The below command can be used to generate typed Ballerina records and parser functions for a given EDI schema.</p> <pre><code>$ bal edi codegen -i &lt;input schema path&gt; -o &lt;output path&gt;\n</code></pre> <p>The above command generates all Ballerina records and parser functions required for working with data in the given EDI schema and writes those into the file specified in the <code>output path</code>. The generated parser function (i.e., <code>fromEdiString(...)</code>) can read EDI text files into generated records, which can be accessed from the Ballerina code, similar to accessing any other Ballerina record. Similarly, the generated serialization function (i.e., <code>toEdiString(...)</code>) can serialize generated Ballerina records into EDI text.</p>"},{"location":"developer-guides/tools/integration-tools/edi-tool/#command-options-for-codegen","title":"Command options for <code>codegen</code>","text":"Command option Description Mandatory/Optional <code>-i, --input</code> Path to the EDI schema file. Mandatory <code>-o, --output</code> Path to the output file. Mandatory"},{"location":"developer-guides/tools/integration-tools/edi-tool/#code-generation-example","title":"Code generation example","text":"<p>1. Create a new BI project.</p> <p>2. Create a new folder named resources in the root of the project and copy the <code>schema.json</code> and <code>sample.edi</code> files into it. </p> <p>3. Ballerina records for the EDI schema in <code>resources/schema.json</code> can be generated as follows (generated Ballerina records will be saved in <code>orders.bal</code>).</p> <p>Run the below command from the project root directory to generate the Ballerina parser for the above schema.</p> <pre><code>$ bal edi codegen -i resources/schema.json -o orders.bal\n</code></pre> <p>Generated Ballerina records for the above schema are shown below:</p> <pre><code>public type Header_Type record {|\n   string code = \"HDR\";\n   string orderId?;\n   string organization?;\n   string date?;\n|};\n\npublic type Items_Type record {|\n   string code = \"ITM\";\n   string item?;\n   int? quantity?;\n|};\n\npublic type SimpleOrder record {|\n   Header_Type header;\n   Items_Type[] items = [];\n|};\n</code></pre>"},{"location":"developer-guides/tools/integration-tools/edi-tool/#reading-edi-files","title":"Reading EDI files","text":"<p>The generated <code>fromEdiString</code> function can be used to read EDI text files into the generated Ballerina record, as shown below. Note that any data item in the EDI can be accessed using the record's fields, as shown in the example code.</p> <pre><code>import ballerina/io;\n\npublic function main() returns error? {\n    string ediText = check io:fileReadString(\"resources/sample.edi\");\n    SimpleOrder sample_order = check fromEdiString(ediText);\n    io:println(sample_order.header.date);\n}\n</code></pre>"},{"location":"developer-guides/tools/integration-tools/edi-tool/#writing-edi-files","title":"Writing EDI files","text":"<p>The generated <code>toEdiString</code> function can be used to serialize <code>SimpleOrder</code> records into EDI text, as shown below:</p> <pre><code>import ballerina/io;\n\npublic function main() returns error? {\n    SimpleOrder simpleOrder = {header: {code: \"HDR\", orderId: \"ORDER_200\", organization: \"ABC_Store\", date: \"17-05-2024\"}};\n    simpleOrder.items.push({code: \"ITM\", item: \"A680\", quantity: 15}); \n    simpleOrder.items.push({code: \"ITM\", item: \"A530\", quantity: 2}); \n    simpleOrder.items.push({code: \"ITM\", item: \"A500\", quantity: 4});\n    string ediText = check toEdiString(simpleOrder);\n    io:println(ediText);\n}\n</code></pre>"},{"location":"developer-guides/tools/integration-tools/edi-tool/#package-generation","title":"Package generation","text":"<p>Usually, organizations have to work with many EDI formats, and integration developers need to have a convenient way to work on EDI data with minimum effort. Ballerina EDI packages facilitate this by allowing organizations to pack all EDI processing codes for their EDI collections into an importable package. Therefore, integration developers can simply import those packages and convert EDI messages into Ballerina records in a single line of code.</p> <p>The below command can be used to generate Ballerina records, parser and util functions, and a REST connector for a given collection of EDI schemas organized into a Ballerina package:</p> <pre><code>$ bal edi libgen -p &lt;organization-name/package-name&gt; -i &lt;input schema folder&gt; -o &lt;output folder&gt;\n</code></pre> <p>The Ballerina package will be generated in the output folder. This package can be built and published by issuing <code>bal pack</code> and <code>bal push</code> commands from the output folder. Then, the generated package can be imported into any BI project, and the generated utility functions of the package can be invoked to parse EDI messages into Ballerina records. </p>"},{"location":"developer-guides/tools/integration-tools/edi-tool/#command-options-for-libgen","title":"Command options for <code>libgen</code>","text":"Command option Description Mandatory/Optional <code>-p, --package</code> Package name (organization-name/package-name). Mandatory <code>-i, --input</code> Path to the folder containing EDI schemas. Mandatory <code>-o, --output</code> Path to the folder where packages will be generated. Mandatory"},{"location":"developer-guides/tools/integration-tools/edi-tool/#package-generation-example","title":"Package generation example","text":"<p>Let's assume that an organization named \"CityMart\" needs to work with X12 850, 810, 820, and 855 to handle purchase orders. CityMart's integration developers can put schemas of those X12 specifications into a folder as follows:</p> <pre><code>|-- CityMart\n    |--lib\n    |--schemas\n       |--850.json\n       |--810.json\n       |--820.json\n       |--855.json\n</code></pre> <p>Then, the <code>libgen</code> command can be used to generate a Ballerina package as shown below:</p> <pre><code>$ bal edi libgen -p citymart/porder -i CityMart/schemas -o CityMart/lib\n</code></pre> <p>The generated Ballerina package will look like below:</p> <pre><code>|-- CityMart\n    |--lib  \n    |--porder\n    |     |--modules\n    |     |   |--m850\n    |     |   |  |--G_850.bal\n    |     |   |  |--transformer.bal\n    |     |   |--m810\n    |     |   |  |--G_810.bal\n    |     |   |  |--transformer.bal\n    |     |   |--m820\n    |     |   |  |--G_820.bal\n    |     |   |  |--transformer.bal\n    |     |   |--m855\n    |     |     |--G_855.bal\n    |     |     |--transformer.bal\n    |     |--Ballerina.toml\n    |     |--Module.md\n    |     |--Package.md\n    |     |--porder.bal\n    |     |--rest_connector.bal\n    |\n    |--schemas\n       |--850.json\n       |--810.json\n       |--820.json\n       |--855.json\n</code></pre> <p>As seen in the above project structure, code for each EDI schema is generated into a separate module, to prevent possible conflicts. Now it is possible to build the above project using the <code>bal pack</code> command and publish it into the central repository using the <code>bal push</code> command. Then any BI project can import this package and use it to work with purchase order-related EDI files. An example of using this package for reading an 850 file and writing an 855 file is shown below:</p> <pre><code>import ballerina/io;\nimport citymart/porder.m850;\nimport citymart/porder.m855;\n\npublic function main() returns error? {\n    string orderText = check io:fileReadString(\"orders/d15_05_2023/order10.edi\");\n    m850:Purchase_Order purchaseOrder = check m850:fromEdiString(orderText);\n    ...\n    m855:Purchase_Order_Acknowledgement orderAck = {...};\n    string orderAckText = check m855:toEdiString(orderAck);\n    check io:fileWriteString(\"acks/d15_05_2023/ack10.edi\", orderAckText);\n}\n</code></pre> <p>It is quite common for different trading partners to use variations of standard EDI formats. In such cases, it is possible to create partner-specific schemas and generate a partner-specific Ballerina package for processing interactions with the particular partner.</p>"},{"location":"developer-guides/tools/integration-tools/edi-tool/#using-generated-edi-packages-as-standalone-rest-services","title":"Using generated EDI Packages as standalone REST services","text":"<p>EDI packages generated in the previous step can also be compiled into a jar file (using the <code>bal build</code> command) and executed (using the <code>bal run</code> command) as a standalone Ballerina service that processes EDI files via a REST interface. This is useful for microservice environments where the EDI processing functionality can be deployed as a separate microservice.</p> <p>For example, the \"citymart\" package generated in the above step can be built and executed as a jar file. Once executed, it will expose a REST service to work with X12 850, 810, 820, and 855 files. </p>"},{"location":"developer-guides/tools/integration-tools/edi-tool/#converting-of-x12-850-edi-text-to-json-using-the-rest-service","title":"Converting of X12 850 EDI text to JSON using the REST service","text":"<p>The below REST call can be used to convert an X12 850 EDI text to JSON using the REST service generated from the \"citymart\" package:</p> <pre><code>curl --location 'http://localhost:9090/porderParser/edis/850' \\\n--header 'Content-Type: text/plain' \\\n--data-raw 'GS*PO*SENDERID*RECEIVERID*20240802*1705*1*X*004010~\nST*850*0001~\nBEG*00*NE*4500012345**20240802~\nREF*DP*038~\nPER*BD*John Doe*TE*1234567890*EM*john.doe@example.com~\nFOB*CC~\nITD*01*3*2**30**31~\nDTM*002*20240902~\nN1*ST*SHIP TO NAME*92*SHIP TO CODE~\nN3*123 SHIP TO ADDRESS~\nN4*CITY*STATE*12345*US~\nPO1*1*10*EA*15.00**BP*123456789012*VP*9876543210*UP*123456789012~\nPID*F****PRODUCT DESCRIPTION~\nPO4*1*CA*20*LB~\nCTT*1~\nSE*16*0001~\nGE*1*1~\nIEA*1*000000001~'\n</code></pre> <p>The above REST call will return a JSON response like the below:</p> <pre><code>{\n    \"X12_FunctionalGroup\": {\n        \"FunctionalGroupHeader\": {\n            \"code\": \"GS\",\n            \"GS01__FunctionalIdentifierCode\": \"PO\",\n            \"GS02__ApplicationSendersCode\": \"SENDERID\",\n            \"GS03__ApplicationReceiversCode\": \"RECEIVERID\",\n            ... // Other fields\n        }\n        ... // Other fields\n    },\n    \"InterchangeControlTrailer\": {\n        \"code\": \"IEA\",\n        \"IEA01__NumberofIncludedFunctionalGroups\": 1.0,\n        \"IEA02__InterchangeControlNumber\": 1.0\n    }\n}\n</code></pre>"},{"location":"developer-guides/tools/integration-tools/edi-tool/#converting-of-json-to-x12-850-edi-text-using-the-rest-service","title":"Converting of JSON to X12 850 EDI text using the REST service","text":"<p>The below REST call can be used to convert a JSON to X12 850 EDI text using the REST service generated from the \"citymart\" package:</p> <pre><code>curl --location 'http://localhost:9090/ediParser/objects/850' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n    \"X12_FunctionalGroup\": {\n        \"FunctionalGroupHeader\": {\n            \"code\": \"GS\",\n            \"GS01__FunctionalIdentifierCode\": \"PO\",\n            \"GS02__ApplicationSendersCode\": \"SENDERID\",\n            \"GS03__ApplicationReceiversCode\": \"RECEIVERID\",\n            \"GS04__Date\": \"20240802\",\n            \"GS05__Time\": \"1705\",\n            \"GS06__GroupControlNumber\": 1.0,\n            ... // Other fields\n        },\n        ... // Other fields\n    },\n    \"InterchangeControlTrailer\": {\n        \"code\": \"IEA\",\n        \"IEA01__NumberofIncludedFunctionalGroups\": 1.0,\n        \"IEA02__InterchangeControlNumber\": 1.0\n    }\n}'\n</code></pre> <p>The above REST call will return an X12 850 EDI text response like the below:</p> <pre><code>GS*PO*SENDERID*RECEIVERID*20240802*1705*1*X*004010~\nST*850*0001~\nBEG*00*NE*4500012345**20240802~\nREF*DP*038~\nPER*BD*John Doe*TE*1234567890*EM*john.doe@example.com~\nFOB*CC~\nITD*01*3*2**30**31~\nDTM*002*20240902~\nN1*ST*SHIP TO NAME*92*SHIP TO CODE~\nN3*123 SHIP TO ADDRESS~\nN4*CITY*STATE*12345*US~\nPO1*1*10*EA*15.00**BP*123456789012*VP*9876543210*UP*123456789012~\nPID*F****PRODUCT DESCRIPTION~\nPO4*1*CA*20*LB~\nCTT*1~\nSE*16*0001~\nGE*1*1~\nIEA*1*1~\n</code></pre>"},{"location":"developer-guides/tools/integration-tools/edi-tool/#schema-conversion","title":"Schema conversion","text":"<p>Instead of writing the Ballerina EDI schema from scratch, the Ballerina EDI tool also supports converting various EDI schema formats to the Ballerina EDI schema format.</p>"},{"location":"developer-guides/tools/integration-tools/edi-tool/#x12-schema-to-the-ballerina-edi-schema","title":"X12 schema to the Ballerina EDI schema","text":"<p>X12, short for ANSI ASC X12, is a standard for electronic data interchange (EDI) in the United States. It defines the structure and format of business documents such as <code>purchase orders</code>, <code>invoices</code>, and <code>shipping notices</code>, allowing for seamless communication between different computer systems. X12 standards cover a wide range of industries, including healthcare, finance, retail, and manufacturing.</p> <p>The below command can be used to convert the X12 schema to the Ballerina EDI schema:</p> <pre><code>$ bal edi convertX12Schema -H &lt;enable headers mode&gt; -c &lt;enable collection mode &gt; -i &lt;input schema path&gt; -o &lt;output json file/folder path&gt; -d &lt;segment details path&gt;\n</code></pre> <p>Command options for <code>convertX12Schema</code></p> Command option Description Mandatory/Optional <code>-H, --headers</code> Enable headers mode for X12 schema conversion. Optional <code>-c, --collection</code> Enable collection mode for X12 schema conversion. Optional <code>-i, --input</code> Path to the X12 schema file. Mandatory <code>-o, --output</code> Path to the output file or folder. Mandatory <code>-d, --segdet</code> Path to the segment details file for X12 schema conversion. Optional <p>Example: <pre><code>$ bal edi convertX12Schema -i input/schema.xsd -o output/schema.json\n</code></pre></p>"},{"location":"developer-guides/tools/integration-tools/edi-tool/#edifact-schema-to-the-ballerina-edi-schema","title":"EDIFACT schema to the Ballerina EDI schema","text":"<p>EDIFACT, which stands for Electronic Data Interchange For Administration, Commerce, and Transport, is an international EDI standard developed by the United Nations. It's widely used in Europe and many other parts of the world. EDIFACT provides a common syntax for exchanging business documents electronically between trading partners, facilitating global trade and improving efficiency in supply chain management.</p> <p>The below command can be used to convert the EDIFACT schema to the Ballerina EDI schema:</p> <pre><code>$ bal edi convertEdifactSchema -v &lt;EDIFACT version&gt; -t &lt;EDIFACT message type&gt; -o &lt;output folder&gt;\n</code></pre> <p>Command options for <code>convertEdifactSchema</code></p> Command option Description Mandatory/Optional <code>-v, --version</code> EDIFACT version for EDIFACT schema conversion. Mandatory <code>-t, --type</code> EDIFACT message type for EDIFACT schema conversion. Mandatory <code>-o, --output</code> Path to the folder where EDIFACT schemas will be generated. Mandatory <p>Example: <pre><code>$ bal edi convertEdifactSchema -v d03a -t ORDERS -o output/schema.json\n</code></pre></p>"},{"location":"developer-guides/tools/integration-tools/edi-tool/#esl-to-ballerina-edi-schema","title":"ESL to Ballerina EDI schema","text":"<p>ESL, or Electronic Shelf Labeling, is a technology used in retail stores to display product pricing and information electronically. Instead of traditional paper price tags, ESL systems use digital displays that can be updated remotely, allowing retailers to change prices in real-time and automate pricing strategies.</p> <p>The below command can be used to convert the ESL schema to the Ballerina EDI schema:</p> <pre><code>$ bal edi convertESL -b &lt;segment definitions file path&gt; -i &lt;input ESL schema file/folder&gt; -o &lt;output file/folder&gt;\n</code></pre> <p>Command options for <code>convertEdifactSchema</code></p> Command option Description Mandatory/Optional <code>-b, --basedef</code> Path to the segment definitions file for ESL schema conversion. Mandatory <code>-i, --input</code> Path to the ESL schema file or folder. Mandatory <code>-o, --output</code> Path to the output file or folder. Mandatory <p>Example: <pre><code>$ bal edi convertESL -b segment_definitions.yaml -i esl_schema.esl -o output/schema.json\n</code></pre></p>"},{"location":"developer-guides/tools/integration-tools/health-tool/","title":"Health Tool (FHIR/HL7)","text":"<p>The health tool generates Ballerina library packages and Ballerina templates for FHIR APIs for developing healthcare integrations.</p> <p>These artifacts generated by the tool are primarily focused on the Fast Healthcare Interoperability Resources (FHIR) standard and are developed using Ballerina.</p>"},{"location":"developer-guides/tools/integration-tools/health-tool/#prerequisites","title":"Prerequisites","text":"<p>Download a directory containing all FHIR specification definition files. You can download a preferred standard implementation guide from the FHIR Implementation Guide registry.</p> Note<p>It is recommended to use a Standard for Trial Use (STU) or higher release level of the implementation guides. Make sure that the downloaded specification archive has the <code>StructureDefinition</code>, <code>ValueSet</code>, and <code>CodeSystem</code> files for the Implementation Guide (IG) resources when extracted.</p>"},{"location":"developer-guides/tools/integration-tools/health-tool/#install-the-tool","title":"Install the tool","text":"<p>Execute the command below to pull the Health tool from Ballerina Central.</p> <pre><code>$ bal tool pull health\nhealth:2.0.0 pulled successfully.\nhealth:2.0.0 successfully set as the active version.\n</code></pre>"},{"location":"developer-guides/tools/integration-tools/health-tool/#usage","title":"Usage","text":"<p>The Ballerina Health tool has the following usages.</p> <ul> <li>FHIR package generation: generate a Ballerina package from a given FHIR implementation guide.</li> <li>FHIR template generation: generate Ballerina templates for FHIR APIs from a given FHIR implementation guide.</li> <li>CDS template generation: generate Ballerina templates for Clinical Decision Support (CDS) services based on the CDS specification 2.0.</li> </ul> <p>The general usage of the tool is as follows.</p> Note<p>Make sure to give the directory path of the downloaded FHIR definitions as the last argument.</p> <pre><code>$ bal health fhir [-m | --mode] &lt;mode-type&gt;\n            [-o | --output] &lt;output-location&gt;\n            [--package-name] &lt;ballerina-package-name&gt;\n            [--dependent-package] &lt;dependent-ballerina-package-name&gt; \n            [--org-name] &lt;package-or-template-organization-name&gt;\n            [--included-profile] &lt;profile(s)-to-include-in-generation&gt;\n            [--excluded-profile] &lt;profile(s)-to-exclude-in-generation&gt;\n            &lt;fhir-specification-directory-path&gt;\n</code></pre>"},{"location":"developer-guides/tools/integration-tools/health-tool/#command-options","title":"Command options","text":"<p>The parameters that are available with the tool are listed below.</p> Command option Description Usage <code>-m, --mode</code> Mode type can be <code>package</code> or <code>template</code>. The Ballerina package and API templates are generated according to the mode. <ul><li>package generation</li><li>template generation</li></ul> <code>-o, --output</code> The Ballerina artifacts are generated at the same location from which the <code>bal health fhir</code> command is executed. You can point to another directory location by using the <code>(-o\\|--output)</code> flag. <ul><li>package generation</li><li>template generation</li></ul> <code>--package-name</code> Name of the Ballerina package to be generated. <ul><li>package generation</li></ul> <code>--dependent-package</code> Ballerina package name, which contains the IG resources. <ul><li>template generation</li></ul> <code>--org-name</code> Organization name of the Ballerina package or API templates to be generated. <ul><li>package generation</li><li>template generation</li></ul> <code>--included-profile</code> Generate one or more specific FHIR profiles as Ballerina templates for FHIR APIs. <ul><li>template generation</li></ul> <code>--excluded-profile</code> Skip one or more specific FHIR profiles when generating Ballerina templates for FHIR APIs. <ul><li>template generation</li></ul>"},{"location":"developer-guides/tools/integration-tools/health-tool/#fhir-package-generation","title":"FHIR package generation","text":"<p>The FHIR resources in the implementation guide will be represented as Ballerina records including the correct cardinality constraints and metadata. FHIR integration developers can leverage the generated package when transforming custom health data into FHIR format without referring to the specification.</p>"},{"location":"developer-guides/tools/integration-tools/health-tool/#package-generation-usage","title":"Package generation usage","text":"<p>The tool supports the package generation usage as follows.</p> <pre><code>$ bal health fhir [-m | --mode] package\n            [--package-name] &lt;ballerina-package-name&gt;\n            [-o | --output] &lt;output-location&gt;\n            [--org-name] &lt;package-organization-name&gt;\n            &lt;fhir-specification-directory-path&gt;\n</code></pre>"},{"location":"developer-guides/tools/integration-tools/health-tool/#package-generation-command-options","title":"Package generation command options","text":"Command option Description Mandatory/Optional <code>-m, --mode</code> If <code>mode</code> is set to <code>package</code>, a Ballerina package will be generated including all the records and types. Mandatory <code>--package-name</code> Name of the Ballerina package to be generated. The package name can be explicitly set using this argument. Unless specified, the default name of the implementation guide will be taken to construct the name of the package. For more information, see the the <code>name</code> field. Mandatory <code>-o, --output</code> Location of the generated Ballerina artifacts. If this path is not specified, the output will be written to the same directory from which the command is run. Optional <code>--org-name</code> Organization name of the Ballerina package to be generated. For more information, see  the <code>org</code> field. Optional"},{"location":"developer-guides/tools/integration-tools/health-tool/#package-generation-example","title":"Package generation example","text":"<p>Follow the steps below to try out an example package generation use case of the Health tool.</p>"},{"location":"developer-guides/tools/integration-tools/health-tool/#step-1-clone-the-example-project","title":"Step 1: Clone the example project","text":"<ul> <li> <p>Clone the artifacts of the example and extract them to a preferred location.</p> </li> <li> <p>The cloned directory includes the artifacts below that will be required to try out this example (Ballerina project and the FHIR specification files). </p> <ul> <li>The <code>ig-carinbb/definitions</code> directory: includes the definition files of the FHIR specification.</li> <li>The <code>carinbb-patient-service</code> directory: includes the Ballerina project containing the artifacts (i.e., the <code>Ballerina.toml</code>, <code>Dependencies.toml</code>, and <code>service.bal</code> files) to be executed.</li> </ul> </li> </ul>"},{"location":"developer-guides/tools/integration-tools/health-tool/#step-2-generate-the-package","title":"Step 2: Generate the package","text":"<p>Follow the steps below to run the Health tool and create the Ballerina package.</p> <ol> <li> <p>Navigate to the cloned <code>working-with-health-tool/package-generation</code> directory.</p> </li> <li> <p>Run the tool with the required command options to generate the package.</p> Note<p>This example uses the definitions files downloaded from the JSON Definitions ZIP archive of the Carin BB implementation guide to generate the package.</p> <pre><code>$ bal health fhir -m package -o ig-carinbb/gen --org-name healthcare_samples --package-name carinbb_package ig-carinbb/definitions/\n[INFO] Ballerina FHIR package generation completed successfully. Generated package can be found at: /tmp/healthcare-samples/working-with-health-tool/package-generation/ig-carinbb/gen\n</code></pre> <p>The generated folder (i.e., <code>working-with-health-tool/package-generation/ig-carinbb/gen</code>) will contain the following directory structure.</p> <pre><code>\u2514\u2500\u2500 carinbb_package\n    \u251c\u2500\u2500 Ballerina.toml\n    \u251c\u2500\u2500 Package.md\n    \u251c\u2500\u2500 initializer.bal\n    \u251c\u2500\u2500 resource_c4bbcoverage.bal\n    \u251c\u2500\u2500 resource_c4bbexplanation_of_benefit.bal\n    \u251c\u2500\u2500 resource_c4bbexplanation_of_benefit_inpatient_institutional.bal\n    \u251c\u2500\u2500 resource_c4bbexplanation_of_benefit_oral.bal\n    \u251c\u2500\u2500 resource_c4bbexplanation_of_benefit_outpatient_institutional.bal\n    \u251c\u2500\u2500 resource_c4bbexplanation_of_benefit_pharmacy.bal\n    \u251c\u2500\u2500 resource_c4bbexplanation_of_benefit_professional_non_clinician.bal\n    \u251c\u2500\u2500 resource_c4bborganization.bal\n    \u251c\u2500\u2500 resource_c4bbpatient.bal\n    \u251c\u2500\u2500 resource_c4bbpractitioner.bal\n    \u251c\u2500\u2500 resource_c4bbrelated_person.bal\n    \u251c\u2500\u2500 resources\n    \u251c\u2500\u2500 tests\n    \u2514\u2500\u2500 variables.bal\n</code></pre> </li> <li> <p>Build the generated package.</p> <pre><code>$ cd ig-carinbb/gen/carinbb_package\n$ bal pack\nCompiling source\n        healthcare_samples/carinbb_package:0.0.1\n\nCreating bala\n        target/bala/healthcare_samples-carinbb_package-any-0.0.1.bala\n</code></pre> </li> <li> <p>Push it to a repository.</p> Tip<p>You can push either to the local repository or to Ballerina Central, which is a remote repository.</p> <pre><code>$ bal push --repository local\nSuccessfully pushed target/bala/healthcare_samples-carinbb_package-any-0.0.1.bala to 'local' repository.\n</code></pre> </li> </ol>"},{"location":"developer-guides/tools/integration-tools/health-tool/#step-3-use-the-generated-package","title":"Step 3: Use the generated package","text":"<p>Follow the steps below to use the generated package by running the cloned BI project.</p> <ol> <li> <p>Navigate to the cloned <code>working-with-health-tool/package-generation/carinbb-patient-service</code> directory.</p> Info<p>You can change the dependency (name and version) of the generated package in the <code>carinbb-patient-service/Ballerina.toml</code> file of this cloned BI project directory as preferred.</p> </li> <li> <p>Run the cloned BI project and validate the output.</p> <pre><code>Compiling source\n        healthcare_samples/carinbb_ballerina:1.0.0\n\nRunning executable\n</code></pre> </li> <li> <p>Invoke the API to try it out.</p> <pre><code>$ curl http://localhost:9090/Patient/2121\n</code></pre> <p>You can view the response shown below.</p> <pre><code>{\n\"resourceType\": \"Patient\",\n\"gender\": \"male\",\n\"id\": \"2121\",\n\"identifier\": [\n{\n\"system\": \"http://hl7.org/fhir/sid/us-ssn\",\n\"value\": \"2121\"\n}\n],\n\"meta\": {\n\"profile\": [\n\"http://hl7.org/fhir/us/carin-bb/StructureDefinition/C4BB-Patient\"\n]\n},\n\"name\": [\n{\n\"family\": \"Doe\",\n\"given\": [\n\"John\",\n\"Hemish\"\n]\n}\n]\n}\n</code></pre> </li> </ol>"},{"location":"developer-guides/tools/integration-tools/health-tool/#fhir-template-generation","title":"FHIR template generation","text":"<p>The tool can also be used to generate Ballerina templates for FHIR APIs for the FHIR resources in an implementation guide. FHIR integration developers can utilize these API templates by customizing them to align with their specific business logic and subsequently exposing them as standard FHIR APIs.</p>"},{"location":"developer-guides/tools/integration-tools/health-tool/#template-generation-usage","title":"Template generation usage","text":"<p>The tool supports the template generation usage as follows.</p> <pre><code>$ bal health fhir [-m | --mode] template\n            [--dependent-package] &lt;dependent-ballerina-package-name&gt; \n            [-o | --output] &lt;output-location&gt;\n            [--org-name] &lt;template-organization-name&gt;\n            [--included-profile] &lt;profile(s)-to-include-in-generation&gt;\n            [--excluded-profile] &lt;profile(s)-to-exclude-in-generation&gt;\n            &lt;fhir-specification-directory-path&gt;\n</code></pre>"},{"location":"developer-guides/tools/integration-tools/health-tool/#template-generation-command-options","title":"Template generation command options","text":"Command option Description Mandatory/Optional <code>-m, --mode</code> If <code>mode</code> is set to <code>template</code>, Ballerina templates for FHIR APIs can be generated. Mandatory <code>--dependent-package</code> Fully qualified name of the published Ballerina package containing the IG resources (e.g., <code>&lt;org&gt;/&lt;package&gt;</code>). This option can be used to generate Ballerina templates for FHIR APIs specifically for the resources in the given IG. The package name part of this value will be added as a prefix to the template name. Mandatory <code>-o, --output</code> Location of the generated Ballerina artifacts. If this path is not specified, the output will be written to the same directory from which the command is run. Optional <code>--org-name</code> Organization name of the Ballerina templates for FHIR APIs to be generated. For more information, see  the <code>org</code> field. Optional <code>--included-profile</code> If one or more specific FHIR profiles need to be generated as Ballerina templates, specify the profile URL(s) as the value of this parameter. This argument can be used more than once. Optional <code>--excluded-profile</code> If one or more specific FHIR profiles need to be skipped when generating Ballerina templates, specify the profile URL(s) as the value of this parameter. This argument can be used more than once. Optional"},{"location":"developer-guides/tools/integration-tools/health-tool/#template-generation-example","title":"Template generation example","text":"<p>Follow the steps below to try out an example template generation use case of the Health tool.</p>"},{"location":"developer-guides/tools/integration-tools/health-tool/#step-1-clone-the-example-project_1","title":"Step 1: Clone the example project","text":"<ul> <li> <p>Clone the artifacts of the example and extract them to a preferred location.</p> </li> <li> <p>The cloned directory includes the <code>ig-uscore/definitions</code> directory, which includes the definition files of the FHIR specification.</p> </li> </ul>"},{"location":"developer-guides/tools/integration-tools/health-tool/#step-2-generate-the-templates","title":"Step 2: Generate the templates","text":"<p>Follow the steps below to run the Health tool and generate the Ballerina templates for FHIR APIs for the selected package.</p> Note<p>You need to have a Ballerina package containing IG-specific FHIR resource data models to generate FHIR IG templates. You can use the package mode of the Health tool for easy generation of this package. This example uses the <code>health.fhir.r4.uscore501</code> package in Ballerina Central.</p> <ol> <li> <p>Navigate to the cloned <code>working-with-health-tool/template-generation</code> directory.</p> </li> <li> <p>Run the tool with the required command options to generate the Ballerina templates for FHIR APIs.</p> Note<p>This example uses the definitions files downloaded from the JSON Definitions ZIP archive of the US Core implementation guide to generate the templates.</p> <pre><code>$ bal health fhir -m template -o ig-uscore/gen --org-name healthcare_samples --dependent-package ballerinax/health.fhir.r4.uscore501 ig-uscore/definitions\n[INFO] Generating templates for all FHIR profiles...\n[INFO] Ballerina FHIR API templates generation completed successfully. Generated templates can be found at: /tmp/healthcare-samples/working-with-health-tool/template-generation/ig-uscore/gen\n</code></pre> <p>The generated folder (i.e., <code>working-with-health-tool/template-generation/ig-uscore/gen</code>) will contain the following directory structure.</p> <pre><code>.\n|____device\n|   |____api_config.bal\n|   |____service.bal\n|   |____.gitignore\n|   |____Package.md\n|   |____Ballerina.toml\n|____observation\n|   |____api_config.bal\n|   |____service.bal\n|   |____.gitignore\n|   |____Package.md\n|   |____Ballerina.toml\n|____patient\n|   |____api_config.bal\n|   |____service.bal\n|   |____Dependencies.toml\n|   |____.gitignore\n|   |____Package.md\n|   |____Ballerina.toml\n|____practitioner\n|   |____api_config.bal\n|   |____service.bal\n|   |____Dependencies.toml\n|   |____.gitignore\n|   |____Package.md\n|   |____Ballerina.toml\n|____practitionerrole\n|   |____api_config.bal\n|   |____service.bal\n|   |____.gitignore\n|   |____Package.md\n|   |____Ballerina.toml\n|____procedure\n|   |____api_config.bal\n|   |____service.bal\n|   |____.gitignore\n|   |____Package.md\n|   |____Ballerina.toml\n|____relatedperson\n|   |____api_config.bal\n|   |____service.bal\n|   |____.gitignore\n|   |____Package.md\n|   |____Ballerina.toml    \n</code></pre> </li> </ol>"},{"location":"developer-guides/tools/integration-tools/health-tool/#step-3-use-the-generated-templates","title":"Step 3: Use the generated templates","text":"<p>Follow the steps below to use the generated API templates by running the cloned Ballerina project.</p> <ol> <li> <p>Navigate to the generated <code>working-with-health-tool/template-generation/ig-uscore/gen/practitioner/</code> directory.</p> </li> <li> <p>Update the <code>get fhir/r4/Practitioner/[string id]</code> method in the corresponding <code>working-with-health-tool/template-generation/ig-uscore/gen/practitioner/service.bal</code> file with the code below to implement the business logic.</p> <pre><code>isolated resource function get fhir/r4/Practitioner/[string id] (r4:FHIRContext fhirContext) returns Practitioner|r4:OperationOutcome|r4:FHIRError {\n    Practitioner practitioner = {\n        resourceType: \"Practitioner\",\n        id: \"1\",\n        meta: {\n            lastUpdated: \"2021-08-24T10:10:10Z\",\n            profile: [\n                \"http://hl7.org/fhir/us/core/StructureDefinition/us-core-practitioner\"\n            ]\n        },\n        identifier: [\n            {\n                use: \"official\",\n                system: \"http://hl7.org/fhir/sid/us-npi\",\n                value: \"1234567890\"\n            }\n        ],\n        name: [\n            {\n                use: \"official\",\n                family: \"Smith\",\n                given: [\n                    \"John\",\n                    \"Jacob\"\n                ],\n                prefix: [\n                    \"Dr.\"\n                ]\n            }\n        ]\n    };\n    return practitioner;\n}\n</code></pre> </li> <li> <p>Run the service and verify the output response.</p> <pre><code>Compiling source\n        healthcare_samples/health.fhir.r4.uscore501.practitioner:1.0.0\n\nRunning executable\n</code></pre> </li> <li> <p>Invoke the API to try it out.</p> <pre><code>$ curl http://localhost:9090/fhir/r4/Practitioner/1\n</code></pre> <p>You can view the response shown below.</p> <p><code>json { \"resourceType\":\"Practitioner\", \"identifier\":[     {         \"system\":\"http://hl7.org/fhir/sid/us-npi\",         \"use\":\"official\",         \"value\":\"1234567890\"     } ], \"meta\":{     \"lastUpdated\":\"2021-08-24T10:10:10Z\",     \"profile\":[         \"http://hl7.org/fhir/us/core/StructureDefinition/us-core-practitioner\"     ] }, \"name\":[     {         \"given\":[             \"John\",             \"Jacob\"         ],         \"prefix\":[             \"Dr.\"         ],         \"use\":\"official\",         \"family\":\"Smith\"     } ], \"id\":\"1\"    }</code></p> </li> </ol>"},{"location":"developer-guides/tools/integration-tools/health-tool/#cds-template-generation","title":"CDS template generation","text":"<p>A Ballerina service template can be generated from CDS hook definitions. This template will also include basic functionalities such as validation, prefetch, etc., and it will facilitate the developers' implementation of the required connection with the external decision support system to run the CDS server. The generated Ballerina service project will be written into the provided output location.</p> <p>Supported CDS version: 2.0</p>"},{"location":"developer-guides/tools/integration-tools/health-tool/#template-generation-usage_1","title":"Template generation usage","text":"<pre><code>$ bal health cds\n            [--org-name] &lt;template-organization-name&gt;\n            [--package-name] &lt;name-of-the-package&gt;\n            [--package-version] &lt;version-of-the-package&gt;\n            [-o | --output] &lt;output-location&gt;\n            [-i | --input] &lt;cds-hook-definitions-file-path&gt;\n</code></pre>"},{"location":"developer-guides/tools/integration-tools/health-tool/#cds-template-generation-command-options","title":"CDS template generation command options","text":"Command option Description Mandatory/Optional <code>-i, --input</code> The input file with CDS hook definitions which will be used to generate the Ballerina service. Only TOML files are accepted. Mandatory <code>--org-name</code> The organization name to be used for the generated Ballerina template. For more information, see  the <code>org</code> field. Optional <code>--package-name</code> The package name to be used for the generated Ballerina template. If not specified, <code>health.fhir.templates.crd</code> will be used to construct the name of the package. Optional <code>--package-version</code> The version to be used for the generated Ballerina template. Optional <code>-o, --output</code> The location of the generated Ballerina artifacts. If this path is not specified, the output will be written to the same directory from which the command is run. Optional"},{"location":"developer-guides/tools/integration-tools/health-tool/#template-generation-example_1","title":"Template generation example","text":"<p>Follow the steps below to try out a sample CDS template generation use case of the Health tool.</p>"},{"location":"developer-guides/tools/integration-tools/health-tool/#step-1-create-the-cds-definition-file","title":"Step 1: Create the CDS definition file","text":"<p>Create a TOML file with the CDS hook definitions. Refer to CDS specifications for more information about the attributes.</p> <p>Sample <code>cds-definitions.toml</code> file:</p> <pre><code>[[cds_services]]\nid = \"static-patient-greeter\"\nhook = \"patient-view\"\ntitle = \"Static CDS Service Example\"\ndescription = \"An example of a CDS Service that returns a static set of cards\"\nusageRequirements = \"Note: functionality of this CDS Service is degraded without access to a FHIR Restful API as part of CDS recommendation generation.\"\n[cds_services.prefetch]\npatientToGreet = \"Patient/{{context.patientId}}\"\n\n[[cds_services]]\nid = \"book-imaging-center\"\nhook = \"order-dispatch\"\ntitle = \"Book an imaging center\"\ndescription = \"This hook can be used when booking imaging center\"\n</code></pre>"},{"location":"developer-guides/tools/integration-tools/health-tool/#step-2-generate-the-templates_1","title":"Step 2: Generate the templates","text":"<p>Follow the steps below to run the Health tool and generate the Ballerina templates for CDS for the given hook definitions.</p> <ol> <li> <p>Navigate to the working directory that contains the CDS hook definitions file.</p> </li> <li> <p>Run the tool with the required command options to generate the Ballerina template.</p> </li> </ol> <pre><code>$ bal health cds --org-name wso2 --package-name cds_service  --package-version 1.0.0 -i cds-definitions.toml\n[INFO] Ballerina CDS service template generation completed successfully. The generated project can be found at /Users/tom/Desktop/working_directory/generated-template/cds_service\n</code></pre> <p>The generated folder (i.e., working_directory/template-generation/cds_service) will contain the following directory structure.</p> <pre><code>.\n\u251c\u2500\u2500 Ballerina.toml\n\u251c\u2500\u2500 Config.toml\n\u251c\u2500\u2500 Package.md\n\u251c\u2500\u2500 decision_engine_connector.bal\n\u251c\u2500\u2500 interceptor.bal\n\u251c\u2500\u2500 service.bal\n\u2514\u2500\u2500 utils.bal\n</code></pre>"},{"location":"developer-guides/tools/integration-tools/health-tool/#step-3-use-the-generated-templates_1","title":"Step 3: Use the generated templates","text":"<p>Follow the steps below to use the generated CDS service template.</p> <p>1. Navigate to the generated <code>working_directory/template-generation/cds_service/</code> directory.</p> <p>2. Complete the decision system connectivity implementation.\u00a0The <code>decision_engine_connector</code>\u00a0file contains placeholder functions that must be implemented to connect with external decision systems. Please follow the instructions in the file.</p> <pre><code>Sample implementation for a placeholder function:\n\n```\nisolated function connectDecisionSystemForBookImagingCenter(cds:CdsRequest cdsRequest, string hookId) returns cds:CdsResponse|cds:CdsError {\n    cds:Card card1 = {\n        summary: \"Prior authorization\",\n        indicator: \"critical\",\n        'source: {\n            label: \"Static CDS Service Example\",\n            url: \"https://example.com\",\n            icon: \"https://example.com/img/icon-100px.png\"\n        },\n        detail: \"Obtain prior authorization to avoid claim denials and patient financial liability. Contact: For questions, reach out to the insurance provider or billing department.\",\n        suggestions: [{label: \"Kindly get pri-authorization\"}],\n        selectionBehavior: \"at-most-one\",\n        links: [{label: \"Prior-auth\", url: \"https://www.acmehealth.com/policies/lab-coverage\", 'type: cds:ABSOLUTE}]\n    };\n\n    cds:Card card2 = {\n        summary: \"Alternative centers\",\n        indicator: \"info\",\n        'source: {\n            label: \"Static CDS Service Example\",\n            url: \"https://example.com\",\n            icon: \"https://example.com/img/icon-100px.png\"\n        },\n        detail: \"Discuss alternative imaging centers with patients to enhance access and affordability. For assistance, reach out to the facility's scheduling department or insurance provider.\",\n        suggestions: [\n            {label: \"The selected imaging center is far away from your location. Please select nearby one. Suggested: Asiri labs : Col - 3\"}\n        ],\n        selectionBehavior: \"any\"\n    };\n\n    cds:CdsResponse cdsResponse = {\n        cards: [card1, card2],\n        systemActions: []\n    };\n    return cdsResponse;\n}\n```</code></pre> <p>3. Run the service.</p> <pre><code>Compiling source\n        healthcare_samples/health.fhir.r4.uscore501.practitioner:1.0.0\n\nRunning executable\n</code></pre> <p>4. Invoke the API to try it out.</p> <pre><code>curl --location 'http://localhost:8080/cds-services/book-imaging-center' \\\n--header 'Content-Type: application/json' \\\n--data '{\n \"hookInstance\": \"d1577c69-dfbe-44ad-ba6d-3e05e953b2ea\",\n \"hook\": \"order-dispatch\",\n \"context\": {\n     \"patientId\": \"12345\",\n     \"dispatchedOrders\": [\n         \"ServiceRequest/proc002\"\n     ],\n     \"performer\": \"Organization/O12345\",\n     \"fulfillmentTasks\": [\n         {\n             \"resourceType\": \"Task\",\n             \"status\": \"draft\",\n             \"intent\": \"order\",\n             \"code\": {\n                 \"coding\": [\n                     {\n                         \"system\": \"http://hl7.org/fhir/CodeSystem/task-code\",\n                         \"code\": \"fulfill\"\n                     }\n                 ]\n             },\n             \"focus\": {\n                 \"reference\": \"ServiceRequest/proc002\"\n             },\n             \"for\": {\n                 \"reference\": \"Patient/12345\"\n             },\n             \"authoredOn\": \"2016-03-10T22:39:32-04:00\",\n             \"lastModified\": \"2016-03-10T22:39:32-04:00\",\n             \"requester\": {\n                 \"reference\": \"Practitioner/wdwdwd\"\n             },\n             \"owner\": {\n                 \"reference\": \"Organization/some-performer\"\n             }\n         }\n     ]\n }\n}'\n</code></pre> <p>You can view the response shown below.</p> <pre><code>{\n\"resourceType\": \"Practitioner\",\n\"identifier\": [\n{\n\"system\": \"http://hl7.org/fhir/sid/us-npi\",\n\"use\": \"official\",\n\"value\": \"1234567890\"\n}\n],\n\"meta\": {\n\"lastUpdated\": \"2021-08-24T10:10:10Z\",\n\"profile\": [\n\"http://hl7.org/fhir/us/core/StructureDefinition/us-core-practitioner\"\n]\n},\n\"name\": [\n{\n\"given\": [\"John\", \"Jacob\"],\n\"prefix\": [\"Dr.\"],\n\"use\": \"official\",\n\"family\": \"Smith\"\n}\n],\n\"id\": \"1\"\n}\n</code></pre>"},{"location":"developer-guides/tools/migration-tools/logic-apps-migration-tool/","title":"Azure Logic Apps Migration Tool","text":"<p>This guide explains how to use the migrate-logicapps tool to convert Azure Logic Apps integrations into Ballerina packages compatible with the WSO2 Integrator: BI.</p>"},{"location":"developer-guides/tools/migration-tools/logic-apps-migration-tool/#tool-overview","title":"Tool overview","text":"<p>The tool accepts either a project directory that contains multiple Logic Apps <code>.json</code> files or a single Logic Apps <code>.json</code>  file as input and produces an equivalent WSO2 Integrator: BI project.</p>"},{"location":"developer-guides/tools/migration-tools/logic-apps-migration-tool/#supported-logic-apps-versions","title":"Supported Logic Apps versions","text":"<p>The migration tool supports all the NuGet versions of Azure Logic Apps.  It is recommended to use the latest version of the Logic Apps JSON schema for the best results.</p>"},{"location":"developer-guides/tools/migration-tools/logic-apps-migration-tool/#installation","title":"Installation","text":"<p>To pull the <code>migrate-logicapps</code> tool from Ballerina Central, run the following command: <pre><code>$ bal tool pull migrate-logicapps\n</code></pre></p>"},{"location":"developer-guides/tools/migration-tools/logic-apps-migration-tool/#parameters","title":"Parameters","text":"<p>Following are parameters that can be used with the <code>migrate-logicapps</code> tool:</p> <ul> <li>source-project-directory-or-file - Required. The path to the directory that contains multiple Logic Apps JSON files   or a single Logic Apps JSON file to be migrated.</li> <li>-o or --out - Optional. The directory where the new Ballerina package will be created. If not provided,<ul> <li>For a project directory input, the new Ballerina package is created inside the source project directory.</li> <li>For a single JSON file, the new Ballerina package is created in the same directory as the source file.</li> </ul> </li> <li>-v or --verbose - Optional. Enable verbose output during conversion.</li> <li>-m or --multi-root - Optional. Treat each child directory as a separate project and convert all of them. The source must be a directory containing multiple Logic Apps JSON files.</li> </ul>"},{"location":"developer-guides/tools/migration-tools/logic-apps-migration-tool/#implementation","title":"Implementation","text":"<p>Follow the steps below to migrate your Logic Apps integration.</p>"},{"location":"developer-guides/tools/migration-tools/logic-apps-migration-tool/#step-1-prepare-your-input","title":"Step 1: Prepare your input","text":"<p>You can migrate either a project directory that contains multiple Logic Apps <code>.json</code> files or a single Logic Apps <code>.json</code> file:</p> <ul> <li>For multiple JSON files: Ensure that the project directory only contains Logic Apps <code>.json</code> files.</li> <li>For single JSON files: You can directly use any valid Logic Apps <code>.json</code> file.</li> </ul>"},{"location":"developer-guides/tools/migration-tools/logic-apps-migration-tool/#step-2-run-the-migration-tool","title":"Step 2: Run the migration tool","text":"<p>Use one of the following commands based on your needs.</p> <ol> <li> <p>To convert a Logic Apps JSON file with the default output location:</p> <pre><code>$ bal migrate-logicapps /path/to/logic-app-control-flow.json\n</code></pre> <p>This will create a Ballerina package in the same directory as the input <code>.json</code> file.</p> </li> <li> <p>To convert a Logic Apps JSON file with a custom output location:</p> <pre><code>$ bal migrate-logicapps /path/to/logic-app-control-flow.json --out /path/to/output-dir\n</code></pre> <p>This will create a Ballerina package at <code>/path/to/output-dir</code>.</p> </li> <li> <p>To convert multiple Logic Apps JSON files with the default output location:</p> <pre><code>$ bal migrate-logicapps /path/to/logic-apps-file-directory --multi-root\n</code></pre> <p>This will create multiple Ballerina packages inside <code>/path/to/logic-apps-file-directory</code> directory for each Logic  Apps file.</p> </li> <li> <p>To convert multiple Logic Apps JSON files with a custom output location:</p> <pre><code>$ bal migrate-logicapps /path/to/logic-apps-file-directory --out /path/to/output-dir --multi-root\n</code></pre> <p>This will create multiple Ballerina packages at <code>/path/to/output-dir</code> for each Logic Apps file.</p> </li> </ol>"},{"location":"developer-guides/tools/migration-tools/logic-apps-migration-tool/#step-3-review-migration-output","title":"Step 3: Review migration output","text":"<ol> <li> <p>For a directory with multiple Logic Apps JSON files as input:</p> <ul> <li>A new Ballerina package is created for each Logic Apps file with the same name as the input <code>.json</code> file, appended    with a <code>_ballerina</code> suffix.</li> <li>Created Ballerina package contains the WSO2 Integrator: BI file structure.</li> </ul> </li> <li> <p>For a single Logic Apps JSON file input:</p> <ul> <li>A new Ballerina package is created with the same name as the <code>.json</code> file, appended with a <code>_ballerina</code> suffix.</li> <li>Created Ballerina package contains the WSO2 Integrator: BI file structure.</li> </ul> </li> </ol>"},{"location":"developer-guides/tools/migration-tools/logic-apps-migration-tool/#step-4-address-the-todo-comments-and-manual-adjustments","title":"Step 4: Address the TODO comments and manual adjustments","text":"<p>The generated Ballerina code may contain TODO comments for some Logic Apps actions.  You need to manually review and implement these actions in the Ballerina code.</p> <pre><code>// Function to escape special characters for database operations\npublic function escapeSpecialCharacters(string input) returns string {\n    // Simplified implementation since replace function is not available\n    return input;\n}\n</code></pre> <p>The generated Ballerina code may also contain semantic errors or unsupported features that require manual adjustments.</p> <pre><code>// Initialize HTTP client with timeout configuration\npublic function initializeHttpClient(HttpConfig config) returns http:Client|error {\n    return new (config.baseUrl, {\n        timeout: config.timeout\n    });\n}\n</code></pre>"},{"location":"developer-guides/tools/migration-tools/logic-apps-migration-tool/#example-converting-a-logic-apps-json-file","title":"Example: Converting a Logic Apps JSON file","text":"<p>Let's walk through an example of migrating a Logic Apps sample <code>.json</code> integration to Ballerina.</p> <p>Here's a sample Logic Apps <code>.json</code> file (<code>weather-forecast.json</code>) that runs every hour to fetch weather data from an external API and store it in a SQL database.</p> <pre><code>{\n\"$schema\": \"https://schema.management.azure.com/providers/Microsoft.Logic/schemas/2016-06-01/workflowdefinition.json#\",\n\"contentVersion\": \"1.0.0.0\",\n\"parameters\": {\n\"sqlConnectionString\": {\n\"type\": \"string\",\n\"metadata\": {\n\"description\": \"SQL Database connection string\"\n}\n},\n\"weatherApiKey\": {\n\"type\": \"string\",\n\"metadata\": {\n\"description\": \"Weather API key for external service\"\n}\n}\n},\n\"triggers\": {\n\"Recurrence\": {\n\"type\": \"Recurrence\",\n\"recurrence\": {\n\"frequency\": \"Hour\",\n\"interval\": 1\n}\n}\n},\n\"actions\": {\n\"Initialize_Location_Variable\": {\n\"type\": \"InitializeVariable\",\n\"inputs\": {\n\"variables\": [\n{\n\"name\": \"location\",\n\"type\": \"string\",\n\"value\": \"Seattle,WA\"\n}\n]\n},\n\"runAfter\": {}\n},\n\"Get_Weather_Data\": {\n\"type\": \"Http\",\n\"inputs\": {\n\"method\": \"GET\",\n\"uri\": \"https://api.openweathermap.org/data/2.5/weather\",\n\"queries\": {\n\"q\": \"@variables('location')\",\n\"appid\": \"@parameters('weatherApiKey')\",\n\"units\": \"metric\"\n}\n},\n\"runAfter\": {\n\"Initialize_Location_Variable\": [\n\"Succeeded\"\n]\n}\n},\n\"Check_Weather_Response\": {\n\"type\": \"If\",\n\"expression\": {\n\"and\": [\n{\n\"not\": {\n\"equals\": [\n\"@outputs('Get_Weather_Data')['statusCode']\",\n200\n]\n}\n}\n]\n},\n\"actions\": {\n\"Terminate_Error\": {\n\"type\": \"Terminate\",\n\"inputs\": {\n\"runStatus\": \"Failed\",\n\"runError\": {\n\"code\": \"WeatherApiError\",\n\"message\": \"Failed to retrieve weather data\"\n}\n}\n}\n},\n\"else\": {\n\"actions\": {\n\"Parse_Weather_JSON\": {\n\"type\": \"ParseJson\",\n\"inputs\": {\n\"content\": \"@body('Get_Weather_Data')\",\n\"schema\": {\n\"type\": \"object\",\n\"properties\": {\n\"main\": {\n\"type\": \"object\",\n\"properties\": {\n\"temp\": {\n\"type\": \"number\"\n},\n\"humidity\": {\n\"type\": \"number\"\n},\n\"pressure\": {\n\"type\": \"number\"\n}\n}\n},\n\"weather\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"main\": {\n\"type\": \"string\"\n},\n\"description\": {\n\"type\": \"string\"\n}\n}\n}\n},\n\"name\": {\n\"type\": \"string\"\n}\n}\n}\n}\n},\n\"Check_Temperature_Range\": {\n\"type\": \"If\",\n\"expression\": {\n\"and\": [\n{\n\"greater\": [\n\"@body('Parse_Weather_JSON')['main']['temp']\",\n-50\n]\n},\n{\n\"less\": [\n\"@body('Parse_Weather_JSON')['main']['temp']\",\n60\n]\n}\n]\n},\n\"actions\": {\n\"Update_Weather_Database\": {\n\"type\": \"ApiConnection\",\n\"inputs\": {\n\"host\": {\n\"connection\": {\n\"name\": \"@parameters('$connections')['sql']['connectionId']\"\n}\n},\n\"method\": \"post\",\n\"path\": \"/v2/datasets/@{encodeURIComponent(encodeURIComponent('default'))},@{encodeURIComponent(encodeURIComponent('default'))}/tables/@{encodeURIComponent(encodeURIComponent('[dbo].[WeatherReadings]'))}/items\",\n\"body\": {\n\"Location\": \"@body('Parse_Weather_JSON')['name']\",\n\"Temperature\": \"@body('Parse_Weather_JSON')['main']['temp']\",\n\"Humidity\": \"@body('Parse_Weather_JSON')['main']['humidity']\",\n\"Pressure\": \"@body('Parse_Weather_JSON')['main']['pressure']\",\n\"Condition\": \"@first(body('Parse_Weather_JSON')['weather'])['main']\",\n\"Description\": \"@first(body('Parse_Weather_JSON')['weather'])['description']\",\n\"Timestamp\": \"@utcNow()\",\n\"IsValid\": true\n}\n}\n},\n\"Log_Success\": {\n\"type\": \"Compose\",\n\"inputs\": {\n\"message\": \"Weather data successfully updated\",\n\"location\": \"@body('Parse_Weather_JSON')['name']\",\n\"temperature\": \"@body('Parse_Weather_JSON')['main']['temp']\",\n\"timestamp\": \"@utcNow()\"\n},\n\"runAfter\": {\n\"Update_Weather_Database\": [\n\"Succeeded\"\n]\n}\n}\n},\n\"else\": {\n\"actions\": {\n\"Log_Invalid_Temperature\": {\n\"type\": \"Compose\",\n\"inputs\": {\n\"error\": \"Invalid temperature reading\",\n\"temperature\": \"@body('Parse_Weather_JSON')['main']['temp']\",\n\"location\": \"@body('Parse_Weather_JSON')['name']\"\n}\n},\n\"Insert_Invalid_Reading\": {\n\"type\": \"ApiConnection\",\n\"inputs\": {\n\"host\": {\n\"connection\": {\n\"name\": \"@parameters('$connections')['sql']['connectionId']\"\n}\n},\n\"method\": \"post\",\n\"path\": \"/v2/datasets/@{encodeURIComponent(encodeURIComponent('default'))},@{encodeURIComponent(encodeURIComponent('default'))}/tables/@{encodeURIComponent(encodeURIComponent('[dbo].[WeatherReadings]'))}/items\",\n\"body\": {\n\"Location\": \"@body('Parse_Weather_JSON')['name']\",\n\"Temperature\": \"@body('Parse_Weather_JSON')['main']['temp']\",\n\"Humidity\": \"@body('Parse_Weather_JSON')['main']['humidity']\",\n\"Pressure\": \"@body('Parse_Weather_JSON')['main']['pressure']\",\n\"Condition\": \"Invalid\",\n\"Description\": \"Temperature out of valid range\",\n\"Timestamp\": \"@utcNow()\",\n\"IsValid\": false\n}\n},\n\"runAfter\": {\n\"Log_Invalid_Temperature\": [\n\"Succeeded\"\n]\n}\n}\n}\n},\n\"runAfter\": {\n\"Parse_Weather_JSON\": [\n\"Succeeded\"\n]\n}\n}\n}\n},\n\"runAfter\": {\n\"Get_Weather_Data\": [\n\"Succeeded\",\n\"Failed\"\n]\n}\n},\n\"Handle_Errors\": {\n\"type\": \"Scope\",\n\"actions\": {\n\"Send_Error_Notification\": {\n\"type\": \"Http\",\n\"inputs\": {\n\"method\": \"POST\",\n\"uri\": \"https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK\",\n\"body\": {\n\"text\": \"Weather Logic App failed: @{workflow()['run']['error']['message']}\"\n}\n}\n}\n},\n\"runAfter\": {\n\"Check_Weather_Response\": [\n\"Failed\",\n\"Skipped\",\n\"TimedOut\"\n]\n}\n}\n},\n\"outputs\": {\n\"result\": {\n\"type\": \"Object\",\n\"value\": {\n\"status\": \"completed\",\n\"location\": \"@variables('location')\",\n\"executionTime\": \"@utcNow()\"\n}\n}\n}\n}\n</code></pre> <p>Following is the flow diagram of the Logic Apps:</p> <p>Logic Apps workflow showing the hourly weather data collection and database storage process</p>"},{"location":"developer-guides/tools/migration-tools/logic-apps-migration-tool/#run-the-migration-tool","title":"Run the migration tool","text":"<p>To convert the Logic Apps <code>.json</code> file using the <code>migrate-logicapps</code> tool, execute the following command:</p> <pre><code>$ bal migrate-logicapps /path/to/weather-forecast.json\n</code></pre>"},{"location":"developer-guides/tools/migration-tools/logic-apps-migration-tool/#examine-the-generated-ballerina-code","title":"Examine the generated Ballerina code","text":"<p>The tool generates a Ballerina package named <code>weather-forecast_ballerina</code> inside <code>/path/to</code> with the following structure:</p> <pre><code>weather-forecast_ballerina/\n\u251c\u2500\u2500 agents.bal\n\u251c\u2500\u2500 Ballerina.toml\n\u251c\u2500\u2500 config.bal\n\u251c\u2500\u2500 connections.bal\n\u251c\u2500\u2500 data_mappings.bal\n\u251c\u2500\u2500 functions.bal\n\u251c\u2500\u2500 main.bal\n\u2514\u2500\u2500 types.bal\n</code></pre> <p>The <code>main.bal</code> file contains the main logic of the integration, which includes the scheduled trigger.</p> <p>Please note that the generated Ballerina code may be different in multiple runs since the migration tool uses AI-based  conversion and the output may vary based on the complexity of the Logic Apps application.</p>"},{"location":"developer-guides/tools/migration-tools/logic-apps-migration-tool/#supported-logic-apps-features","title":"Supported Logic Apps features","text":"<p>The migration tool supports the following Azure Logic Apps features:</p>"},{"location":"developer-guides/tools/migration-tools/logic-apps-migration-tool/#core-workflow-components","title":"Core workflow components","text":"<ul> <li>Triggers: HTTP requests, scheduled triggers, and event-based triggers</li> <li>Actions: HTTP actions, data operations, and control flow actions</li> <li>Connectors: Common Azure connectors and third-party service integrations</li> <li>Variables: Workflow variables and their transformations</li> <li>Expressions: Logic Apps expressions and functions</li> </ul>"},{"location":"developer-guides/tools/migration-tools/logic-apps-migration-tool/#control-flow","title":"Control flow","text":"<ul> <li>Conditional Logic: If-else conditions and switch statements</li> <li>Loops: For-each loops and until loops</li> <li>Parallel Branches: Concurrent execution paths</li> <li>Scopes: Grouping actions and error handling</li> </ul>"},{"location":"developer-guides/tools/migration-tools/logic-apps-migration-tool/#data-operations","title":"Data operations","text":"<ul> <li>Data Transformation: JSON parsing, composition, and manipulation</li> <li>Variable Operations: Initialize, set, increment, and append operations</li> <li>Array Operations: Filtering, mapping, and aggregation</li> <li>String Operations: Concatenation, substring, and formatting</li> </ul>"},{"location":"developer-guides/tools/migration-tools/logic-apps-migration-tool/#error-handling","title":"Error handling","text":"<ul> <li>Try-Catch Blocks: Exception handling and error propagation</li> <li>Retry Policies: Configurable retry mechanisms</li> <li>Timeout Settings: Action timeout configurations</li> </ul>"},{"location":"developer-guides/tools/migration-tools/logic-apps-migration-tool/#integration-patterns","title":"Integration patterns","text":"<ul> <li>REST API Calls: HTTP client operations with authentication</li> <li>Message Routing: Content-based routing and message transformation</li> <li>Protocol Translation: Converting between different message formats</li> </ul>"},{"location":"developer-guides/tools/migration-tools/logic-apps-migration-tool/#limitations","title":"Limitations","text":"<p>While the migration tool provides comprehensive conversion capabilities, there are some limitations to be aware of:</p>"},{"location":"developer-guides/tools/migration-tools/logic-apps-migration-tool/#platform-specific-features","title":"Platform-specific features","text":"<ul> <li>Azure-specific connectors: Some Azure-native connectors may not have direct Ballerina equivalents.</li> <li>Logic Apps runtime features: Some runtime-specific features may need manual implementation</li> </ul>"},{"location":"developer-guides/tools/migration-tools/logic-apps-migration-tool/#advanced-scenarios","title":"Advanced scenarios","text":"<ul> <li>Complex Custom Connectors: Custom connectors with complex authentication flows may require manual adaptation</li> <li>Stateful Workflows: Long-running stateful workflows may need additional consideration</li> <li>Large-scale Parallel Processing: Extremely high-concurrency scenarios may require performance tuning</li> </ul>"},{"location":"developer-guides/tools/migration-tools/logic-apps-migration-tool/#ai-generated-code-considerations","title":"AI-generated code considerations","text":"<ul> <li>Code Review Required: Generated code should be reviewed and tested before production use</li> <li>Performance Optimization: Generated code may require optimization for specific use cases</li> <li>Security Validation: Security configurations and credentials should be validated manually</li> </ul>"},{"location":"developer-guides/tools/migration-tools/logic-apps-migration-tool/#post-migration-requirements","title":"Post-migration requirements","text":"<ul> <li>Testing: Comprehensive testing of converted workflows is recommended</li> <li>Configuration: Environment-specific configurations need to be set up manually</li> <li>Monitoring: Logging and monitoring setup may require additional configuration</li> </ul> Disclaimer<p>Azure Logic Apps: \"Azure Logic Apps\", \"Microsoft Azure\", and \"Logic Apps\" are trademarks of Microsoft Corporation. All product, company names and marks mentioned herein are the property of their respective owners and are mentioned for identification purposes only.</p>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/","title":"MuleSoft Migration Tool","text":"<p>This guide explains how to convert existing MuleSoft applications into integrations compatible with WSO2 Integrator: BI.</p>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#overview","title":"Overview","text":"<p>This migration support is directly integrated into WSO2 Integrator: BI, providing a user-friendly wizard interface for converting MuleSoft projects. The tool accepts either a MuleSoft project directory or a standalone Mule <code>.xml</code> configuration file as input and, generates equivalent Ballerina packages that can be opened directly in WSO2 Integrator: BI.</p> <p>The migration wizard provides:</p> <ul> <li>Interactive project selection with file picker support.</li> <li>Real-time migration status with detailed logs.</li> <li>Migration coverage reports showing conversion success rates.</li> <li>Automated project creation with the converted Ballerina code.</li> </ul>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#supported-mule-versions","title":"Supported Mule versions","text":"<p>The migration tool supports both Mule 3.x and Mule 4.x projects.</p>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#usage","title":"Usage","text":"<p>Follow the steps below to migrate your MuleSoft application.</p>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#step-1-prepare-your-input","title":"Step 1: Prepare your input","text":"<p>You can migrate a complete MuleSoft project, a standalone Mule <code>.xml</code> configuration file, or a directory containing multiple MuleSoft projects:</p> <ul> <li>For MuleSoft projects: Ensure your project follows the standard structure with configuration XML files located under:<ul> <li>Mule 3.x: <code>mule-project/src/main/app</code></li> <li>Mule 4.x: <code>mule-project/src/main/mule</code></li> </ul> </li> <li>For standalone XML files: You can directly use any valid Mule XML configuration file.</li> </ul>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#step-2-launch-the-migration-wizard","title":"Step 2: Launch the migration wizard","text":"<ol> <li>Open WSO2 Integrator: BI in VS Code.</li> <li> <p>Access the welcome page - If not automatically displayed, you can access it through the Command Palette (<code>Ctrl+Shift+P</code> / <code>Cmd+Shift+P</code>) and search for \"BI: Open Welcome\".</p> </li> <li> <p>Click \"Import External Integration\" in the \"Import External Integration\" section.</p> </li> </ol>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#step-3-select-source-platform-and-project","title":"Step 3: Select source platform and project","text":"<ol> <li>Choose MuleSoft as your source platform from the available options.</li> <li>Select your project using the file picker:<ul> <li>For MuleSoft projects: Select the project root directory.</li> <li>For standalone XML files: Select the individual <code>.xml</code> file.</li> </ul> </li> <li> <p>Configure MuleSoft settings:</p> <ul> <li>Force Version: Choose \"Auto Detect\" (recommended) or manually specify Mule version (3 or 4).</li> <li>Click \"Start Migration\" to begin the conversion process.</li> </ul> </li> </ol>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#step-4-monitor-migration-progress-and-review-results","title":"Step 4: Monitor migration progress and review results","text":""},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#during-migration-real-time-progress-monitoring","title":"During Migration: Real-time Progress Monitoring","text":"<p>While the migration is ongoing, you will see:</p> <ul> <li>Real-time migration status updates.</li> <li>Detailed logs of the conversion process.</li> <li>Progress indication showing current migration step.</li> </ul>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#after-migration-coverage-report-and-results","title":"After Migration: Coverage Report and Results","text":"<p>Once the migration process completes, the same page updates to show:</p> <ul> <li>Migration Coverage: Percentage showing successful conversion rate.</li> <li>Total code lines: Number of lines processed.</li> <li>Migratable vs Non-migratable code lines: Breakdown of conversion success.</li> <li>View Full Report: Click this button to view the detailed migration report in your browser.</li> <li>Save Report: Click this button to save the migration report to your local file system for future reference.</li> </ul>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#step-5-create-and-open-the-ballerina-project","title":"Step 5: Create and open the Ballerina project","text":"<ol> <li>Configure your integration project:<ul> <li>Enter an Integration Name.</li> <li>Specify the Package Name for the Ballerina package.</li> <li>Select Integration Path where the project will be created.</li> <li>Choose whether to create a new directory using the package name.</li> </ul> </li> <li>Click \"Create and Open Project\" to generate the Ballerina integration project with the converted code.</li> </ol>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#step-6-review-migration-output","title":"Step 6: Review migration output","text":"<p>The generated Ballerina package follows the standard Ballerina Integration (BI) file structure and includes:</p> <ul> <li>Generated Ballerina code with your converted MuleSoft logic.</li> <li>Configuration files (<code>Config.toml</code>, <code>Ballerina.toml</code>) for the new project.</li> <li>Organized code structure with separate files for connections, functions, types, and main logic.</li> </ul>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#step-7-review-the-migration-summary","title":"Step 7: Review the migration summary","text":"<ul> <li>The migration assessment/summary report provides the following percentages:<ol> <li>Component conversion percentage - Shows the proportion of MuleSoft components successfully converted to Ballerina.</li> <li>DataWeave conversion percentage - Reflects the success rate of converting DataWeave scripts.</li> <li>Overall project conversion percentage \u2013 Combines both component and DataWeave conversion rates to indicate the total migration success.</li> </ol> </li> <li>The report includes a Manual work estimation section, which provides an estimated time required to review the migrated code, address TODOs, and complete the migration process.</li> <li>The report also features sections for Element blocks that require manual conversion and DataWeave expressions that require manual conversion, listing all Mule component blocks and DataWeave scripts unsupported by the current tool version and requiring manual conversion. These items are marked as TODOs in the appropriate locations within the generated Ballerina package.</li> </ul>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#step-8-address-the-todo-items","title":"Step 8: Address the TODO items","text":"<p>During conversion, if there are any unsupported Mule XML tags, they are included in the generated Ballerina code as TODO comments. You may need to do the conversion for them manually.</p> <pre><code>public function endpoint(Context ctx) returns http:Response|error {\n\n    // TODO: UNSUPPORTED MULE BLOCK ENCOUNTERED. MANUAL CONVERSION REQUIRED.\n    // ------------------------------------------------------------------------\n    // &lt;db:select-unsupported config-ref=\"MySQL_Configuration\" xmlns:doc=\"http://www.mulesoft.org/schema/mule/documentation\" doc:name=\"Database\" xmlns:db=\"http://www.mulesoft.org/schema/mule/db\"&gt;\n    //             &lt;db:parameterized-query&gt;&lt;![CDATA[SELECT * from users;]]&gt;&lt;/db:parameterized-query&gt;\n    //         &lt;/db:select-unsupported&gt;\n    // ------------------------------------------------------------------------\n\n    log:printInfo(string `Users details: ${ctx.payload.toString()}`);\n\n    ctx.inboundProperties.response.setPayload(ctx.payload);\n    return ctx.inboundProperties.response;\n}\n</code></pre>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#example-converting-a-standalone-mule-xml-file","title":"Example: Converting a standalone Mule XML file","text":"<p>Let's walk through an example of migrating a MuleSoft standalone sample <code>.xml</code> configuration to Ballerina.</p> <p>Here's a sample MuleSoft XML file (<code>users-database-query.xml</code>) that gets invoked via an HTTP listener and performs a database operation:</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n\n&lt;mule xmlns:db=\"http://www.mulesoft.org/schema/mule/db\" xmlns:json=\"http://www.mulesoft.org/schema/mule/json\" xmlns:tracking=\"http://www.mulesoft.org/schema/mule/ee/tracking\" xmlns:http=\"http://www.mulesoft.org/schema/mule/http\" xmlns=\"http://www.mulesoft.org/schema/mule/core\" xmlns:doc=\"http://www.mulesoft.org/schema/mule/documentation\"\nxmlns:spring=\"http://www.springframework.org/schema/beans\"\nxmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\nxsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-current.xsd\nhttp://www.mulesoft.org/schema/mule/core http://www.mulesoft.org/schema/mule/core/current/mule.xsd\nhttp://www.mulesoft.org/schema/mule/http http://www.mulesoft.org/schema/mule/http/current/mule-http.xsd\nhttp://www.mulesoft.org/schema/mule/ee/tracking http://www.mulesoft.org/schema/mule/ee/tracking/current/mule-tracking-ee.xsd\nhttp://www.mulesoft.org/schema/mule/db http://www.mulesoft.org/schema/mule/db/current/mule-db.xsd\nhttp://www.mulesoft.org/schema/mule/json http://www.mulesoft.org/schema/mule/json/current/mule-json.xsd\"&gt;\n&lt;http:listener-config name=\"config\" host=\"0.0.0.0\" port=\"8081\"  doc:name=\"HTTP Listener Configuration\" basePath=\"demo\"/&gt;\n&lt;db:mysql-config name=\"MySQL_Configuration\" host=\"localhost\" port=\"3306\" user=\"root\" password=\"admin123\" database=\"test_db\" doc:name=\"MySQL Configuration\"/&gt;\n&lt;flow name=\"demoFlow\"&gt;\n&lt;http:listener config-ref=\"config\" path=\"/users\" allowedMethods=\"GET\" doc:name=\"HTTP\"/&gt;\n&lt;db:select config-ref=\"MySQL_Configuration\" doc:name=\"Database\"&gt;\n&lt;db:parameterized-query&gt;&lt;![CDATA[SELECT * FROM users;]]&gt;&lt;/db:parameterized-query&gt;\n&lt;/db:select&gt;\n&lt;/flow&gt;\n&lt;/mule&gt;\n</code></pre>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#run-the-migration-wizard","title":"Run the migration wizard","text":"<p>To convert the Mule XML file using the integrated migration wizard:</p> <ol> <li>Open WSO2 Integrator: BI in VS Code.</li> <li>Click \"Import External Integration\" on the welcome page.</li> <li>Select \"MuleSoft\" as the source platform.</li> <li>Use the file picker to select <code>/path/to/users-database-query.xml</code>.</li> <li>Set Force Version to \"3\" in the MuleSoft settings.</li> <li>Click \"Start Migration\" to begin the conversion process.</li> </ol>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#examine-the-generated-ballerina-code","title":"Examine the generated Ballerina code","text":"<p>The tool generates a Ballerina package named <code>users-database-query-ballerina</code> inside <code>/path/to</code> with the following structure (Standard BI layout):</p> <pre><code>users-database-query-ballerina/\n\u251c\u2500\u2500 Ballerina.toml\n\u251c\u2500\u2500 Config.toml\n\u251c\u2500\u2500 configs.bal\n\u251c\u2500\u2500 connections.bal\n\u251c\u2500\u2500 functions.bal\n\u251c\u2500\u2500 main.bal\n\u2514\u2500\u2500 types.bal\n</code></pre> <p>The bal file contains the Ballerina translation of the original MuleSoft XML configuration. It sets up an HTTP service that listens on port 8081 and responds to <code>GET</code> <code>/users</code> requests by querying the MySQL database and returning the results as the response payload.</p> <p>For illustration purposes, the combined code from multiple Ballerina files in the package is summarized below.</p> <pre><code>import ballerina/http;\nimport ballerina/sql;\nimport ballerinax/mysql;\nimport ballerinax/mysql.driver as _;\n\npublic type Record record {\n};\n\nmysql:Client MySQL_Configuration = check new (\"localhost\", \"root\", \"admin123\", \"test_db\", 3306);\npublic listener http:Listener config = new (8081);\n\nservice /demo on config {\n    Context ctx;\n\n    function init() {\n        self.ctx = {payload: (), inboundProperties: {response: new, request: new, uriParams: {}}};\n    }\n\n    resource function get users(http:Request request) returns http:Response|error {\n        self.ctx.inboundProperties.request = request;\n        return invokeEndPoint0(self.ctx);\n    }\n}\n\npublic function invokeEndPoint0(Context ctx) returns http:Response|error {\n\n    // database operation\n    sql:ParameterizedQuery dbQuery0 = `SELECT * FROM users;`;\n    stream&lt;Record, sql:Error?&gt; dbStream0 = MySQL_Configuration-&gt;query(dbQuery0);\n    Record[] dbSelect0 = check from Record _iterator_ in dbStream0\n        select _iterator_;\n    ctx.payload = dbSelect0;\n\n    ctx.inboundProperties.response.setPayload(ctx.payload);\n    return ctx.inboundProperties.response;\n}\n</code></pre> <p>You can view the migration report using the \"View Full Report\" button in the migration wizard for an overview of the migration.</p> <p>This example demonstrates how to migrate a MuleSoft application that performs database operations to Ballerina using the migration tool. The migration tool automatically converts the database configuration and SQL query to the equivalent Ballerina code using the <code>ballerinax/mysql</code> module.</p>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#supported-mule-components","title":"Supported Mule components","text":"<p>The migration tool currently supports a wide range of Mule components for both Mule 3.x and Mule 4.x. For a full list of supported components and their mappings, see:</p> <ul> <li>Mule 3.x Components</li> <li>Mule 4.x Components</li> </ul>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#supported-dataweave-transformations","title":"Supported DataWeave transformations","text":"<p>The migration tool supports both DataWeave 1.0 (Mule 3.x) and DataWeave 2.0 (Mule 4.x) transformations. For details and conversion samples, see:</p> <ul> <li>DataWeave 1.0 Mappings</li> <li>DataWeave 2.0 Mappings</li> </ul>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#limitations","title":"Limitations","text":"<ul> <li>Multi-project migration is not currently supported through the VS Code extension UI. For batch migration of multiple MuleSoft projects, use the CLI tool migrate-mule separately.</li> <li>Some moderate to advanced MuleSoft features may require manual adjustments after migration.</li> </ul> Disclaimer<p>MuleSoft: \"MuleSoft\", Mulesoft's \"Anypoint Platform\", and \"DataWeave\" are trademarks of MuleSoft LLC, a Salesforce company. All product, company names and marks mentioned herein are the property of their respective owners and are mentioned for identification purposes only.</p>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/","title":"TIBCO BusinessWorks Migration Tool","text":"<p>This guide explains how to use the integrated migration feature in WSO2 Integrator: BI to convert TIBCO BusinessWorks integrations into Ballerina packages.</p>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#overview","title":"Overview","text":"<p>This migration support is directly integrated into WSO2 Integrator: BI, providing a user-friendly wizard interface for converting TIBCO BusinessWorks projects. The tool accepts either a BusinessWorks project directory or a standalone process file as input and, generates equivalent Ballerina packages that can be opened directly in WSO2 Integrator: BI.</p> <p>The migration wizard provides:</p> <ul> <li>Interactive project selection with file picker support.</li> <li>Real-time migration status with detailed logs.</li> <li>Migration coverage reports showing conversion success rates.</li> <li>Automated project creation with the converted Ballerina code.</li> </ul>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#supported-businessworks-versions","title":"Supported BusinessWorks versions","text":"<p>The migration tool supports both BusinessWorks 5 and BusinessWorks 6 projects.</p>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#usage","title":"Usage","text":"<p>Follow the steps below to migrate your TIBCO BusinessWorks application using the integrated migration wizard.</p>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#step-1-prepare-your-input","title":"Step 1: Prepare your input","text":"<p>You can migrate a complete TIBCO BusinessWorks project or a standalone process file:</p> <ul> <li>For TIBCO BusinessWorks projects: Ensure your project follows the standard BusinessWorks structure</li> <li>For standalone process files: You can directly use any valid BusinessWorks process file.</li> </ul>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#step-2-launch-the-migration-wizard","title":"Step 2: Launch the migration wizard","text":"<ol> <li>Open WSO2 Integrator: BI in VS Code</li> <li> <p>Access the welcome page - If not automatically displayed, you can access it through the Command Palette (<code>Ctrl+Shift+P</code> / <code>Cmd+Shift+P</code>) and search for \"BI: Open Welcome\"</p> </li> <li> <p>Click \"Import External Integration\" in the \"Import External Integration\" section</p> </li> </ol>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#step-3-select-source-platform-and-project","title":"Step 3: Select source platform and project","text":"<ol> <li>Choose TIBCO as your source platform from the available options</li> <li>Select your project using the file picker:<ul> <li>For TIBCO BusinessWorks projects: Select the project root directory</li> <li>For standalone process files: Select the individual process file</li> </ul> </li> <li>Configure TIBCO settings if available in the wizard</li> <li>Click \"Start Migration\" to begin the conversion process</li> </ol>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#step-4-monitor-migration-progress-and-review-results","title":"Step 4: Monitor migration progress and review results","text":""},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#during-migration-real-time-progress-monitoring","title":"During Migration: Real-time Progress Monitoring","text":"<p>While the migration is ongoing, you will see:</p> <ul> <li>Real-time migration status updates</li> <li>Detailed logs of the conversion process</li> <li>Progress indication showing current migration step</li> </ul>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#after-migration-coverage-report-and-results","title":"After Migration: Coverage Report and Results","text":"<p>Once the migration process completes, the same page updates to show:</p> <ul> <li>Migration Coverage: Percentage showing successful conversion rate.</li> <li>Total code lines: Number of lines processed.</li> <li>Migratable vs Non-migratable code lines: Breakdown of conversion success.</li> <li>View Full Report: Click this button to view the detailed migration report in your browser.</li> <li>Save Report: Click this button to save the migration report to your local file system for future reference.</li> </ul>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#step-5-create-and-open-the-ballerina-project","title":"Step 5: Create and open the Ballerina project","text":"<ol> <li>Configure your integration project:<ul> <li>Enter an Integration Name.</li> <li>Specify the Package Name for the Ballerina package.</li> <li>Select Integration Path where the project will be created.</li> <li>Choose whether to create a new directory using the package name.</li> </ul> </li> <li>Click \"Create and Open Project\" to generate the Ballerina integration project with the converted code.</li> </ol>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#step-6-review-migration-output","title":"Step 6: Review migration output","text":"<p>The generated Ballerina package follows the standard Ballerina Integration (BI) file structure and includes:</p> <ul> <li>Generated Ballerina code with your converted TIBCO BusinessWorks logic.</li> <li>Configuration files (<code>Config.toml</code>, <code>Ballerina.toml</code>) for the new project.</li> <li>Organized code structure with separate files for connections, functions, types, and main logic.</li> </ul> <p>Note: The migration report is no longer automatically saved to the project directory. Instead, use the \"View Full Report\" button during the migration process to view the report, or \"Save Report\" to save it to your desired location.</p>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#step-7-review-the-migration-summary","title":"Step 7: Review the migration summary","text":"<p>The migration report provides comprehensive metrics:</p> <ol> <li>Component conversion percentage - Shows the proportion of TIBCO components successfully converted to Ballerina.</li> <li>Overall project conversion percentage \u2013 Indicates the total migration success.</li> <li>Manual work estimation - Estimated time required to review migrated code and address TODOs.</li> <li>Activities requiring manual conversion - Lists unsupported TIBCO activities.</li> </ol>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#step-8-address-the-todo-items","title":"Step 8: Address the TODO items","text":"<p>During conversion, if there are any unsupported TIBCO activities or components, they are included in the generated Ballerina code as TODO comments. You may need to do the conversion for them manually.</p>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#examples","title":"Examples","text":""},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#migrating-tibco-businessworks-5-process","title":"Migrating TIBCO BusinessWorks 5 process","text":""},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#step-1-prepare-the-migration-files","title":"Step 1: Prepare the migration files","text":"<ol> <li> <p>Create new directory named <code>tibco-hello-world</code> with following two files.</p> helloworld.process<pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;pd:ProcessDefinition xmlns:pd=\"http://xmlns.tibco.com/bw/process/2003\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\" xmlns:ns=\"http://www.tibco.com/pe/EngineTypes\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\"&gt;\n&lt;pd:name&gt;Processes/simpleResponse&lt;/pd:name&gt;\n&lt;pd:startName&gt;HTTP Receiver&lt;/pd:startName&gt;\n&lt;pd:starter name=\"HTTP Receiver\"&gt;\n&lt;pd:type&gt;com.tibco.plugin.http.HTTPEventSource&lt;/pd:type&gt;\n&lt;pd:resourceType&gt;httppalette.httpEventSource&lt;/pd:resourceType&gt;\n&lt;config&gt;\n&lt;outputMode&gt;String&lt;/outputMode&gt;\n&lt;inputOutputVersion&gt;5.3.0&lt;/inputOutputVersion&gt;\n&lt;sharedChannel&gt;GeneralConnection.sharedhttp&lt;/sharedChannel&gt;\n&lt;parsePostData&gt;true&lt;/parsePostData&gt;\n&lt;Headers/&gt;\n&lt;/config&gt;\n&lt;pd:inputBindings/&gt;\n&lt;/pd:starter&gt;\n&lt;pd:endName&gt;End&lt;/pd:endName&gt;\n&lt;pd:errorSchemas/&gt;\n&lt;pd:processVariables/&gt;\n&lt;pd:targetNamespace&gt;http://xmlns.example.com/simpleResponse&lt;/pd:targetNamespace&gt;\n&lt;pd:activity name=\"HTTP Response\"&gt;\n&lt;pd:type&gt;com.tibco.plugin.http.HTTPResponseActivity&lt;/pd:type&gt;\n&lt;pd:resourceType&gt;httppalette.httpResponseActivity&lt;/pd:resourceType&gt;\n&lt;config&gt;\n&lt;responseHeader&gt;\n&lt;header name=\"Content-Type\"&gt;text/xml; charset=UTF-8&lt;/header&gt;\n&lt;/responseHeader&gt;\n&lt;httpResponseCode&gt;200&lt;/httpResponseCode&gt;\n&lt;/config&gt;\n&lt;pd:inputBindings&gt;\n&lt;ResponseActivityInput&gt;\n&lt;asciiContent&gt;\n&lt;response&gt;hello world&lt;/response&gt;\n&lt;/asciiContent&gt;\n&lt;/ResponseActivityInput&gt;\n&lt;/pd:inputBindings&gt;\n&lt;/pd:activity&gt;\n\n&lt;pd:transition&gt;\n&lt;pd:from&gt;HTTP Receiver&lt;/pd:from&gt;\n&lt;pd:to&gt;HTTP Response&lt;/pd:to&gt;\n&lt;pd:lineType&gt;Default&lt;/pd:lineType&gt;\n&lt;/pd:transition&gt;\n\n&lt;pd:transition&gt;\n&lt;pd:from&gt;HTTP Response&lt;/pd:from&gt;\n&lt;pd:to&gt;End&lt;/pd:to&gt;\n&lt;pd:lineType&gt;Default&lt;/pd:lineType&gt;\n&lt;/pd:transition&gt;\n&lt;/pd:ProcessDefinition&gt;\n</code></pre> GeneralConnection.sharedhttp<pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;ns0:httpSharedResource xmlns:ns0=\"www.tibco.com/shared/HTTPConnection\"&gt;\n&lt;config&gt;\n&lt;Host&gt;localhost&lt;/Host&gt;\n&lt;Port&gt;9090&lt;/Port&gt;\n&lt;/config&gt;\n&lt;/ns0:httpSharedResource&gt;\n</code></pre> </li> </ol>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#step-2-run-the-migration-wizard","title":"Step 2: Run the migration wizard","text":"<ol> <li>Open WSO2 Integrator: BI in VS Code.</li> <li>Click \"Import External Integration\" on the welcome page.</li> <li>Select \"TIBCO\" as the source platform.</li> <li>Use the file picker to select the <code>tibco-hello-world</code> project directory.</li> <li>Click \"Start Migration\" to begin the conversion process.</li> <li>Configure your integration project details and click \"Create and Open Project\".</li> </ol>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#step-3-review-the-generated-code","title":"Step 3: Review the generated code","text":"<p>The migration wizard will create a new Ballerina project with the converted code, which you can immediately start working with in the BI interface.</p>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#migrating-tibco-businessworks-6-process","title":"Migrating TIBCO BusinessWorks 6 process","text":""},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#step-1-prepare-the-migration-files_1","title":"Step 1: Prepare the migration files","text":"<ol> <li> <p>Create new directory named <code>tibco-hello-world</code> with following process file.</p> main.bwp<pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;bpws:process exitOnStandardFault=\"no\"\nname=\"test.api.MainProcess\" suppressJoinFailure=\"yes\"\ntargetNamespace=\"http://xmlns.example.com/test/api\"\nxmlns:bpws=\"http://docs.oasis-open.org/wsbpel/2.0/process/executable\"\nxmlns:info=\"http://www.tibco.com/bw/process/info\"\nxmlns:ns=\"http://www.tibco.com/pe/EngineTypes\"\nxmlns:ns0=\"http://xmlns.example.com/test/api/wsdl\"\nxmlns:ns1=\"http://xmlns.example.com/test/api\"\nxmlns:sca=\"http://docs.oasis-open.org/ns/opencsa/sca/200912\"\nxmlns:sca-bpel=\"http://docs.oasis-open.org/ns/opencsa/sca-bpel/200801\"\nxmlns:tibex=\"http://www.tibco.com/bpel/2007/extensions\"\nxmlns:tibprop=\"http://ns.tibco.com/bw/property\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\"&gt;\n&lt;tibex:Types&gt;\n&lt;xs:schema attributeFormDefault=\"unqualified\"\nelementFormDefault=\"qualified\"\ntargetNamespace=\"http://www.tibco.com/pe/EngineTypes\"\nxmlns:tns=\"http://www.tibco.com/pe/EngineTypes\" xmlns:xs=\"http://www.w3.org/2001/XMLSchema\"&gt;\n&lt;xs:complexType block=\"extension restriction\"\nfinal=\"extension restriction\" name=\"ProcessContext\"&gt;\n&lt;xs:sequence&gt;\n&lt;xs:element\nblock=\"extension restriction substitution\"\nform=\"unqualified\" name=\"JobId\" type=\"xs:string\"/&gt;\n&lt;xs:element\nblock=\"extension restriction substitution\"\nform=\"unqualified\" name=\"ApplicationName\" type=\"xs:string\"/&gt;\n&lt;xs:element\nblock=\"extension restriction substitution\"\nform=\"unqualified\" name=\"EngineName\" type=\"xs:string\"/&gt;\n&lt;xs:element\nblock=\"extension restriction substitution\"\nform=\"unqualified\" name=\"ProcessInstanceId\" type=\"xs:string\"/&gt;\n&lt;xs:element\nblock=\"extension restriction substitution\"\nform=\"unqualified\" minOccurs=\"0\"\nname=\"CustomJobId\" type=\"xs:string\"/&gt;\n&lt;xs:element\nblock=\"extension restriction substitution\"\nform=\"unqualified\" maxOccurs=\"unbounded\"\nminOccurs=\"0\" name=\"TrackingInfo\" type=\"xs:string\"/&gt;\n&lt;/xs:sequence&gt;\n&lt;/xs:complexType&gt;\n&lt;xs:element block=\"extension restriction substitution\"\nfinal=\"extension restriction\" name=\"ProcessContext\" type=\"tns:ProcessContext\"/&gt;\n&lt;/xs:schema&gt;\n&lt;xs:schema attributeFormDefault=\"unqualified\"\nelementFormDefault=\"qualified\"\ntargetNamespace=\"http://xmlns.example.com/test/api\"\nxmlns:tns=\"http://xmlns.example.com/test/api\" xmlns:xs=\"http://www.w3.org/2001/XMLSchema\"&gt;\n&lt;xs:complexType name=\"TestRequestType\"&gt;\n&lt;xs:sequence&gt;\n&lt;xs:element name=\"request\" type=\"xs:string\"/&gt;\n&lt;/xs:sequence&gt;\n&lt;/xs:complexType&gt;\n&lt;xs:complexType name=\"TestResponseType\"&gt;\n&lt;xs:sequence&gt;\n&lt;xs:element name=\"response\" type=\"xs:string\"/&gt;\n&lt;/xs:sequence&gt;\n&lt;/xs:complexType&gt;\n&lt;xs:element name=\"TestRequest\" type=\"tns:TestRequestType\"/&gt;\n&lt;xs:element name=\"TestResponse\" type=\"tns:TestResponseType\"/&gt;\n&lt;/xs:schema&gt;\n&lt;wsdl:definitions\ntargetNamespace=\"http://xmlns.example.com/test/api/wsdl\"\nxmlns:extns=\"http://tns.tibco.com/bw/REST\"\nxmlns:extns1=\"http://xmlns.example.com/test/api\"\nxmlns:plnk=\"http://docs.oasis-open.org/wsbpel/2.0/plnktype\"\nxmlns:tibex=\"http://www.tibco.com/bpel/2007/extensions\"\nxmlns:tns=\"http://xmlns.example.com/test/api/wsdl\"\nxmlns:vprop=\"http://docs.oasis-open.org/wsbpel/2.0/varprop\"\nxmlns:wsdl=\"http://schemas.xmlsoap.org/wsdl/\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\"&gt;\n&lt;plnk:partnerLinkType name=\"partnerLinkType\"&gt;\n&lt;plnk:role name=\"use\" portType=\"tns:testapi\"/&gt;\n&lt;/plnk:partnerLinkType&gt;\n&lt;wsdl:import namespace=\"http://tns.tibco.com/bw/REST\"/&gt;\n&lt;wsdl:import namespace=\"http://xmlns.example.com/test/api\"/&gt;\n&lt;wsdl:message name=\"postRequest\"&gt;\n&lt;wsdl:part element=\"extns1:TestRequest\"\nname=\"item\" tibex:hasMultipleNamespaces=\"false\"/&gt;\n&lt;wsdl:part element=\"extns:httpHeaders\"\nname=\"httpHeaders\" tibex:source=\"bw.rest\"/&gt;\n&lt;/wsdl:message&gt;\n&lt;wsdl:message name=\"postResponse\"&gt;\n&lt;wsdl:part element=\"extns1:TestResponse\"\nname=\"item\" tibex:hasMultipleNamespaces=\"false\"/&gt;\n&lt;/wsdl:message&gt;\n&lt;wsdl:message name=\"post4XXFaultMessage\"&gt;\n&lt;wsdl:part element=\"extns:client4XXError\" name=\"clientError\"/&gt;\n&lt;/wsdl:message&gt;\n&lt;wsdl:message name=\"post5XXFaultMessage\"&gt;\n&lt;wsdl:part element=\"extns:server5XXError\" name=\"serverError\"/&gt;\n&lt;/wsdl:message&gt;\n&lt;wsdl:portType name=\"testapi\"\ntibex:bw.rest.apipath=\"/test\"\ntibex:bw.rest.basepath=\"TestAPI\"\ntibex:bw.rest.resource=\"Service Descriptors/test.api.MainProcess-TestAPI.json\"\ntibex:bw.rest.resource.source=\"generated\" tibex:source=\"bw.rest.service\"&gt;\n&lt;wsdl:documentation&gt;Simple REST API with test endpoint.&lt;/wsdl:documentation&gt;\n&lt;wsdl:operation name=\"post\"&gt;\n&lt;wsdl:input message=\"tns:postRequest\" name=\"postInput\"/&gt;\n&lt;wsdl:output message=\"tns:postResponse\" name=\"postOutput\"/&gt;\n&lt;wsdl:fault message=\"tns:post4XXFaultMessage\" name=\"clientFault\"/&gt;\n&lt;wsdl:fault message=\"tns:post5XXFaultMessage\" name=\"serverFault\"/&gt;\n&lt;/wsdl:operation&gt;\n&lt;/wsdl:portType&gt;\n&lt;/wsdl:definitions&gt;\n&lt;/tibex:Types&gt;\n&lt;tibex:ProcessInfo callable=\"false\" createdBy=\"heshan\"\ncreatedOn=\"Mon Dec 16 00:00:00 PST 2024\" description=\"\"\nextraErrorVars=\"true\" modifiers=\"public\"\nproductVersion=\"6.5.0 V63 2018-08-08\" scalable=\"true\"\nsingleton=\"true\" stateless=\"true\" type=\"IT\"/&gt;\n&lt;tibex:ProcessInterface context=\"\" input=\"\" output=\"\"/&gt;\n&lt;tibex:ProcessTemplateConfigurations/&gt;\n&lt;tibex:NamespaceRegistry enabled=\"true\"&gt;\n&lt;tibex:namespaceItem\nnamespace=\"http://xmlns.example.com/test/api\" prefix=\"tns\"/&gt;\n&lt;tibex:namespaceItem\nnamespace=\"http://xmlns.example.com/test/api/wsdl\" prefix=\"tns1\"/&gt;\n&lt;/tibex:NamespaceRegistry&gt;\n&lt;bpws:import importType=\"http://www.w3.org/2001/XMLSchema\" namespace=\"http://tns.tibco.com/bw/REST\"/&gt;\n&lt;bpws:import importType=\"http://www.w3.org/2001/XMLSchema\" namespace=\"http://xmlns.example.com/test/api\"/&gt;\n&lt;bpws:partnerLinks&gt;\n&lt;bpws:partnerLink myRole=\"use\" name=\"testapi\"\npartnerLinkType=\"ns0:partnerLinkType\"\nsca-bpel:ignore=\"false\" sca-bpel:service=\"testapi\"/&gt;\n&lt;/bpws:partnerLinks&gt;\n&lt;bpws:variables&gt;\n&lt;bpws:variable element=\"ns:ProcessContext\"\nname=\"_processContext\" sca-bpel:internal=\"true\"/&gt;\n&lt;bpws:variable messageType=\"ns0:postRequest\" name=\"post\" sca-bpel:internal=\"true\"/&gt;\n&lt;bpws:variable messageType=\"ns0:postResponse\"\nname=\"postOut-input\" sca-bpel:internal=\"true\"/&gt;\n&lt;bpws:variable element=\"ns1:TestResponse\" name=\"RenderOutput-output\" sca-bpel:internal=\"true\"/&gt;\n&lt;/bpws:variables&gt;\n&lt;bpws:extensions&gt;\n&lt;bpws:extension mustUnderstand=\"no\" namespace=\"http://www.eclipse.org/gmf/runtime/1.0.2/notation\"/&gt;\n&lt;bpws:extension mustUnderstand=\"no\" namespace=\"http://www.tibco.com/bw/process/info\"/&gt;\n&lt;bpws:extension mustUnderstand=\"no\" namespace=\"http://docs.oasis-open.org/ns/opencsa/sca-bpel/200801\"/&gt;\n&lt;bpws:extension mustUnderstand=\"no\" namespace=\"http://docs.oasis-open.org/ns/opencsa/sca/200912\"/&gt;\n&lt;bpws:extension mustUnderstand=\"no\" namespace=\"http://ns.tibco.com/bw/property\"/&gt;\n&lt;bpws:extension mustUnderstand=\"no\" namespace=\"http://www.tibco.com/bpel/2007/extensions\"/&gt;\n&lt;/bpws:extensions&gt;\n&lt;bpws:scope name=\"scope\"&gt;\n&lt;bpws:flow name=\"flow\"&gt;\n&lt;bpws:links/&gt;\n&lt;bpws:pick createInstance=\"yes\" name=\"pick\"&gt;\n&lt;bpws:onMessage operation=\"post\"\npartnerLink=\"testapi\"\nportType=\"ns0:testapi\"\nvariable=\"post\"&gt;\n&lt;bpws:scope name=\"scope1\"&gt;\n&lt;bpws:flow name=\"flow1\"&gt;\n&lt;bpws:links&gt;\n&lt;bpws:link name=\"JSONPayloadOut\" tibex:linkType=\"SUCCESS\"/&gt;\n&lt;/bpws:links&gt;\n&lt;bpws:extensionActivity&gt;\n&lt;tibex:activityExtension name=\"RenderOutput\" outputVariable=\"RenderOutput\"\nxmlns:tibex=\"http://www.tibco.com/bpel/2007/extensions\"&gt;\n&lt;bpws:targets/&gt;\n&lt;bpws:sources&gt;\n&lt;bpws:source linkName=\"JSONPayloadOut\"/&gt;\n&lt;/bpws:sources&gt;\n&lt;tibex:inputBindings&gt;\n&lt;tibex:inputBinding expression=\"&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&gt;&amp;#xa;&amp;lt;xsl:stylesheet xmlns:xsl=&amp;quot;http://www.w3.org/1999/XSL/Transform&amp;quot; xmlns:tns=&amp;quot;http://xmlns.example.com/test/api&amp;quot; version=&amp;quot;2.0&amp;quot;&gt;&amp;#xa;    &amp;lt;xsl:template name=&amp;quot;RenderOutput-input&amp;quot; match=&amp;quot;/&amp;quot;&gt;&amp;#xa;        &amp;lt;tns:TestResponse&gt;&amp;#xa;            &amp;lt;tns:response&gt;Hello world&amp;lt;/tns:response&gt;&amp;#xa;        &amp;lt;/tns:TestResponse&gt;&amp;#xa;    &amp;lt;/xsl:template&gt;&amp;#xa;&amp;lt;/xsl:stylesheet&gt;\" expressionLanguage=\"urn:oasis:names:tc:wsbpel:2.0:sublang:xslt1.0\"/&gt;\n&lt;/tibex:inputBindings&gt;\n&lt;tibex:config&gt;\n&lt;bwext:BWActivity activityTypeID=\"bw.restjson.JsonRender\"\nxmlns:activityconfig=\"http://tns.tibco.com/bw/model/activityconfig\"\nxmlns:bwext=\"http://tns.tibco.com/bw/model/core/bwext\"\nxmlns:restjson=\"http://ns.tibco.com/bw/palette/restjson\"\nxmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt;\n&lt;activityConfig&gt;\n&lt;properties name=\"config\" xsi:type=\"activityconfig:EMFProperty\"&gt;\n&lt;type href=\"http://ns.tibco.com/bw/palette/restjson#//JsonRender\"/&gt;\n&lt;value jsonOutputStyle=\"None\" schemaType=\"Xsd\" xsi:type=\"restjson:JsonRender\"&gt;\n&lt;inputEditorElement href=\"Schema.xsd#//TestResponse;XSDElementDeclaration\"/&gt;\n&lt;/value&gt;\n&lt;/properties&gt;\n&lt;/activityConfig&gt;\n&lt;/bwext:BWActivity&gt;\n&lt;/tibex:config&gt;\n&lt;/tibex:activityExtension&gt;\n&lt;/bpws:extensionActivity&gt;\n&lt;bpws:extensionActivity&gt;\n&lt;tibex:activityExtension\ninputVariable=\"RenderOutput\"\nname=\"SendHTTPResponse\"\nxmlns:tibex=\"http://www.tibco.com/bpel/2007/extensions\"&gt;\n&lt;bpws:targets&gt;\n&lt;bpws:target linkName=\"JSONPayloadOut\"/&gt;\n&lt;/bpws:targets&gt;\n&lt;tibex:inputBindings&gt;\n&lt;tibex:inputBinding\nexpression=\"&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&gt;&amp;#xa;&amp;lt;xsl:stylesheet xmlns:xsl=&amp;quot;http://www.w3.org/1999/XSL/Transform&amp;quot; xmlns:tns1=&amp;quot;http://tns.tibco.com/bw/activity/sendhttpresponse/xsd/input+3847aa9b-8275-4b15-9ea8-812816768fa4+ResponseActivityInput&amp;quot; version=&amp;quot;2.0&amp;quot;&gt;&amp;#xa;    &amp;lt;xsl:template name=&amp;quot;SendHTTPResponse-input&amp;quot; match=&amp;quot;/&amp;quot;&gt;&amp;#xa;        &amp;lt;tns1:ResponseActivityInput&gt;&amp;#xa;            &amp;lt;asciiContent&gt;&amp;#xa;                &amp;lt;xsl:value-of select=&amp;quot;/jsonString&amp;quot;/&gt;&amp;#xa;            &amp;lt;/asciiContent&gt;&amp;#xa;            &amp;lt;Headers&gt;&amp;#xa;                &amp;lt;Content-Type&gt;&amp;#xa;                    &amp;lt;xsl:value-of select=&amp;quot;&amp;amp;quot;application/json&amp;amp;quot;&amp;quot;/&gt;&amp;#xa;                &amp;lt;/Content-Type&gt;&amp;#xa;            &amp;lt;/Headers&gt;&amp;#xa;        &amp;lt;/tns1:ResponseActivityInput&gt;&amp;#xa;    &amp;lt;/xsl:template&gt;&amp;#xa;&amp;lt;/xsl:stylesheet&gt;\"\nexpressionLanguage=\"urn:oasis:names:tc:wsbpel:2.0:sublang:xslt1.0\"/&gt;\n&lt;/tibex:inputBindings&gt;\n&lt;tibex:config&gt;\n&lt;bwext:BWActivity\nactivityTypeID=\"bw.http.sendHTTPResponse\"\nversion=\"6.0.0.20132205\"\nxmlns:ResponseActivityInput=\"http://tns.tibco.com/bw/activity/sendhttpresponse/xsd/input+3847aa9b-8275-4b15-9ea8-812816768fa4+ResponseActivityInput\"\nxmlns:activityconfig=\"http://tns.tibco.com/bw/model/activityconfig\"\nxmlns:bwext=\"http://tns.tibco.com/bw/model/core/bwext\"\nxmlns:http=\"http://ns.tibco.com/bw/palette/http\"\nxmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt;\n&lt;activityConfig&gt;\n&lt;properties name=\"config\" xsi:type=\"activityconfig:EMFProperty\"&gt;\n&lt;type href=\"http://ns.tibco.com/bw/palette/http#//SendHTTPResponse\"/&gt;\n&lt;value closeConnection=\"true\"\ninputHeadersQName=\"ResponseActivityInput:headersType\"\nreplyFor=\"HTTPReceiver\" xsi:type=\"http:SendHTTPResponse\"/&gt;\n&lt;/properties&gt;\n&lt;/activityConfig&gt;\n&lt;/bwext:BWActivity&gt;\n&lt;/tibex:config&gt;\n&lt;/tibex:activityExtension&gt;\n&lt;/bpws:extensionActivity&gt;\n&lt;/bpws:flow&gt;\n&lt;/bpws:scope&gt;\n&lt;/bpws:onMessage&gt;\n&lt;/bpws:pick&gt;\n&lt;/bpws:flow&gt;\n&lt;/bpws:scope&gt;\n&lt;/bpws:process&gt;\n</code></pre> </li> </ol>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#step-2-run-the-migration-wizard_1","title":"Step 2: Run the migration wizard","text":"<ol> <li>Open WSO2 Integrator: BI in VS Code.</li> <li>Click \"Import External Integration\" on the welcome page.</li> <li>Select \"TIBCO\" as the source platform.</li> <li>Use the file picker to select the <code>tibco-hello-world</code> project directory.</li> <li>Click \"Start Migration\" to begin the conversion process.</li> <li>Configure your integration project details and click \"Create and Open Project\".</li> </ol>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#step-3-review-the-generated-code_1","title":"Step 3: Review the generated code","text":"<p>The migration wizard will create a new Ballerina project with the converted code, which you can immediately start working with in the BI interface.</p>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#limitations","title":"Limitations","text":"<ul> <li>Multi-project migration is not currently supported through the VS Code extension UI. For batch migration of multiple TIBCO projects, use the CLI tool migrate-tibco separately.</li> <li>Tool generates code assuming target compiler version is 2201.12.0 or later.</li> </ul>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#unhandled-activities","title":"Unhandled activities","text":"<ul> <li> <p>If the tool encounters any activity which it does not know how to convert it will generate a placeholder \"unhandled\" function with a comment containing the relevant part of the process file.</p> <pre><code>function unhandled(map&lt;xml&gt; context) returns xml|error {\n    //FIXME: [ParseError] : Unknown activity\n    //&lt;bpws:empty name=\"OnMessageStart\" xmlns:tibex=\"http://www.tibco.com/bpel/2007/extensions\" tibex:constructor=\"onMessageStart\" tibex:xpdlId=\"c266c167-7a80-40cc-9db2-60739386deeb\" xmlns:bpws=\"http://docs.oasis-open.org/wsbpel/2.0/process/executable\"/&gt;\n\n    //&lt;bpws:empty name=\"OnMessageStart\" xmlns:tibex=\"http://www.tibco.com/bpel/2007/extensions\" tibex:constructor=\"onMessageStart\" tibex:xpdlId=\"c266c167-7a80-40cc-9db2-60739386deeb\" xmlns:bpws=\"http://docs.oasis-open.org/wsbpel/2.0/process/executable\"/&gt;\n    return xml `&lt;root&gt;&lt;/root&gt;`;\n}\n</code></pre> </li> </ul>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#partially-supported-activities","title":"Partially supported activities","text":"<ul> <li> <p>In case of activities that are only partially supported you will see a log message with the activity name.     <pre><code>WARNING: Partially supported activity: JMS Send\n</code></pre></p> </li> <li> <p>They will also be listed in the report under heading \"Activities that need manual validation\". For most typical use cases, you can use the converted source as is, but we highly encourage users to check the converted code. There will be comments explaining any limitations/assumptions the tool has made.     <pre><code>    // WARNING: using default destination configuration\n    jms:MessageProducer var4 = check var3.createProducer(destination = {\n        'type: jms:TOPIC,\n        name: \"TOPIC\"\n    });\n</code></pre></p> </li> </ul>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#supported-tibco-businessworks-activities","title":"Supported TIBCO BusinessWorks activities","text":"<ul> <li><code>invoke</code></li> <li><code>pick</code></li> <li><code>empty</code></li> <li><code>reply</code></li> <li><code>throw</code></li> <li><code>assign</code></li> <li><code>forEach</code></li> <li><code>extensionActivity</code></li> <li><code>receiveEvent</code></li> <li><code>activityExtension</code><ul> <li><code>bw.internal.end</code></li> <li><code>bw.http.sendHTTPRequest</code></li> <li><code>bw.restjson.JsonRender</code></li> <li><code>bw.restjson.JsonParser</code></li> <li><code>bw.http.sendHTTPResponse</code></li> <li><code>bw.file.write</code></li> <li><code>bw.generalactivities.log</code></li> <li><code>bw.xml.renderxml</code></li> <li><code>bw.generalactivities.mapper</code></li> <li><code>bw.internal.accumulateend</code></li> </ul> </li> <li><code>extActivity</code></li> <li><code>com.tibco.plugin.mapper.MapperActivity</code></li> <li><code>com.tibco.plugin.http.HTTPEventSource</code></li> <li><code>com.tibco.pe.core.AssignActivity</code></li> <li><code>com.tibco.plugin.http.HTTPResponseActivity</code></li> <li><code>com.tibco.plugin.xml.XMLRendererActivity</code></li> <li><code>com.tibco.plugin.xml.XMLParseActivity</code></li> <li><code>com.tibco.pe.core.LoopGroup</code></li> <li><code>com.tibco.pe.core.WriteToLogActivity</code></li> <li><code>com.tibco.pe.core.CatchActivity</code></li> <li><code>com.tibco.plugin.file.FileReadActivity</code></li> <li><code>com.tibco.plugin.file.FileWriteActivity</code></li> <li><code>com.tibco.plugin.jdbc.JDBCGeneralActivity</code></li> <li><code>com.tibco.plugin.json.activities.RestActivity</code></li> <li><code>com.tibco.pe.core.CallProcessActivity</code></li> <li><code>com.tibco.plugin.soap.SOAPSendReceiveActivity</code></li> <li><code>com.tibco.plugin.json.activities.JSONParserActivity</code></li> <li><code>com.tibco.plugin.json.activities.JSONRenderActivity</code></li> <li><code>com.tibco.plugin.soap.SOAPSendReplyActivity</code></li> <li><code>com.tibco.plugin.jms.JMSQueueEventSource</code></li> <li><code>com.tibco.plugin.jms.JMSQueueSendActivity</code></li> <li><code>com.tibco.plugin.jms.JMSQueueGetMessageActivity</code></li> <li><code>com.tibco.plugin.jms.JMSTopicPublishActivity</code></li> <li><code>com.tibco.pe.core.GenerateErrorActivity</code></li> <li><code>com.tibco.plugin.timer.NullActivity</code></li> <li><code>com.tibco.plugin.timer.SleepActivity</code></li> <li><code>com.tibco.pe.core.GetSharedVariableActivity</code></li> <li><code>com.tibco.pe.core.SetSharedVariableActivity</code></li> <li><code>com.tibco.plugin.file.FileEventSource</code></li> <li><code>com.tibco.pe.core.OnStartupEventSource</code></li> <li><code>com.tibco.plugin.file.ListFilesActivity</code></li> <li><code>com.tibco.plugin.xml.XMLTransformActivity</code></li> </ul> Disclaimer<p>TIBCO: \"TIBCO\", \u201cTIBCO BusinessWorks\u201d, and \u201cTIBCO Flogo\u201d are trademarks, or registered trademarks, of TIBCO Software Inc. a business unit of Cloud Software Group. All product, company names and marks mentioned herein are the property of their respective owners and are mentioned for identification purposes only.</p>"},{"location":"developer-guides/tools/other-tools/scan-tool/","title":"Scan Tool","text":"<p>The scan tool is a static code analysis tool that performs analysis on BI projects and identifies potential code smells, bugs, and vulnerabilities without executing them.</p> Note<p>Ballerina scan is an experimental feature that supports only a limited set of rules.</p>"},{"location":"developer-guides/tools/other-tools/scan-tool/#install-the-tool","title":"Install the tool","text":"<p>Execute the command below to pull the scan tool from Ballerina Central.</p> <pre><code>$ bal tool pull scan\n</code></pre> <p>To learn more about managing Ballerina tools, refer to the Ballerina CLI tool command documentation.</p>"},{"location":"developer-guides/tools/other-tools/scan-tool/#usage-guide-for-the-scan-tool","title":"Usage guide for the scan tool","text":"<p>The scan tool helps you analyze your BI project for potential issues, enforce coding standards, and generate detailed reports. </p> <p>The scan tool supports several command-line options as follows.</p> <pre><code>$ bal scan [--target-dir] &lt;target-dir&gt;\n        [--scan-report] [--list-rules]\n[--include-rules] &lt;id(s)-of-rule(s)-to-include&gt;\n        [--exclude-rules] &lt;id(s)-of-rule(s)-to-exclude&gt;\n        [--platforms] &lt;platform(s)-to-report-results&gt;\n</code></pre> <p>Below are various ways you can use the tool to fit your development workflow.</p>"},{"location":"developer-guides/tools/other-tools/scan-tool/#scan-a-bi-project","title":"Scan a BI project","text":"<p>To run a full analysis across all Ballerina files in your BI project, use the following command in terminal.</p> <pre><code>$ bal scan --scan-report\n</code></pre> <p>This will produce the HTML report and scan results inside the <code>target/report</code> directory.</p> <p>The report includes a summary of the number of code smells, bugs, and vulnerabilities found in each file.</p> <p></p> <p>To investigate further, you can click on a file name to view a detailed breakdown of the issues. This view highlights the exact lines where problems were detected, along with a description, and the severity level.</p> <p></p>"},{"location":"developer-guides/tools/other-tools/scan-tool/#list-all-available-analysis-rules","title":"List all available analysis rules","text":"<p>If you\u2019d like to explore the full set of rules the tool can apply, run:</p> <pre><code>$ bal scan --list-rules\n</code></pre> <p>This will display a comprehensive list of available rules for your project, which you can include or exclude in future scans.</p> <p>The output will look something like this:</p> <p></p> Note<p>The list of displayed rules is specific to the current BI project and is determined based on its dependencies.</p>"},{"location":"developer-guides/tools/other-tools/scan-tool/#run-analysis-for-specific-rules","title":"Run analysis for specific rules","text":"<p>If you want to apply a specific set of rules, list them as a comma-separated string by specifying the rule ID:</p> <pre><code>$ bal scan --include-rules=\"ballerina:1, ballerina/io:2\"\n</code></pre> <p>To ignore a specific set of rules during the analysis, use the following command:</p> <pre><code>$ bal scan --exclude-rules=\"ballerina:1, ballerina/io:2\"\n</code></pre>"},{"location":"developer-guides/tools/other-tools/scan-tool/#publishing-static-code-analysis-reports-to-sonarqube","title":"Publishing static code analysis reports to SonarQube.","text":"<p>To learn how to publish reports to SonarQube, refer to Configuration for Platform Plugins.</p>"},{"location":"get-started/develop-ai-agent/","title":"Develop AI Agent","text":""},{"location":"get-started/develop-ai-agent/#overview","title":"Overview","text":"<p>In this guide, you will: Create a simple AI agent that provides personal assistance. We will define a GraphQL schema with a query that invokes the inline agent to generate dynamic responses based on input parameters. The agent runs within the resolver logic and returns results directly as part of the GraphQL response.</p>"},{"location":"get-started/develop-ai-agent/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, make sure you have the following:</p> <ul> <li>Visual Studio Code: Install Visual Studio Code if you don't have it already.</li> <li>WSO2 Integrator: BI Extension: Install the WSO2 Integrator: BI extension. Refer to Install WSO2 Integrator: BI for detailed instructions.</li> <li>Get OpenAI key:<ol> <li>Sign up at OpenAI.</li> <li>Get an API key from the API section.</li> </ol> </li> </ul>"},{"location":"get-started/develop-ai-agent/#step-1-create-a-new-integration-project","title":"Step 1: Create a new integration project","text":"<ol> <li>Click on the BI icon in the sidebar.</li> <li>Click on the Create New Integration button.</li> <li>Enter the project name as <code>GraphqlService</code>.</li> <li>Select the project directory by clicking on the Select Location button.</li> <li> <p>Click the Create New Integration button to generate the integration project.</p> <p></p> </li> </ol>"},{"location":"get-started/develop-ai-agent/#step-2-create-a-graphql-service","title":"Step 2: Create a GraphQL service","text":"<ol> <li>Click the + button on the WSO2 Integrator: BI side panel or navigate back to the design screen and click on Add Artifact.</li> <li>Select GraphQL Service under the Integration as API artifacts.</li> <li> <p>Keep the default Listener and Service base path configurations, and click Create.</p> <p></p> </li> </ol>"},{"location":"get-started/develop-ai-agent/#step-3-create-a-graphql-resolver","title":"Step 3: Create a GraphQL resolver","text":"<ol> <li>Click the + Create Operations button in the GraphQL design view.</li> <li>In the side panel, click the + button in the Mutation section to add a mutation operation.</li> <li>Provide <code>task</code> as the value for the Field name.</li> <li>Click the Add Argument button to add a GraphQL input<ul> <li>Provide <code>query</code> for the Argument name.</li> <li>Provide <code>string</code> for the Argument type.</li> <li>Click Add to save the argument.</li> </ul> </li> <li> <p>Provide <code>string|error</code> for the Field type, as this will be used as the return type of the resolver.</p> <p></p> </li> </ol>"},{"location":"get-started/develop-ai-agent/#step-4-implement-the-resolving-logic-with-an-inline-agent","title":"Step 4: Implement the resolving logic with an inline agent","text":"<ol> <li>Click the created <code>task</code> operation in the side panel to navigate to the resolver editor view.</li> <li>Click the + button in the flow to open the side panel.</li> <li>Click Agent under Statement, which will navigate you to the agent creation panel.</li> <li>Update Variable Name to <code>response</code>. This is the variable where the agent's output will be stored.</li> <li>Update the Role and Instructions to configure the agent\u2019s behavior.</li> <li>Provide the query parameter as the input for Query. This will serve as the command that the agent will execute.</li> <li>Click Save.</li> <li>Next, configure the agent\u2019s memory, model, and tools. For guidance, refer to the Chat Agent configuration steps and the Personal Assistant setup guide to make the agent function as a personal assistant.</li> <li>After configuring the agent, click the + button on the flow and select Return under Control from the side panel.</li> <li> <p>For the Expression, provide the <code>response</code> variable as the input.</p> <p></p> </li> </ol> <p>At this point, we've created a GraphQL resolver that takes a user-provided <code>query</code> as input, passes it to an inline agent for processing, and returns the agent\u2019s <code>response</code> as the result of the resolver.</p> <p>Note</p> <p>You must implement a query operation to have a valid GraphQL service. Similar to creating the <code>task</code> operation in Step 3, add an operation named <code>greet</code> by pressing the + button in the Query section, without any input parameters. For the implementation, you can simply return a string literal saying <code>\"welcome\"</code>.</p>"},{"location":"get-started/develop-ai-agent/#step-5-run-the-integration-and-query-the-agent","title":"Step 5: Run the integration and query the agent","text":"<ol> <li>Click on the Run button in the top-right corner to run the integration.</li> <li> <p>Query the agent by sending the mutation request below.     <pre><code>curl -X POST http://localhost:8080/graphql \\\n-H \"Content-Type: application/json\" \\\n-d '{ \"query\": \"mutation Task { task(query: \\\"Summarize latest emails\\\") }\" }'\n</code></pre></p> <p></p> </li> </ol>"},{"location":"get-started/develop-automation/","title":"Develop Automation","text":""},{"location":"get-started/develop-automation/#overview","title":"Overview","text":"<p>In this guide, you will create a simple automation that prints <code>\"Hello World\"</code>.</p>"},{"location":"get-started/develop-automation/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, make sure you have the following:</p> <ul> <li>Visual Studio Code: Install Visual Studio Code if you don't have it already.</li> <li>WSO2 Integrator: BI Extension: Install the WSO2 Integrator: BI extension. Refer to Install WSO2 Integrator: BI for detailed instructions.</li> </ul>"},{"location":"get-started/develop-automation/#step-1-develop-automation-in-wso2-integrator-bi","title":"Step 1: Develop automation in WSO2 Integrator: BI","text":"<ol> <li>In WSO2 Integrator: BI design view, click Add Artifact.</li> <li>Select Automation from the Constructs menu.</li> <li>Click Create to create an automation. This directs you to the automation diagram view.</li> <li>Click + after the Start node to open the node panel.</li> <li>Select Call Function and select println.</li> <li>Click + Add Another Value, type <code>\"Hello World\"</code> and click Save.</li> </ol>"},{"location":"get-started/develop-automation/#step-2-run-automation-in-wso2-integrator-bi","title":"Step 2: Run automation in WSO2 Integrator: BI","text":"<ol> <li> <p>Click Run in the top right corner to run the automation. This compiles the automation and runs it in the embedded Ballerina runtime.</p> <p></p> </li> </ol>"},{"location":"get-started/develop-event-integration/","title":"Develop Event Integration","text":""},{"location":"get-started/develop-event-integration/#overview","title":"Overview","text":"<p>In this guide, you will build a simple event integration that monitors RabbitMQ for new messages and displays them once they become available.</p>"},{"location":"get-started/develop-event-integration/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, make sure you have the following:</p> <ul> <li>Visual Studio Code: Install Visual Studio Code if you don't have it already.</li> <li>WSO2 Integrator: BI Extension: Install the WSO2 Integrator: BI extension. Refer to Install WSO2 Integrator: BI for detailed instructions.</li> <li>Set up RabbitMQ:<ol> <li>Use an existing RabbitMQ instance or start a new RabbitMQ instance on a server that can be accessed via the internet.</li> <li>Obtain the <code>host</code>, <code>port</code>, <code>username</code>, and <code>password</code> from the RabbitMQ instance.</li> </ol> </li> </ul>"},{"location":"get-started/develop-event-integration/#step-1-develop-event-integration-in-wso2-integrator-bi","title":"Step 1: Develop Event Integration in WSO2 Integrator: BI","text":"<ol> <li>In WSO2 Integrator: BI design view, click Add Artifact.</li> <li>Select Event Integration from the Constructs menu.</li> <li>Click Create to create an event integration. This directs you to the event integration diagram view.</li> <li> <p>Go to the Design View by clicking the Home icon in the top left corner, click on the Configure button, and add the following configurables.</p> Configurable Type <code>host</code> <code>string</code> <code>port</code> <code>int</code> <code>username</code> <code>string</code> <code>password</code> <code>string</code> <p></p> </li> <li> <p>Go to the Design View by clicking the Home icon on the top left corner and click Add Artifact.</p> </li> <li>Select RabbitMQ Event Handler. Choosing the Event Integration from the Devant console disables the other options.</li> <li>Provide the name of the RabbitMQ Configuration as <code>eventListener</code>.</li> <li>Select previously defined <code>host</code> and <code>port</code> configuration variables for the Host and Port.</li> <li> <p>Then, expand the Advanced Configurations and enter the following configurables. Then click Next.</p> Field Value username <code>username</code> password <code>password</code> </li> <li> <p>Add <code>Orders</code> as the Queue Name and click Create. If there is no queue named <code>Orders</code> in RabbitMQ server, this will create a new queue with this name. </p> <p></p> </li> <li> <p>In the Design view, click the <code>onMessage</code> function box. It will redirect you to the flow diagram view.</p> </li> <li>Click the plus icon after the Start node to open the node panel.</li> <li> <p>Add a Log Info node with the Msg as <code>message.toString()</code>. </p> <p></p> </li> </ol>"},{"location":"get-started/develop-event-integration/#step-2-run-the-integration-in-wso2-integrator-bi","title":"Step 2: Run the integration in WSO2 Integrator: BI","text":"<ol> <li>Click Run in the top right corner to run the integration. This compiles the integration and runs it in the embedded Ballerina runtime.</li> </ol>"},{"location":"get-started/develop-file-integration/","title":"Develop File Integration","text":""},{"location":"get-started/develop-file-integration/#overview","title":"Overview","text":"<p>In this guide, you will create a file integration that fetches recent weather data.</p>"},{"location":"get-started/develop-file-integration/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, make sure you have the following:</p> <ul> <li>Visual Studio Code: Install Visual Studio Code if you don't have it already.</li> <li>WSO2 Integrator: BI Extension: Install the WSO2 Integrator: BI extension. Refer to Install WSO2 Integrator: BI for detailed instructions.</li> </ul>"},{"location":"get-started/develop-file-integration/#step-1-develop-file-integration-in-wso2-integrator-bi","title":"Step 1: Develop File Integration in WSO2 Integrator: BI","text":"<ol> <li>Choose the Integration Type as <code>File Integration</code> and click Create.</li> </ol> <p>This redirects you to the Create New Integration in VS Code page. </p> <ol> <li> <p>Click on the Configure button on the top-right side, and add the following configurables.</p> Configurable Type <code>host</code> <code>string</code> <code>username</code> <code>string</code> <code>password</code> <code>string</code> <code>path</code> <code>string</code> <code>pattern</code> <code>string</code> <p></p> </li> <li> <p>Go to the Design View by clicking the Home icon in the top left corner and click Add Artifact.</p> </li> <li>Select FTP Service. Choosing the File Integration from the Devant console disables the other options.</li> <li>Provide the name of the Listener Configuration as <code>weatherListener</code>.</li> <li> <p>Then expand the Advanced Configurations and enter the following configurables:</p> Field Value Host <code>host</code> Auth <code>{ credentials: { username: username, password: password }}</code> Path <code>path</code> FileNamePattern <code>pattern</code> </li> <li> <p>Click Next, and you will see the created listener with the name <code>weatherListener</code>. </p> </li> <li> <p>Then click on Create. It will redirect you to the Service Designer view.</p> <p></p> </li> <li> <p>In the Design view, click the <code>onFileChange</code> function box. It will redirect you to the flow diagram view.</p> </li> <li>Click the plus icon after the Start node to open the node panel.</li> <li> <p>Select Foreach and enter the following values in relevant fields:</p> Field Value Variable Name <code>addFile</code> Variable Type <code>var</code> Collection <code>event.addedFiles</code> </li> <li> <p>Under the Foreach node, add a Log Info node with the Msg as <code>\"File added:\" + addedFiles.name</code>. </p> <p></p> </li> </ol>"},{"location":"get-started/develop-file-integration/#step-2-run-the-integration-in-wso2-integrator-bi","title":"Step 2: Run the integration in WSO2 Integrator: BI","text":"<ol> <li>Click Run in the top right corner to run the integration. This compiles the integration and runs it in the embedded Ballerina runtime.</li> </ol>"},{"location":"get-started/develop-integration-as-api/","title":"Develop Integration as API","text":""},{"location":"get-started/develop-integration-as-api/#overview","title":"Overview","text":"<p>In this guide, you will create a simple integration as an API that acts as a service that calls a third-party endpoint and returns its response to the client.</p> <p></p>"},{"location":"get-started/develop-integration-as-api/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, make sure you have the following:</p> <ul> <li>Visual Studio Code: Install Visual Studio Code if you don't have it already.</li> <li>WSO2 Integrator: BI Extension: Install the WSO2 Integrator: BI extension. Refer to Install WSO2 Integrator: BI for detailed instructions.</li> </ul>"},{"location":"get-started/develop-integration-as-api/#step-1-create-a-new-integration-project","title":"Step 1: Create a new integration project","text":"<ol> <li>Click on the BI icon on the sidebar.</li> <li>Click on the Create New Integration button.</li> <li>Enter the Integration Name as <code>HelloWorld</code>.</li> <li>Select the project directory by clicking on the Select Path button.</li> <li> <p>Click on the Create Integration button to create the integration project.</p> <p></p> </li> </ol>"},{"location":"get-started/develop-integration-as-api/#step-2-create-an-integration-service","title":"Step 2: Create an integration service","text":"Generate with AI<p>The integration service can also be generated using the AI-assistant. Click on the Generate with AI button and enter the following prompt, then press Add to Integration to generate the integration service.</p> <p><code>Create an http service that has base path as /hello, and 9090 as the port. Add GET resource on /greeting that invokes https://apis.wso2.com/zvdz/mi-qsg/v1.0 endpoint and forward the response to the caller.</code></p> <ol> <li>In the design view, click on the Add Artifact button.</li> <li>Select HTTP Service under the Integration as API category.</li> <li>Select the Create and use the default HTTP listener option from the Listeners dropdown.</li> <li>Select the Design From Scratch option as the Service Contract.</li> <li>Specify the Service base path as <code>/hello</code>.</li> <li> <p>Click on the Create button to create the new service with the specified configurations.</p> <p></p> </li> </ol>"},{"location":"get-started/develop-integration-as-api/#step-3-design-the-integration","title":"Step 3: Design the integration","text":"<ol> <li>The generated service will have a default resource named <code>greeting</code> with the <code>GET</code> method.</li> <li>Click on the <code>greeting</code> resource to view the resource details. Let's modify the resource to invoke the <code>HelloWorld</code> API endpoint.</li> <li>Hover over the arrow after start and click the \u2795 button to add a new action to the resource.</li> <li>Select Add Connection from the node panel. </li> <li>Search for <code>HTTP</code> in the search bar and select HTTP as the connection type.</li> <li>Add the URL <code>\"https://apis.wso2.com\"</code> to the connection URL field and click Save.</li> <li> <p>Change the Connection Name to <code>externalEP</code>.</p> <p></p> </li> <li> <p>Select Connections -&gt; externalEP -&gt; get from the node panel.</p> </li> <li>Fill in the request details as below and click Save.</li> </ol> Field Value Path <code>\"/zvdz/mi-qsg/v1.0\"</code> Result <code>epResponse</code> Target Type <code>string</code> <ol> <li>Click \u2795 button again and select Return from the node panel.  </li> <li> <p>Select the <code>epResponse</code> variable as the Expression from the dropdown and click Save. This step will return the response from the <code>HelloWorld</code> API endpoint.      </p> <p></p> </li> </ol>"},{"location":"get-started/develop-integration-as-api/#step-4-run-the-integration","title":"Step 4: Run the integration","text":"<ol> <li>Click on the Run button in top right corner to run the integration.</li> <li>The integration will be compiled and started in the embedded Ballerina runtime.</li> <li>Once the integration is started, click on the Test button to open the embedded HTTP client.</li> <li> <p>Click on the Send button to invoke the <code>greeting</code> resource.</p> <p></p> </li> <li> <p>Additionally, you can test the integration using REST clients like Postman or curl.</p> <pre><code>curl http://localhost:9090/hello/greeting\n{\"message\":\"Hello World!!!\"}%\n</code></pre> </li> <li> <p>Click on the \u23f9\ufe0f button or press <code>Shift + F5</code> shortcut to stop the integration.</p> <p></p> </li> </ol>"},{"location":"get-started/install-wso2-integrator-bi/","title":"Install WSO2 Integrator: BI","text":""},{"location":"get-started/install-wso2-integrator-bi/#step-1-install-visual-studio-code","title":"Step 1: Install Visual Studio Code","text":"<p>Download and install Visual Studio Code.</p>"},{"location":"get-started/install-wso2-integrator-bi/#step-2-install-the-wso2-integrator-bi-extension","title":"Step 2: Install the WSO2 Integrator: BI extension","text":"<ol> <li>Go to the Extensions view by clicking on the extension icon on the sidebar or pressing <code>Ctrl + Shift + X</code> on Windows and Linux, or <code>Shift + \u2318 + X</code> on a Mac. <p>Check system requirements to verify environment compatibility.</p> </li> <li>Search for <code>WSO2 Integrator: BI</code> in the extensions view search box.</li> <li> <p>Click on the Install button to install the <code>WSO2 Integrator: BI</code> extension.</p> <p></p> </li> <li> <p>This will install the WSO2 Integrator: BI and Ballerina extensions on VS Code.</p> </li> </ol>"},{"location":"get-started/install-wso2-integrator-bi/#step-3-set-up-wso2-integrator-bi-for-the-first-time","title":"Step 3: Set up WSO2 Integrator: BI for the first time","text":"<ol> <li> <p>Click on the BI icon on the sidebar.  </p> <p></p> </li> <li> <p>Click on the Set up Ballerina distribution button.</p> </li> <li>The setup wizard will install and configure the Ballerina distribution required for WSO2 Integrator: BI.</li> <li> <p>Click on the Restart VS Code button to complete the setup.</p> <p></p> </li> </ol>"},{"location":"get-started/quick-start-guide/","title":"Quick Start Guide","text":"<p>WSO2 Integrator: BI is a powerful low-code integration platform built on top of the Ballerina programming language. It\u2019s designed to help developers quickly build, deploy, and manage integration solutions with minimal boilerplate and maximum productivity.</p> <p>BI combines a visual design interface, AI-assisted development, and seamless low-code\u2013to\u2013pro-code transitions. With built-in connectors, flexible deployment options, and support for patterns like APIs, events, and automations, BI empowers teams to integrate faster and smarter.</p> <p>Whether you\u2019re modernizing legacy systems or building cloud-native services, BI provides a productive and scalable path to integration, helping teams drive digital transformation with clarity, speed, and confidence.</p> <p></p> <p>This quick start guide introduces five core integration types, each with a dedicated hands-on walkthrough.</p>"},{"location":"get-started/quick-start-guide/#automation","title":"Automation","text":"<p>Create integrations that run on a timer\u2014for example, to sync data, generate reports, or perform routine jobs. Follow Develop your first automation to get started.</p>"},{"location":"get-started/quick-start-guide/#ai-agent","title":"AI agent","text":"<p>Build agents that reason and act using GenAI models. Use them to respond to user input, access tools, or make decisions dynamically. Follow Develop your first AI agent to get started. </p>"},{"location":"get-started/quick-start-guide/#integrations-as-apis","title":"Integrations as APIs","text":"<p>Expose your integration as a real-time API that handles incoming requests and returns results. Follow Develop your first integration as API to get started.</p>"},{"location":"get-started/quick-start-guide/#event-integration","title":"Event Integration","text":"<p>Trigger your integration when messages arrive from sources like Kafka or RabbitMQ, enabling reactive workflows. Follow Develop your first event integration to get started.</p>"},{"location":"get-started/quick-start-guide/#file-integration","title":"File Integration","text":"<p>Run your integration when files appear in a folder or FTP location\u2014ideal for batch uploads or scheduled file processing. Follow Develop your first file integration to get started.</p> <p>Explore one or more quick start guides to experience how fast and flexible integration can be with BI.</p>"},{"location":"integration-guides/ai/agents/","title":"Agents Overview","text":"<p>WSO2 Integrator: BI enables developers to easily create intelligent AI agents powered by large language models (LLMs) and integrated with external APIs and services. These AI agents can automate complex workflows, interact with users through natural language, and seamlessly connect with systems like Gmail, Google Calendar, and more. Designed for low-code development and rapid integration, BI makes it simple to embed AI-driven logic into your applications, services, and business processes.</p> <p>There are two main types of AI agents in BI:</p>"},{"location":"integration-guides/ai/agents/#chat-agents","title":"Chat Agents","text":"<p>Chat agents are exposed through HTTP endpoints as REST APIs and are designed to interact with users or external systems. These agents are ideal when you need a chatbot-like experience, where users can type questions or commands and receive intelligent responses powered by an LLM.</p>"},{"location":"integration-guides/ai/agents/#inline-agents","title":"Inline Agents","text":"<p>Inline agents are embedded within service logic (e.g., REST APIs, GraphQL resolvers) and invoked programmatically as part of a backend workflow. These agents are ideal for automation, enrichment, or dynamic processing tasks within your services or business logic.</p> <p>Both Chat and Inline agents can be extended with tools that connect to real-world systems via BI's built-in connectors. You can easily integrate agents with services like Gmail, Google Calendar, databases, or custom APIs\u2014allowing agents to perform actions beyond reasoning, such as reading emails, sending messages, creating events, or fetching records.</p> <p>To get started with agents, visit the following tutorial examples:</p> <ul> <li>Introduction to Chat Agents</li> <li>Introduction to Inline Agents</li> <li>Integrating Agents with MCP Servers</li> <li>Integrating Agents with External Endpoints</li> </ul>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/","title":"Integrating Agents with External Endpoints","text":"<p>In this tutorial, you\u2019ll create an AI-powered personal assistant agent that integrates with Gmail and Google Calendar to help you efficiently manage emails, tasks, and schedules. You'll use the prebuilt WSO2 Integrator: BI connectors for seamless integration by turning their actions into agent tools.</p>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#prerequisites","title":"Prerequisites","text":"<p>To get started, you\u2019ll need to configure Google API credentials:</p> <ol> <li>Go to the Google Cloud Console and sign in.</li> <li>Follow this guide to generate your Client ID, Client Secret, and Refresh Token.</li> <li>Make sure the necessary scopes and permissions are enabled for both the Gmail and Calendar APIs.</li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#create-the-agent","title":"Create the agent","text":"<p>Before adding tools, make sure you\u2019ve set up your agent by completing steps 1 to 5 in the Introduction to Chat Agents guide. For this tutorial, you may use the following role and instructions when configuring the agent's behavior.</p> <p>Role <pre><code>Personal AI Assistant\n</code></pre></p> <p>Instructions <pre><code>You are Nova, a smart AI assistant helping me stay organized and efficient.\n\nYour primary responsibilities include:\n- Calendar Management: Scheduling, updating, and retrieving events from the calendar as per the user's needs.\n- Email Assistance: Reading, summarizing, composing, and sending emails while ensuring clarity and professionalism.\n- Context Awareness: Maintaining a seamless understanding of ongoing tasks and conversations to \n  provide relevant responses.\n- Privacy &amp; Security: Handling user data responsibly, ensuring sensitive information is kept confidential,\n  and confirming actions before executing them.\n\nGuidelines:\n- Respond in a natural, friendly, and professional tone.\n- Always confirm before making changes to the user's calendar or sending emails.\n- Provide concise summaries when retrieving information unless the user requests details.\n- Prioritize clarity, efficiency, and user convenience in all tasks.\n</code></pre></p>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#use-connector-actions-as-agent-tools","title":"Use connector actions as agent tools","text":"<p>BI includes prebuilt connectors for many external services like Gmail and Google Calendar. You can directly use their actions as tools for your agent\u2014no need to write custom integration code. This significantly reduces the manual effort typically required when working with external APIs.</p>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#add-gmail-tools-to-the-agent","title":"Add Gmail tools to the agent","text":""},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#tool-1-list-unread-emails","title":"Tool 1: List unread emails","text":""},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-1-add-the-gmail-connector","title":"Step 1: Add the Gmail connector","text":"<ol> <li>In Agent Flow View, click the + button at the bottom-left of the <code>AI Agent</code> box.</li> <li>Click the + button next to Tools \u2192 Create New Tool.</li> <li>Click Add Connection under the Connections section.</li> <li> <p>Search for and select the Gmail connector.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-2-configure-the-gmail-connector","title":"Step 2: Configure the Gmail connector","text":"<ol> <li> <p>In the configuration panel:</p> <ul> <li>Click Config to open the Expression Helper.</li> <li>Under the Construct Record tab, select ConnectionConfig.</li> <li>Set the <code>auth</code> type to OAuth2RefreshTokenGrantType.</li> <li>Fill in your clientId, clientSecret, and refreshToken.</li> </ul> <p>Note</p> <p>Externalize credentials using configurable values to avoid exposing them in your version control system. </p> </li> <li> <p>Save the configuration. You\u2019ll now see the Gmail connection listed under Connections.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-3-create-the-tool","title":"Step 3: Create the tool","text":"<ol> <li>Select the Gmail connection \u2192 choose the action List messages in user\u2019s mailbox.</li> <li> <p>Provide the required Tool Name input as <code>listUnreadEmails</code>, and optionally add a meaningful Description to help the LLM better understand the tool's purpose.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-4-customize-the-tool","title":"Step 4: Customize the tool","text":"<ol> <li>Click on the circular <code>listUnreadEmails</code> tool node.</li> <li>Click \u22ee &gt; View to open the tool function.</li> <li>Click the Gmail connector action node (the rectangle connected to the Gmail connection) to open the configuration panel for that specific connector action.</li> <li>Update these inputs:<ul> <li>Set userId to <code>me</code>. The value <code>\"me\"</code> represents the authenticated user.</li> <li>Under Advanced Configurations, set the q input to <code>\"is:unread\"</code> to filter unread emails only.</li> </ul> </li> <li> <p>Click Save.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-5-clean-up","title":"Step 5: Clean up","text":"<p>Remove the <code>userId</code> parameter from the function as it is no longer used in the tool:</p> <ul> <li>Click Edit in the top-right of the function panel.</li> <li>Click the Trash icon next to <code>userId</code>.</li> <li> <p>Click Save.</p> <p></p> </li> </ul> <p>You\u2019ve now created a tool that lists unread emails in the user\u2019s Gmail inbox.</p>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#tool-2-read-a-specific-email","title":"Tool 2: Read a specific email","text":""},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-1-create-the-tool","title":"Step 1: Create the tool","text":"<ol> <li>In Agent Flow View, click + under Tools \u2192 Create New Tool.</li> <li>Select the existing gmailClient connection.</li> <li>Choose the action Gets the specified message.</li> <li> <p>Name the tool as <code>readSpecificEmail</code> and optionally add a description.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-2-customize-the-tool","title":"Step 2: Customize the tool","text":"<ol> <li>Open the <code>readSpecificEmail</code> tool node \u2192 \u22ee &gt; View.</li> <li>Click the Gmail action node and update inputs:<ul> <li>Set userId to <code>\"me\"</code>. The value <code>\"me\"</code> represents the authenticated user.</li> <li>Under Advanced Configurations, set the format input to <code>full</code> to get the full email message data with the body content parsed.</li> </ul> </li> <li> <p>Click Save.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-3-clean-up","title":"Step 3: Clean up","text":"<p>Remove <code>userId</code> from parameters (as done previously) and save the tool.</p> <p></p>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#tool-3-send-an-email","title":"Tool 3: Send an email","text":""},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-1-create-the-tool_1","title":"Step 1: Create the tool","text":"<ol> <li>Use the existing gmailClient connection.</li> <li>Select the action Sends the specified message to the recipients.</li> <li> <p>Name the tool as <code>sendEmail</code> and optionally add a helpful description.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-2-customize-and-clean-up","title":"Step 2: Customize and clean up","text":"<ol> <li>Set <code>userId</code> to <code>\"me\"</code> in the connector action configuration (as done previously) .</li> <li>Remove <code>userId</code> from the parameters.</li> <li> <p>Save your tool.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#add-calendar-tools-to-the-agent","title":"Add calendar tools to the agent","text":""},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#tool-4-list-calendar-events","title":"Tool 4: List calendar events","text":""},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-1-add-the-google-calendar-connector","title":"Step 1: Add the google calendar connector","text":"<ol> <li>In Agent Flow View, click the + button at the bottom-left of the <code>AI Agent</code> box.</li> <li>Click the + button next to Tools \u2192 Create New Tool.</li> <li>Click + button of the Connections section.</li> <li> <p>Search for and select the Gcalendar connector.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-2-configure-the-google-calendar-connector","title":"Step 2: Configure the google calendar connector","text":"<ol> <li> <p>In the configuration panel:</p> <ul> <li>Click Config to open the Expression Helper.</li> <li>Under the Construct Record tab, select ConnectionConfig.</li> <li>Set the <code>auth</code> type to OAuth2RefreshTokenGrantType.</li> <li>Fill in your clientId, clientSecret, and refreshToken.</li> </ul> <p>Note</p> <p>Externalize credentials using configurable values to avoid exposing them in your version control system. </p> <p></p> </li> <li> <p>Save the configuration. You\u2019ll now see the Google calendar connection listed under Connections.</p> </li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-3-create-the-tool_1","title":"Step 3: Create the tool","text":"<ol> <li>Select the Google calendar connection \u2192 choose the action Returns events on the specified calendar..</li> <li> <p>Provide the required Tool Name input as <code>listCalendarEvents</code>, and optionally add a meaningful Description.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-4-customize-the-tool_1","title":"Step 4: Customize the tool","text":"<ol> <li>Click on the circular <code>listCalendarEvents</code> tool node.</li> <li>Click \u22ee &gt; View to open the tool function.</li> <li>Click the Google calendar connector action node (the rectangle connected to the Google calendar connection) to open the configuration panel for that specific connector action.</li> <li>Update the <code>calendarId</code> input to <code>\"primary\"</code>, which allows access to the primary calendar of the authenticated user.</li> <li> <p>Click Save.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-5-clean-up_1","title":"Step 5: Clean up","text":"<p>Remove the <code>calendarId</code> parameter from the function as it is no longer used in the tool:</p> <ul> <li>Click Edit in the top-right of the function panel.</li> <li>Click the Trash icon next to <code>calendarId</code>.</li> <li> <p>Click Save.</p> <p></p> </li> </ul>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#tool-5-create-calendar-event","title":"Tool 5: Create calendar event","text":""},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-1-create-the-tool_2","title":"Step 1: Create the tool","text":"<ol> <li>In Agent Flow View, click + under Tools \u2192 Create New Tool.</li> <li>Select the existing gcalendarClient connection.</li> <li>Choose the action Creates an event.</li> <li> <p>Name the tool as <code>createCalendarEvent</code> and optionally add a helpful description.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-2-customize-the-tool_1","title":"Step 2: Customize the tool","text":"<ol> <li>Click on the circular <code>createCalendarEvent</code> tool node.</li> <li>Click \u22ee &gt; View to open the tool function.</li> <li>Click the Google calendar connector action node to open the configuration panel for that specific connector action.</li> <li>Update the <code>calendarId</code> input to <code>\"primary\"</code>.</li> <li> <p>Click Save.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-3-clean-up_1","title":"Step 3: Clean up","text":"<p>Remove the <code>calendarId</code> parameter from the function as it is no longer used in the tool:</p> <ul> <li>Click Edit in the top-right of the function panel.</li> <li>Click the Trash icon next to <code>calendarId</code>.</li> <li> <p>Click Save.</p> <p></p> </li> </ul>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#interact-with-the-agent","title":"Interact with the agent","text":"<p>After completing the above steps, your personal AI assistant agent is now ready to assist you with necessary tasks. WSO2 Integrator: BI provides a built-in chat interface to interact with the agent.</p> <p>To start chatting with the agent:</p> <ol> <li>Click the Chat button located at the top-left corner of the interface.</li> <li>You will be prompted to run the integration. Click Run Integration.</li> <li>If you have added any variables to the project, you\u2019ll be prompted to update their values in the Config.toml file. Configure them to continue with the execution of the agent.</li> <li> <p>Start chatting with your assistant.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-mcp-servers/","title":"Integrating Agents with MCP Servers","text":"<p>This tutorial guides you through creating an AI-powered Weather Assistant that integrates with an MCP server to provide real-time weather information. By the end of this tutorial, you will have a personal assistant capable of delivering current weather conditions and forecast details for any location worldwide.</p>"},{"location":"integration-guides/ai/agents/integrating-agents-with-mcp-servers/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have a running MCP Server connected to a weather service. For this setup, you can set up an MCP Server using the guidelines given here. This server enables effective communication between your AI agent and the weather API, allowing real-time data retrieval.</p>"},{"location":"integration-guides/ai/agents/integrating-agents-with-mcp-servers/#create-the-ai-agent","title":"Create the AI agent","text":"<p>Before integrating MCP capabilities, you must first create an AI agent. Follow Steps 1 to 5 in the Introduction to Chat Agents guide to set up your agent.</p> <p>For this tutorial, you can configure the agent with the following role and instructions:</p> <p>Role:</p> <pre><code>Weather AI Assistant\n</code></pre> <p>Instructions:</p> <pre><code>You are Nova, a smart AI assistant dedicated to providing accurate and timely weather information.\n\nYour primary responsibilities include:\n- Current Weather: Provide detailed and user-friendly current weather information for a given location.\n- Weather Forecast: Share reliable weather forecasts according to user preferences (e.g., hourly, daily).\n\nGuidelines:\n- Always communicate in a natural, friendly, and professional tone.\n- Provide concise summaries unless the user explicitly requests detailed information.\n- Confirm location details if ambiguous and suggest alternatives when data is unavailable.\n</code></pre>"},{"location":"integration-guides/ai/agents/integrating-agents-with-mcp-servers/#add-mcp-server-to-the-agent","title":"Add MCP Server to the agent","text":"<p>By connecting to the Weather MCP server, your AI agent can access and interact with real-time weather data sources. To integrate it, follow the steps below.</p>"},{"location":"integration-guides/ai/agents/integrating-agents-with-mcp-servers/#step-1-add-the-mcp-server","title":"Step 1: Add the MCP server","text":"<p>Provide the MCP server connection details.</p> <ol> <li>In Agent Flow View, click the + button at the bottom-right of the <code>AI Agent</code> box.</li> <li>Under Add Tools section, select Use MCP Server.</li> <li> <p>Provide the necessary configuration details, then click Save Tool.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-mcp-servers/#step-2-customize-the-mcp-server","title":"Step 2: Customize the MCP server","text":"<p>You can further customize the MCP configuration to include additional weather tools to suit your use case.</p> <p></p>"},{"location":"integration-guides/ai/agents/integrating-agents-with-mcp-servers/#interact-with-the-agent","title":"Interact with the agent","text":"<p>After completing the above steps, your personal AI assistant agent is now ready to assist you with necessary tasks. WSO2 Integrator: BI provides a built-in chat interface to interact with the agent.</p> <p>To start chatting with the agent:</p> <ol> <li>Click the Chat button located at the top-left corner of the interface.</li> <li>You will be prompted to run the integration. Click Run Integration.</li> <li> <p>Start chatting with your assistant.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/introduction-to-chat-agents/","title":"Introduction to Chat Agents","text":"<p>In this tutorial, you'll create an AI-powered math tutor assistant capable of handling a variety of mathematical queries. The agent will be equipped with tools to perform fundamental arithmetic operations and intelligently combine and execute these tools to address user questions. By the end of this tutorial, you'll have built an interactive math assistant that can help users solve problems and provide clear, step-by-step explanations.</p> <p>Note</p> <p>This math tutor agent can technically be implemented using just an LLM, without any agent capabilities. However, the purpose of this tutorial is to help you understand the essential concepts required to build an AI agent using WSO2 Integrator: BI. By following this guide, you'll gain hands-on experience with agent creation in WSO2 Integrator: BI, setting the foundation for developing more powerful and tailored AI agents in the future.</p>"},{"location":"integration-guides/ai/agents/introduction-to-chat-agents/#prerequisites","title":"Prerequisites","text":"<ul> <li>Sign up at OpenAI.</li> <li>Get an API key from the API section.</li> </ul>"},{"location":"integration-guides/ai/agents/introduction-to-chat-agents/#step-1-create-a-new-integration-project","title":"Step 1: Create a new integration project","text":"<ol> <li>Click on the BI icon in the sidebar.</li> <li>Click on the Create New Integration button.</li> <li>Enter the project name as <code>MathTutor</code>.</li> <li>Select the project directory location by clicking on the Select Location button.</li> <li> <p>Click the Create New Integration button to generate the integration project.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/introduction-to-chat-agents/#step-2-create-an-agent","title":"Step 2: Create an agent","text":"<ol> <li>Click the + button on the BI side panel or navigate back to the design screen and click on Add Artifact.</li> <li>Select AI Chat Agent under the AI Agent artifacts.</li> <li>Provide a Name for the agent. It will take a moment to create an agent with the default configuration.</li> <li> <p>After creating the agent, you can configure it with a model provider, memory, tools, roles, and instructions.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/introduction-to-chat-agents/#step-3-configure-the-agent-behavior","title":"Step 3: Configure the agent behavior","text":"<ol> <li>Click on the AI Agent box to open the agent configuration settings.</li> <li>Define the agent's Role and provide Instructions in natural language. These instructions will guide the agent\u2019s behavior and tasks.</li> <li> <p>Click Save to finalize and complete the agent behavior configuration.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/introduction-to-chat-agents/#step-4-configure-the-agent-model","title":"Step 4: Configure the agent model","text":"<ol> <li>Locate the circle with OpenAI logo which is connected to the AI Agent box. This circle represents the LLM model used by the agent.</li> <li>Click on the circle to open the model configuration options.</li> <li>In the Select Model Provider dropdown, choose OpenAiProvider. By default, OpenAiProvider is selected.</li> <li> <p>Next, provide the OpenAI API key in the API Key input field.</p> <p>Note</p> <p>Since the API key is sensitive, it\u2019s recommended to externalize it by using a configurable value. This helps prevent accidentally committing it to your version control system and ensures it\u2019s kept secure without being exposed. To learn more, see Configurations.</p> <ul> <li>Click the API Key input field to open the Expression Helper window.  </li> <li>In the top bar, go to the Configurables tab (the third option).  </li> <li>Click + Create New Configurable Variable to define a new configurable.  </li> <li>Set the Name to <code>openAiApiKey</code> and the Type to <code>string</code>.  </li> <li>Click Save to create the configurable.</li> </ul> </li> <li> <p>In the Model Type dropdown, select <code>ai:GPT_40</code>.</p> </li> <li> <p>Click Save to complete the LLM model configuration.    </p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/introduction-to-chat-agents/#step-5-configure-agent-memory","title":"Step 5: Configure agent memory","text":"<ol> <li>By default, the agent comes preconfigured with an in-memory implementation.</li> <li>For this tutorial, we will keep the default memory configuration and not make any changes.</li> <li>If you prefer to run the agent without memory (in a stateless fashion), follow these steps:<ul> <li>Click on the three vertical dots in the Memory box.</li> <li>Select the Delete option to remove the memory.</li> </ul> </li> </ol>"},{"location":"integration-guides/ai/agents/introduction-to-chat-agents/#step-6-add-tools-to-the-agent","title":"Step 6: Add tools to the agent","text":"<p>BI allows you to create tools using existing functions. It also supports automatically generating tools from connector actions or OpenAPI specifications by leveraging BI\u2019s capability to generate local connectors from an OpenAPI spec.</p> <p>However, in this tutorial, we will create simple functions to perform arithmetic operations and use them as tools.</p>"},{"location":"integration-guides/ai/agents/introduction-to-chat-agents/#create-a-function","title":"Create a function","text":"<ol> <li>Click the + button in the BI side panel under the Functions section.</li> <li>Provide the required details to create the function. For this example, use <code>sum</code> as the function name, and specify the parameters and return types.</li> <li>Implement the function logic in the flow node editor that opens.</li> </ol>"},{"location":"integration-guides/ai/agents/introduction-to-chat-agents/#add-the-created-function-as-a-tool","title":"Add the created function as a tool","text":"<ol> <li>Go to the agent flow view.</li> <li>Click the + button at the bottom-right corner of the <code>AI Agent</code> box.</li> <li>Click the + button under the Tools section.</li> <li>Select the created function from the Current Integration list \u2014 in this case, <code>sum</code>.</li> <li>Then provide the Tool Name and Description of the tool</li> </ol> <p>Follow steps 1 to 3 to create functions named subtract, multiply and divide to perform subtraction, multiplication, and division operations respectively. Define the appropriate parameters and return types, and implement the corresponding logic in the flow node editor. Then repeat steps 4 to 8 to add each of these functions as tools in the agent by selecting them from the Current Integration list and providing a relevant tool name and description for each.    </p> <p></p>"},{"location":"integration-guides/ai/agents/introduction-to-chat-agents/#step-7-interact-with-the-agent","title":"Step 7: Interact with the agent","text":"<p>After completing the above steps, your math tutor assistant is now ready to answer questions. BI provides a built-in chat interface to interact with the agent.</p> <p>To start chatting with the agent:</p> <ol> <li>Click the Chat button located at the top-left corner of the interface.</li> <li>You will be prompted to run the integration. Click Run Integration.</li> <li>Since we have created a configurable variable for <code>openAiApiKey</code> in step 4, provide it in the <code>Config.toml</code> file.</li> </ol> <p>Note</p> <p>A temporary OpenAI API key is used in the GIF below to showcase the steps.  </p> <p></p>"},{"location":"integration-guides/ai/agents/introduction-to-inline-agents/","title":"Introduction to Inline Agents","text":"<p>In this tutorial, you'll learn how to connect an AI agent to a GraphQL service, enabling the agent to be invoked directly within a GraphQL resolver. This demonstrates the use of an inline agent\u2014a powerful capability in the WSO2 Integrator: BI.</p> <p>Unlike chat agents, which are exposed as REST APIs for external interaction, inline agents are not tied to an API endpoint. Instead, they can be invoked programmatically from anywhere within your integration logic, just like a regular function call.</p> <p>In this example, we'll define a GraphQL schema with a query that invokes the inline agent to generate dynamic responses based on input parameters. The agent runs within the resolver logic and returns results directly as part of the GraphQL response.</p>"},{"location":"integration-guides/ai/agents/introduction-to-inline-agents/#prerequisites","title":"Prerequisites","text":"<ul> <li>Sign up at OpenAI.</li> <li>Get an API key from the API section.</li> </ul>"},{"location":"integration-guides/ai/agents/introduction-to-inline-agents/#step-1-create-a-new-integration-project","title":"Step 1: Create a new integration project","text":"<ol> <li>Click on the BI icon in the sidebar.</li> <li>Click on the Create New Integration button.</li> <li>Enter the project name as <code>GraphqlService</code>.</li> <li>Select the project directory by clicking on the Select Location button.</li> <li> <p>Click the Create New Integration button to generate the integration project.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/introduction-to-inline-agents/#step-2-create-a-graphql-service","title":"Step 2: Create a GraphQL service","text":"<ol> <li>Click the + button on the WSO2 Integrator: BI side panel or navigate back to the design screen and click on Add Artifact.</li> <li>Select GraphQL Service under the Integration as API artifacts.</li> <li> <p>Keep the default Listener and Service base path configurations, and click Create.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/introduction-to-inline-agents/#step-3-create-a-graphql-resolver","title":"Step 3: Create a GraphQL resolver","text":"<ol> <li>Click the + Create Operations button in the GraphQL design view.</li> <li>In the side panel, click the + button in the Mutation section to add a mutation operation.</li> <li>Provide <code>task</code> as the value for the Field name.</li> <li>Click the Add Argument button to add a GraphQL input<ul> <li>Provide <code>query</code> for the Argument name.</li> <li>Provide <code>string</code> for the Argument type.</li> <li>Click Add to save the argument.</li> </ul> </li> <li> <p>Provide <code>string|error</code> for the Field type, as this will be used as the return type of the resolver.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/introduction-to-inline-agents/#step-4-implement-the-resolving-logic-with-an-inline-agent","title":"Step 4: Implement the resolving logic with an inline agent","text":"<ol> <li>Click the created <code>task</code> operation in the side panel to navigate to the resolver editor view.</li> <li>Click the + button in the flow to open the side panel.</li> <li>Click Agent under Statement, which will navigate you to the agent creation panel.</li> <li>Update Variable Name to <code>response</code>. This is the variable where the agent's output will be stored.</li> <li>Update the Role and Instructions to configure the agent\u2019s behavior.</li> <li>Provide the query parameter as the input for Query. This will serve as the command that the agent will execute.</li> <li>Click Save.</li> <li>Next, configure the agent\u2019s memory, model, and tools. For guidance, refer to the Chat Agent configuration steps and the Personal Assistant setup guide to make the agent function as a personal assistant.</li> <li>After configuring the agent, click the + button on the flow and select Return under Control from the side panel.</li> <li> <p>For the Expression, provide the <code>response</code> variable as the input.</p> <p></p> </li> </ol> <p>At this point, we've created a GraphQL resolver that takes a user-provided <code>query</code> as input, passes it to an inline agent for processing, and returns the agent\u2019s <code>response</code> as the result of the resolver.</p> <p>Note</p> <p>You must implement a query operation to have a valid GraphQL service. Similar to creating the <code>task</code> operation in Step 3, add an operation named <code>greet</code> by pressing the + button in the Query section, without any input parameters. For the implementation, you can simply return a string literal saying <code>\"welcome\"</code>.</p>"},{"location":"integration-guides/ai/agents/introduction-to-inline-agents/#step-5-run-the-integration-and-query-the-agent","title":"Step 5: Run the integration and query the agent","text":"<ol> <li>Click on the Run button in the top-right corner to run the integration.</li> <li> <p>Query the agent by sending the mutation request below.     <pre><code>curl -X POST http://localhost:8080/graphql \\\n-H \"Content-Type: application/json\" \\\n-d '{ \"query\": \"mutation Task { task(query: \\\"Summarize latest emails\\\") }\" }'\n</code></pre></p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/direct-llm-call/direct-llm-invocation-with-ballerina-model-providers/","title":"Direct LLM invocation with Ballerina model providers","text":"<p>In this tutorial, you will create an integration that makes a direct call to a Large Language Model (LLM) using Ballerina\u2019s model providers. Direct LLM calls are designed for simple, stateless interactions where conversational history is not required, giving you fine-grained control over each request. With Ballerina, you can send a prompt along with a type descriptor, instructing the LLM to generate a response that automatically conforms to your desired type-safe format (e.g., JSON, Ballerina records, integers). This eliminates manual parsing and ensures structured, predictable outputs.</p> <p>In this tutorial, you\u2019ll leverage this capability to analyze blog content\u2014prompting the LLM to return a structured review, including a suggested category and a rating, using the default WSO2 model provider.</p>"},{"location":"integration-guides/ai/direct-llm-call/direct-llm-invocation-with-ballerina-model-providers/#implementation","title":"Implementation","text":"<p>Follow the steps below to implement the integration.</p>"},{"location":"integration-guides/ai/direct-llm-call/direct-llm-invocation-with-ballerina-model-providers/#step-1-create-a-new-integration-project","title":"Step 1: Create a new integration project","text":"<ol> <li>Click on the WSO2 Integrator: BI icon on the sidebar.</li> <li>Click on the <code>Create New Integration</code> button.</li> <li>Enter <code>BlogReviewer</code> as the project name.</li> <li>Select Project Directory and click on the <code>Select Location</code> button.</li> <li>Click on the <code>Create New Integration</code> button to create the integration project.</li> </ol>"},{"location":"integration-guides/ai/direct-llm-call/direct-llm-invocation-with-ballerina-model-providers/#step-2-define-types","title":"Step 2: Define types","text":"<ol> <li>Click on the <code>Add Artifacts</code> button and select <code>Type</code> in the <code>Other Artifacts</code> section.</li> <li>Click on <code>+ Add Type</code> to add a new type.</li> <li>Click on <code>Import</code> button in the top right corner of the type editor.</li> <li> <p>Use <code>Blog</code> as the <code>Name</code>. Then select <code>JSON</code> on the dropdown and paste the following JSON payload. Then Click on the <code>Import</code> button.</p> <pre><code>{\n\"title\": \"Tips for Growing a Beautiful Garden\",\n\"content\": \"Spring is the perfect time to start your garden. Begin by preparing your soil with organic compost and ensure proper drainage. Choose plants suitable for your climate zone, and remember to water them regularly. Don't forget to mulch to retain moisture and prevent weeds.\"\n}\n</code></pre> </li> <li> <p>Add another type with <code>Review</code> as the <code>Name</code> and paste the following JSON payload.</p> <pre><code>{\n\"suggestedCategory\": \"Gardening\",\n\"rating\": 5\n}\n</code></pre> </li> <li> <p>The types are now available in the project. <code>Blog</code> and <code>Review</code> are the types that represent the blog content and review respectively.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/direct-llm-call/direct-llm-invocation-with-ballerina-model-providers/#step-3-create-an-http-service","title":"Step 3: Create an HTTP service","text":"<ol> <li>In the design view, click on the <code>Add Artifact</code> button.</li> <li>Select <code>HTTP Service</code> under the <code>Integration as API</code> category.</li> <li>Select the <code>Create and use the default HTTP listener (port: 9090)</code> option from the <code>Listeners</code> dropdown.</li> <li>Select the <code>Design from Scratch</code> option as the <code>Service Contract</code> and use <code>/blogs</code> as the <code>Service base path</code>.</li> <li> <p>Click on the <code>Create</code> button to create the new service with the specified configurations.</p> <p></p> </li> <li> <p>The service will have a default resource named <code>greeting</code> with the <code>GET</code> method. Click on the three dots that appear in front of the <code>/blogs</code> service and select <code>Edit</code> from the menu.</p> </li> <li>Then click the <code>Edit</code> button in front of <code>/greeting</code> resource.</li> <li>Change the resource HTTP method to <code>POST</code>.</li> <li>Change the resource name to <code>review</code>.</li> <li>Click on <code>Add Payload</code> and specify <code>blog</code> as the name and <code>Blog</code> as the type.</li> <li>Change the 201 response return type to <code>Review</code> and convert it to nilable type using type operators.</li> <li> <p>Click on the <code>Save</code> button to update the resource with the specified configurations.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/direct-llm-call/direct-llm-invocation-with-ballerina-model-providers/#step-4-implement-the-resource-logic","title":"Step 4: Implement the resource logic","text":"<ol> <li>Click on the <code>review</code> resource to navigate to the resource implementation designer view.</li> <li>Hover over the arrow after start and click the \u2795 button to add a new action to the resource.</li> <li>Select <code>Model Provider</code> from the node panel.</li> <li>Click on the <code>+ Add Model Provider</code>.</li> <li>Click on the <code>Default Model Provider (WSO2)</code>.</li> <li>Then add <code>model</code> as the name of the model provider and <code>ai:Wso2ModelProvider</code> as the result type.</li> <li>Then click on the <code>Save</code> button.</li> <li>Then click on the <code>model</code> variable under the <code>Model Providers</code> node.</li> <li>It will shows the list of available APIs from the model provider. Select the <code>generate</code> API from the list.</li> <li> <p>Use the following prompt as the <code>Prompt</code> for reviewing blog usecase. Add the name of the result variable as <code>review</code>. Use <code>Review</code> as the return type and convert it to nilable type using type operators.      Then click on the <code>Save</code> button.</p> <pre><code>You are an expert content reviewer for a blog site that \n    categorizes posts under the following categories: \"Gardening\", \"Sports\", \"Health\", \"Technology\", \"Travel\"\n\n    Your tasks are:\n    1. Suggest a suitable category for the blog from exactly the specified categories. \n       If there is no match, use null.\n\n    2. Rate the blog post on a scale of 1 to 10 based on the following criteria:\n    - **Relevance**: How well the content aligns with the chosen category.\n    - **Depth**: The level of detail and insight in the content.\n    - **Clarity**: How easy it is to read and understand.\n    - **Originality**: Whether the content introduces fresh perspectives or ideas.\n    - **Language Quality**: Grammar, spelling, and overall writing quality.\n\nHere is the blog post content:\n\n    Title: ${blog.title}\n    Content: ${blog.content}\n</code></pre> <p></p> </li> <li> <p>Add a new node after the <code>generate</code> API call and select <code>Return</code> from the node panel.</p> </li> <li> <p>Select the <code>review</code> variable from the dropdown and click <code>Save</code>.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/direct-llm-call/direct-llm-invocation-with-ballerina-model-providers/#step-5-configure-default-wso2-model-provider","title":"Step 5: Configure default WSO2 model provider","text":"<ol> <li>Ballerina supports direct calls to Large Language Models (LLMs) with various providers, such as OpenAI, Azure OpenAI, and Anthropic. This demonstration focuses on using the Default Model Provider (WSO2). To begin, you need to configure its settings:<ul> <li>Press <code>Ctrl/Cmd + Shift + P</code> to open the VS Code command palette.</li> <li>Run the command: <code>Ballerina: Configure default WSO2 model provider</code>.    This will automatically generate the required configuration entries.</li> </ul> </li> </ol>"},{"location":"integration-guides/ai/direct-llm-call/direct-llm-invocation-with-ballerina-model-providers/#step-6-run-the-integration","title":"Step 6: Run the integration","text":"<p>Response May Vary</p> <p>Since this integration involves an LLM (Large Language Model) call, the response values may not always be identical across different executions.</p> <ol> <li>Click on the <code>Run</code> button in the top-right corner to run the integration.</li> <li>The integration will start and the service will be available at <code>http://localhost:9090/blogs</code>.</li> <li>Click on the <code>Try it</code> button to open the embedded HTTP client.</li> <li> <p>Enter the blog content in the request body and click on the \u25b6\ufe0f button to send the request.</p> <pre><code>{\n\"title\": \"The Healthy Maven\",\n\"content\": \"For those who want a 360-degree approach to self-care, with advice for betterment in the workplace, home, gym, and on the go, look no further. The Healthy Maven offers recipes for every type of meal under the sun (salads, sides, soups, and more), DIY tips (you\u2019ll learn how to make your own yoga mat spray), and quick workouts. If you like where all this is going, there\u2019s a supplementary podcast run by blogger Davida with guest wellness experts.\"\n}\n</code></pre> </li> <li> <p>The blog content is analyzed by the LLM to suggest a category and rate it based on predefined criteria.</p> </li> </ol>"},{"location":"integration-guides/ai/natural-functions/natural-functions/","title":"Natural Functions","text":"<p>In this tutorial, you will create and use a natural function using the WSO2 Integrator: BI. A natural function allows the logic of the function to be described in natural language and is executed at runtime with a call to a Large Language Model (LLM), with the natural language instructions as the prompt. The tutorial uses a natural function to analyze blog content to suggest a suitable category and rate it on a scale of 1 to 10 based on specified criteria.</p> Natural Programming<p>To learn more about natural programming and natural functions, see Natural Language is Code: A hybrid approach with Natural Programming.</p>"},{"location":"integration-guides/ai/natural-functions/natural-functions/#implementation","title":"Implementation","text":"<p>Follow the steps below to implement the integration.</p>"},{"location":"integration-guides/ai/natural-functions/natural-functions/#step-1-create-a-new-integration-project","title":"Step 1: Create a new integration project","text":"<ol> <li>Click on the BI icon on the sidebar.</li> <li>Click on the <code>Create New Integration</code> button.</li> <li>Enter <code>BlogReviewer</code> as the project name.</li> <li>Select Project Directory and click on the <code>Select Location</code> button.</li> <li>Click on the <code>Create New Integration</code> button to create the integration project.</li> </ol>"},{"location":"integration-guides/ai/natural-functions/natural-functions/#step-2-define-types","title":"Step 2: Define Types","text":"<ol> <li>Click on the <code>Add Artifacts</code> button and select <code>Type</code> in the <code>Other Artifacts</code> section.</li> <li>Click on <code>+ Add Type</code> to add a new type and switch to the <code>Import</code> section. </li> <li> <p>Enter <code>Blog</code> as the <code>Name</code>, paste the following JSON payload, and then click the <code>Import</code> button.</p> <pre><code>{\n\"title\": \"Tips for Growing a Beautiful Garden\",\n\"content\": \"Spring is the perfect time to start your garden. Begin by preparing your soil with organic compost and ensure proper drainage. Choose plants suitable for your climate zone, and remember to water them regularly. Don't forget to mulch to retain moisture and prevent weeds.\"\n}\n</code></pre> </li> <li> <p>Add another type with <code>Review</code> as the <code>Name</code> and paste the following JSON payload. Then click the <code>Import</code> button.</p> <pre><code>{\n\"suggestedCategory\": \"Gardening\",\n\"rating\": 5\n}\n</code></pre> </li> <li> <p>The types are now available in the project. <code>Blog</code> and <code>Review</code> are the types that represent the blog content and review respectively.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/natural-functions/natural-functions/#step-3-add-a-natural-function","title":"Step 3: Add a Natural Function","text":"<ol> <li>Click on the <code>Add Artifact</code> button and select <code>Natural Function</code> under the <code>Other Artifacts</code> category.</li> <li> <p>Use <code>reviewBlog</code> as the name of the function. Then click the <code>Add Parameter</code> button to add a parameter of type <code>Blog</code> named <code>blog</code>. Use <code>Review</code> as the return type and convert it to nilable type using type operators. Then click on the <code>Create</code> button.</p> <p></p> </li> <li> <p>Click on the <code>Edit</code> button to specify the requirement in natural language (i.e., the prompt).</p> </li> <li> <p>Use the following prompt and click on the <code>Save</code> button. Note how interpolations refer to the <code>blog</code> parameter.</p> <pre><code>You are an expert content reviewer for a blog site that \n    categorizes posts under the following categories: \"Gardening\", \"Sports\", \"Health\", \"Technology\", \"Travel\"\n\n    Your tasks are:\n    1. Suggest a suitable category for the blog from exactly the specified categories. \n       If there is no match, use null.\n\n    2. Rate the blog post on a scale of 1 to 10 based on the following criteria:\n    - **Relevance**: How well the content aligns with the chosen category.\n    - **Depth**: The level of detail and insight in the content.\n    - **Clarity**: How easy it is to read and understand.\n    - **Originality**: Whether the content introduces fresh perspectives or ideas.\n    - **Language Quality**: Grammar, spelling, and overall writing quality.\n\nHere is the blog post content:\n\n    Title: ${blog.title}\n    Content: ${blog.content}\n</code></pre> <p></p> </li> </ol>"},{"location":"integration-guides/ai/natural-functions/natural-functions/#step-4-create-an-http-service","title":"Step 4: Create an HTTP service","text":"<ol> <li>In the design view, click on the <code>Add Artifact</code> button.</li> <li>Select <code>HTTP Service</code> under the <code>Integration as API</code> category.</li> <li>Select the <code>Create and use the default HTTP listener (port: 9090)</code> option from the <code>Listeners</code> dropdown.</li> <li>Select the <code>Design from Scratch</code> option as the <code>Service Contract</code> and use <code>/blogs</code> as the <code>Service base path</code>.</li> <li> <p>Click on the <code>Create</code> button to create the new service with the specified configurations.</p> <p></p> </li> <li> <p>The service will have a default resource named <code>greeting</code> with the <code>GET</code> method. Click on the three dots that appear in front of the <code>/blogs</code> service and select <code>Edit</code> from the menu.</p> </li> <li>Then click the <code>Edit</code> button in front of <code>/greeting</code> resource.</li> <li>Change the resource HTTP method to <code>POST</code>.</li> <li>Change the resource name to <code>review</code>.</li> <li>Click on <code>Add Payload</code> and specify <code>blog</code> as the name and <code>Blog</code> as the type.</li> <li>Change the 201 response return type to <code>Review</code>.</li> <li> <p>Click on the <code>Save</code> button to update the resource with the specified configurations.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/natural-functions/natural-functions/#step-5-implement-the-resource-logic","title":"Step 5: Implement the resource logic","text":"<ol> <li>Click on the <code>review</code> resource to navigate to the resource implementation designer view.</li> <li>Hover over the arrow after start and click the \u2795 button to add a new action to the resource.</li> <li>Select <code>Call Natural Function</code> from the node panel.</li> <li>Select the <code>reviewBlog</code> function from the suggestions.</li> <li> <p>For the <code>Blog</code> parameter, use <code>blog</code> as the argument and click on the <code>Save</code> button.</p> <p></p> </li> <li> <p>Add a new node after the <code>reviewBlog</code> function call and select <code>Return</code> from the node panel.</p> </li> <li> <p>Select the <code>review</code> variable from the dropdown and click <code>Save</code>.</p> <p></p> </li> <li> <p>The resource implementation is now complete. The function <code>reviewBlog</code> is called with the <code>blog</code> content as input, and the <code>review</code> is returned as the response.</p> </li> </ol>"},{"location":"integration-guides/ai/natural-functions/natural-functions/#step-6-configure-model-for-natural-function","title":"Step 6: Configure model for natural function","text":"<ol> <li> <p>Press <code>Ctrl + Shift + P</code> on Windows and Linux, or <code>Shift + \u2318 + P</code> on a Mac, and type <code>&gt;Ballerina: Configure default model for natural functions (Experimental)</code> to configure the default model for natural functions. </p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/natural-functions/natural-functions/#step-7-run-the-integration","title":"Step 7: Run the integration","text":"<p>Response May Vary</p> <p>Since this integration involves an LLM (Large Language Model) call, the response values may not always be identical across different executions.</p> <ol> <li>Click on the <code>Run</code> button in the top-right corner to run the integration.</li> <li>The integration will start and the service will be available at <code>http://localhost:9090/blogs</code>.</li> <li>Click on the <code>Try it</code> button to open the embedded HTTP client.</li> <li> <p>Enter the blog content in the request body and click on the \u25b6\ufe0f button to send the request.</p> <pre><code>{\n\"title\": \"The Healthy Maven\",\n\"content\": \"For those who want a 360-degree approach to self-care, with advice for betterment in the workplace, home, gym, and on the go, look no further. The Healthy Maven offers recipes for every type of meal under the sun (salads, sides, soups, and more), DIY tips (you\u2019ll learn how to make your own yoga mat spray), and quick workouts. If you like where all this is going, there\u2019s a supplementary podcast run by blogger Davida with guest wellness experts.\"\n}\n</code></pre> </li> <li> <p>The blog content is analyzed by the natural function to suggest a category and rate it based on predefined criteria.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/rag/build-a-rag-application/","title":"Build a RAG Application","text":"<p>This tutorial guides you through creating a Retrieval-Augmented Generation (RAG) system using WSO2 Integrator: BI. While there are several ways to structure a RAG workflow, we\u2019ll focus on a typical two-phase approach: ingestion and retrieval.</p>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#rag-ingestion","title":"RAG ingestion","text":"<p>This step is managed through Devant and it focuses on preparing documents for efficient retrieval in the RAG system.</p> <ul> <li>Chunk the information into smaller, meaningful sections</li> <li>Convert each chunk into embeddings using an embedding model</li> <li>Store embeddings in the vector database for efficient retrieval</li> </ul> <p>We assume that you've already used Devant to process and ingest the documents. Devant handles the entire ingestion process independently of the main application flow. The following steps of the tutorial focus solely on RAG retrieval.</p>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#rag-retrieval","title":"RAG retrieval","text":"<p>This tutorial focuses on implementing the retrieval component of a Retrieval-Augmented Generation (RAG) system using the WSO2 Integrator: BI.</p> <ul> <li>Convert the user's question into embeddings</li> <li>Perform a similarity search in the vector database</li> <li>Fetch the most relevant chunks</li> <li>Include only the relevant data in the prompt</li> <li>Generate a fact-grounded answer using the LLM</li> </ul> <p>By the end of this tutorial, you'll have a working RAG system that can retrieve relevant information and generate accurate, grounded responses using pre-ingested documents.</p>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#prerequisites","title":"Prerequisites","text":"<ul> <li>Access to Pinecone vector database (requires API key and service URL)</li> <li>Access to Azure OpenAI (requires API key and endpoint URL)</li> <li>Access to Devant</li> </ul>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#step-1-create-an-http-service","title":"Step 1: Create an HTTP service","text":"<ol> <li>In the design view, click on the Add Artifact button.</li> <li>Select HTTP Service under the Integration as API category.</li> <li>Select the Create and use the default HTTP listener (port:9090) option from the Listeners dropdown.</li> <li>Select the Design from Scratch option as the Service Contract and use <code>/personalAssistant</code> as the Service base path.</li> <li> <p>Click on the Create button to create the new service with the specified configurations.</p> <p></p> </li> <li> <p>The service will have a default resource named <code>greeting</code> with the GET method.</p> </li> <li>Click the Edit FunctionModel button in front of <code>/greeting</code> resource.</li> <li>Change the resource HTTP method to POST.</li> <li>Change the resource name to <code>chat</code>.</li> <li>Click on Add Parameter under the Parameters and specify the parameters you need. Select the Param Type as QUERY and specify <code>request</code> as the name and <code>ChatRequestMessage</code> as the type.</li> <li>Change the 200 response return type to <code>string</code>.</li> <li> <p>Click on the Save button to update the resource with the specified configurations.</p> <p></p> </li> </ol> <p>Note</p> <p>Here we use a modular approach for the resource logic for the <code>/chat</code> resource. You may use your own logic calling directly in the <code>/chat</code> service without creating functions separately.</p> <p>This approach allows for flexibility in implementation - you can either:</p> <ul> <li>Follow the modular pattern shown in this tutorial for better organization and maintainability</li> <li>Implement your logic directly within the <code>/chat</code> resource function based on your specific requirements</li> </ul>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#step-2-implementation-of-rag","title":"Step 2: Implementation of RAG","text":""},{"location":"integration-guides/ai/rag/build-a-rag-application/#21-retrieve-embeddings-for-user-query","title":"2.1 Retrieve embeddings for user query","text":"<p>Follow these steps to create a function that retrieves embeddings using Azure OpenAI:</p>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#211-create-an-embeddings-function","title":"2.1.1 Create an embeddings function","text":"<ol> <li>Click the + button in the Integrator side panel under the Functions section.</li> <li> <p>Provide the required details to create the function. Use <code>getEmbeddings</code> as the function name and specify the parameters and return types.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#212-add-embeddings-connection","title":"2.1.2 Add embeddings connection","text":"<ol> <li>Click the + button and select the + Add Connection in the side panel.</li> <li>Select the connector Embeddings - ballerinax/azure.openai.embeddings.</li> </ol>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#213-configure-the-embeddings-connector","title":"2.1.3 Configure the embeddings connector","text":"<ol> <li>In the configuration of the connector, under the Config select the Add Expression to open the Expression Helper window.</li> <li>In the Expression Helper, navigate to Configurables, click the Create new configurable variable. Here we create <code>azure_api_key</code> and <code>azure_service_url</code>.</li> <li>Select the ConnectionConfig under the Construct Record in the Expression Helper window.</li> <li>Change the BearerTokenConfig to ApiKeysConfig in the auth.</li> <li>Select the Configurables and click the <code>azure_api_key</code>.</li> <li>Expand the Advanced Configurations section. Under the ServiceUrl select the Add Expression to open the Expression Helper window.</li> <li> <p>In the Expression Helper, navigate to Configurables, select on <code>azure_service_url</code> as the value for ServiceUrl and click Save button.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#214-implement-the-embeddings-function-logic","title":"2.1.4 Implement the embeddings function logic","text":"<ol> <li>Click the + button and select the Declare Variable under the Statement.</li> <li>Create variable name as <code>embeddingsBody</code> and specify its type and expression.</li> <li>Click the + button and select the <code>embeddingsClient</code>.</li> <li>Configure the client with the DeploymentId, payload and API version.</li> <li>Configure the function to convert the returned decimal embeddings to float values.</li> <li>Return the final float array.</li> </ol>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#22-retrieve-relevant-chunks-from-vector-database","title":"2.2 Retrieve relevant chunks from vector database","text":"<p>Follow these steps to create a function that retrieves similar vectors from Pinecone using vector embeddings:</p>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#221-add-pinecone-vector-connection","title":"2.2.1 Add Pinecone vector connection","text":"<ol> <li>Click the + button in the Integrator side panel under the Connections section.</li> <li>Select the connector Vector - ballerinax/pinecone.vector.</li> </ol>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#222-configure-the-connector","title":"2.2.2 Configure the connector","text":"<ol> <li>In the configuration of the connector, under the ApiKeyConfig select the Add Expression to open the Expression Helper window.</li> <li>Select the Configurables and click the Create new configurable variable. Here we create <code>pinecone_api_key</code> and <code>pinecone_url</code>.</li> <li>Select the ConnectionConfig under the Construct Record in the Expression Helper window.</li> <li>Click the ApiKeysConfig in the auth, select the Configurables and click the <code>pinecone_api_key</code>.</li> <li> <p>Enter the <code>pinecone_url</code> as ServiceUrl and save it.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#223-create-a-retriever-function","title":"2.2.3 Create a retriever function","text":"<ol> <li>Click the + button in the Integrator side panel under the Functions section.</li> <li> <p>Provide the required details to create the function. Use <code>retrieveData</code> as the function name and specify the parameters and return types.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#224-implement-the-retriever-function-logic","title":"2.2.4 Implement the retriever function logic","text":"<ol> <li>Click the + button and select the <code>vectorClient</code>.</li> <li>Select Query from the vectorClient dropdown.</li> <li>Configure the vector client and specify the payload. Here, we use <code>{ topK: 4}</code> for the record QueryRequest.</li> <li>Extract the matches array from the QueryResponse.</li> <li>Handle null response scenarios with appropriate error handling.</li> <li> <p>Return the relevant matching array from the client response.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#23-augment-queries-with-relevant-chunks","title":"2.3 Augment queries with relevant chunks","text":"<p>Follow these steps to create a function that augments queries with relevant text chunks from vector search results:</p>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#231-create-an-augment-function","title":"2.3.1 Create an augment function","text":"<ol> <li>Click the + button in the Integrator side panel under the Functions section.</li> <li>Create the function with <code>augment</code> as the function name and specify the parameter type and return type.</li> </ol>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#232-implement-the-augment-function-logic","title":"2.3.2 Implement the augment function logic","text":"<ol> <li>Create an empty string variable named <code>context</code>.</li> <li>Add a foreach loop to process each match in the input array.</li> <li>Extract metadata from each match and convert to the appropriate type.</li> <li>Concatenate the text from metadata to the context string.</li> <li> <p>Return the aggregated context string with all relevant text chunks.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#24-generate-response-using-the-context","title":"2.4 Generate response using the context","text":""},{"location":"integration-guides/ai/rag/build-a-rag-application/#241-add-chat-client-connection","title":"2.4.1 Add chat client connection","text":"<ol> <li>Click the + button in the Integrator side panel under the Connections section.</li> <li>Select the connector Chat - ballerinax/azure.openai.chat.</li> <li>In the configuration of the connector, under the Config select the ConnectionConfig under the Construct Record in the Expression Helper window.</li> <li>Change the BearerTokenConfig to ApiKeysConfig in the auth.</li> <li>Select the Configurables and click the <code>azure_api_key</code>.</li> <li> <p>Expand the Advanced Configurations and Enter the <code>azure_service_url</code> as ServiceUrl and save it.</p> <p></p> </li> </ol> Model Flexibility<p>While this tutorial demonstrates Azure OpenAI integration, the same principles apply to other AI providers. You can adapt this implementation to work with:</p> <ul> <li>OpenAI API </li> <li>Anthropic's Claude API</li> <li>Google's PaLM API</li> <li>Local models (via APIs like Ollama)</li> <li>Other cloud AI services</li> </ul> <p>Simply replace the connector and adjust the API configuration parameters according to your chosen provider's requirements.</p>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#242-create-a-generate-function","title":"2.4.2 Create a generate function","text":"<ol> <li>Click the + button in the Integrator side panel under the Functions section.</li> <li>Create the function with <code>generateText</code> as the function name and specify the parameters and return types.</li> </ol>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#243-implement-the-generate-function-logic","title":"2.4.3 Implement the generate function logic","text":"<ol> <li>Create variables such as <code>systemPrompt</code> and <code>chatRequest</code>.</li> <li>Click the + button and select the <code>chatClient</code>.</li> <li>Select Creates a completion for the chat message from the chatClient dropdown.</li> <li>Configure the client and specify the DeploymentId, API version, and payload.</li> <li>Return the chat response from the client.</li> </ol>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#step-3-create-the-combined-llm-function","title":"Step 3: Create the combined LLM function","text":""},{"location":"integration-guides/ai/rag/build-a-rag-application/#31-create-the-llm-function","title":"3.1 Create the LLM function","text":"<ol> <li>Click the + button in the Integrator side panel under the Functions section.</li> <li> <p>Create the function with <code>llmChat</code> as the function name and specify the parameters and return types.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#32-implement-the-function-logic","title":"3.2 Implement the function logic","text":"<p>This function orchestrates the entire RAG (Retrieval-Augmented Generation):</p> <ol> <li>Get Embeddings: Call the <code>getEmbeddings</code> function with the user query to convert it into vector embeddings.</li> <li>Retrieve Data: Use the embeddings to query the vector database through the <code>retrieveData</code> function to get relevant document chunks.</li> <li>Augment Context: Process the retrieved chunks using the <code>augment</code> function to create a consolidated context string.</li> <li>Generate Response: Call the <code>generateText</code> function with both the original query and the augmented context to generate the final response.</li> <li> <p>Return Result: Return the generated response string.</p> <p></p> </li> </ol> <p>This completes the end-to-end RAG where user queries are processed through embeddings, vector search, context augmentation, and LLM generation before returning intelligent responses through the HTTP API.</p>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#step-4-integrate-with-http-service","title":"Step 4: Integrate with HTTP service","text":""},{"location":"integration-guides/ai/rag/build-a-rag-application/#41-update-the-chat-resource","title":"4.1 Update the chat resource","text":"<p>Go back to the HTTP service created in Step 1. In the <code>/chat</code> resource implementation:</p> <ol> <li>Call the <code>llmChat</code> function with the user's query.</li> <li> <p>Return the chat response.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#step-5-run-the-integration-and-query-the-rag","title":"Step 5: Run the integration and query the RAG","text":"<ol> <li>Click on the Run button in the top-right corner to run the integration.</li> <li>If you have added any variables to the project, you\u2019ll be prompted to update their values in the <code>Config.toml</code> file. Configure them to continue with the execution of the request.</li> <li> <p>Query the RAG by sending the curl request below.</p> <pre><code>curl --location 'http://localhost:9090/personalAssistant/chat' \\\n--header 'Content-Type: application/json' \\\n--data '{\"message\": \"What is the process for reporting safety concerns?\"}'\n</code></pre> <p></p> </li> </ol> <p>Response May Vary</p> <p>Since this integration involves an LLM (Large Language Model) call, the response values may not always be identical across different executions.</p> <p>Your RAG system is now ready to answer questions using retrieved context from your vector database!</p>"},{"location":"integration-guides/ai/rag/rag-ingestion/","title":"RAG Ingestion","text":"<p>In this tutorial, you'll build a Retrieval-Augmented Generation (RAG) ingestion pipeline using WSO2 Integrator: BI. The pipeline loads content from a file, chunks them into smaller sections, generates embedding and stores those embeddings in a vector knowledge base for efficient retrieval.</p> <p>By the end of this tutorial, you'll have created a complete ingestion flow that reads a markdown file, processes the content, and stores it in a vector store for use in RAG applications.</p> <p>Note</p> <p>This tutorial focuses solely on the ingestion aspect of RAG. Retrieval and querying will be covered in a separate guide. The ingestion pipeline is designed using WSO2 Integrator: BI's low-code interface, allowing you to visually orchestrate each step with ease.</p>"},{"location":"integration-guides/ai/rag/rag-ingestion/#prerequisites","title":"Prerequisites","text":"<p>To get started, you need a knowledge file (in Markdown format) that you want to ingest into the vector store.</p> <p>Note: This tutorial uses an in-memory vector store for simplicity, but you can also use external vector stores like Pinecone, Milvus, or Weaviate.</p> <p>What is an In-Memory Vector Store?</p> <p>An in-memory vector store holds your data (the chunked and embedded text) directly in your computer's active memory (RAM). This makes it very fast and easy to set up, as it requires no external databases or services. However, this data is temporary\u2014it will be completely erased when you stop the integration or close the project. </p>"},{"location":"integration-guides/ai/rag/rag-ingestion/#step-1-create-a-new-integration-project","title":"Step 1: Create a new integration project","text":"<ol> <li>Click on the BI icon in the sidebar.</li> <li>Click on the Create New Integration button.</li> <li>Enter the project name as <code>rag_ingestion</code>.</li> <li>Select a directory location by clicking on the Select Path button.</li> <li> <p>Click Create New Integration to generate the project.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/rag/rag-ingestion/#step-2-create-an-automation","title":"Step 2: Create an automation","text":"<p>In WSO2 Integrator: BI, an automation is a flow that runs automatically when the integration starts. We will use this to ensure our data is loaded and ingested into the knowledge base as soon as the application is running, making it ready for the query service.</p> <ol> <li>In the design screen, click on + Add Artifact.</li> <li>Select Automation under the Automation artifact category.</li> <li> <p>Click Create to open the flow editor.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/rag/rag-ingestion/#step-3-create-a-text-data-loader","title":"Step 3: Create a text data loader","text":"<ol> <li>Hover over the flow line and click the + icon to open the side panel.</li> <li>Click on Data Loader from the AI section.</li> <li>Click + Add Data Loader to create a new instance.</li> <li>Choose Text Data Loader.</li> <li>Under the paths field, click on + Add Another Value and add the path to your markdown file.</li> <li>Set Data Loader Name as <code>loader</code>.</li> <li> <p>Click Save to continue.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/rag/rag-ingestion/#step-4-load-data-using-the-data-loader","title":"Step 4: Load data using the data loader","text":"<ol> <li>In the Data Loaders section, click on <code>loader</code>.</li> <li>Click on load to open the configuration panel.</li> <li>Name the result as <code>doc</code>.</li> <li> <p>Click Save to complete the data loading step.</p> <p></p> </li> </ol> <p>This step wraps the file content into a <code>ai:Document</code> record, preparing it for chunking and embedding.</p> <p>Note</p> <p>In WSO2 Integrator: BI, an <code>ai:Document</code> is a generic container that wraps the content of any data source\u2014such as a file, webpage, or database entry. It not only holds the main content but can also include additional metadata, which becomes useful during retrieval operations in RAG workflows. In this tutorial, no metadata is used.</p>"},{"location":"integration-guides/ai/rag/rag-ingestion/#step-5-create-a-vector-knowledge-base","title":"Step 5: Create a vector knowledge base","text":"<p>A vector knowledge base in WSO2 Integrator: BI acts as an interface to a vector store and manages the ingestion and retrieval of documents.</p> <p>Note</p> <p>This tutorial uses an In-Memory Vector Store for simplicity and to get you started quickly. For production use cases or persistent storage, you can choose from other supported vector stores including Pinecone, Milvus, Weaviate, and more. Simply select your preferred option when creating the vector store in step 4 below.</p> <p>When using external vector stores, you may need to provide API keys and other configuration details. It's recommended to externalize sensitive values like API keys using configurables to avoid exposing them in your project files. See Configurations for more information.</p> <ol> <li>Hover over the flow line and click the + icon.</li> <li>Select Vector Knowledge Bases under the AI section.</li> <li>Click + Add Vector Knowledge Base to create a new instance.</li> <li>In the Vector Store section, click + Create New Vector Store and choose InMemory Vector Store, then click Save to create the vector store. This will return you to the vector knowledge base configuration.</li> <li>In the Embedding Model section, click + Create New Embedding Model, select Default Embedding Provider (WSO2), then click Save.</li> <li>For the Chunker setting, you can leave it at the default value of AUTO or create a new chunker if needed.</li> <li>Set the Vector Knowledge Base Name to <code>knowledgeBase</code>.</li> <li> <p>Click Save to complete the configuration.</p> <p></p> </li> </ol> <p>Embedding Dimensions</p> <p>The Default Embedding Provider (WSO2) generates dense vectors with 1536 dimensions. If you're using an external vector store (Pinecone, Milvus, Weaviate, etc.), ensure your vector store index is configured to support 1536-dimensional vectors.</p>"},{"location":"integration-guides/ai/rag/rag-ingestion/#step-6-ingest-data-into-the-knowledge-base","title":"Step 6: Ingest data into the knowledge base","text":"<ol> <li>In the Vector Knowledge Bases section, click on <code>knowledgeBase</code>.</li> <li>Click on ingest to open the configuration panel.</li> <li>Provide <code>doc</code> as the input for Documents.</li> <li> <p>Click Save to complete the ingestion step.</p> <p></p> </li> </ol> <p>This step chunks the document and sends them to the vector store, converting each chunk into an embedding and storing them for future retrieval.</p>"},{"location":"integration-guides/ai/rag/rag-ingestion/#step-7-add-a-confirmation-message","title":"Step 7: Add a confirmation message","text":"<ol> <li>Hover over the flow line and click the + icon.</li> <li>Select Log Info under the Logging section.</li> <li>Enter <code>\"Ingestion completed.\"</code> in the Msg field.</li> <li> <p>Click Save.</p> <p></p> </li> </ol> <p>This step will print a confirmation once the ingestion is complete.</p>"},{"location":"integration-guides/ai/rag/rag-ingestion/#step-8-configure-default-wso2-provider-and-run-the-integration","title":"Step 8: Configure default WSO2 provider and run the integration","text":"<ol> <li>As the workflow uses the <code>Default Embedding Provider (WSO2)</code>, you need to configure its settings:<ul> <li>Press <code>Ctrl/Cmd + Shift + P</code> to open the VS Code command palette.</li> <li>Run the command: <code>Ballerina: Configure default WSO2 model provider</code>.    This will automatically generate the required configuration entries.</li> </ul> </li> <li>Click the Run button in the top-right corner to execute the integration.</li> <li> <p>Once the integration runs successfully, you will see the message <code>\"Ingestion completed.\"</code> in the console.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/rag/rag-query/","title":"RAG Query","text":"<p>In this tutorial, you'll build a simple Retrieval-Augmented Generation (RAG) query flow using WSO2 Integrator: BI. You'll create an HTTP service that retrieves relevant information from a previously ingested vector knowledge base and uses a Large Language Model (LLM) to generate a context-aware response.</p> <p>By the end of this tutorial, you'll have a working integration that takes a user query, retrieves relevant chunks from the knowledge base, and returns a natural language answer using the configured LLM.</p>"},{"location":"integration-guides/ai/rag/rag-query/#prerequisites","title":"Prerequisites","text":"<p>To get started, make sure you have completed the following steps:</p> <ul> <li>Completed the RAG Ingestion Tutorial.</li> </ul> <p>Using the Same Project</p> <p>Since this tutorial uses an In-Memory Vector Store (as configured in the ingestion tutorial), the ingested data is only available within the same integration project and runtime session. You'll need to add the HTTP service to the same <code>rag_ingestion</code> project you created in the previous tutorial, rather than creating a new project.</p> <p>If you used an external vector store like Pinecone, Milvus, or Weaviate in the ingestion tutorial, you can create a separate project and configure the same external vector store connection.</p>"},{"location":"integration-guides/ai/rag/rag-query/#step-1-open-your-existing-integration-project","title":"Step 1: Open your existing integration project","text":"<ol> <li>Open the <code>rag_ingestion</code> project that you created in the RAG Ingestion Tutorial.</li> <li>When you run this integration, the ingestion automation will execute first, automatically loading your data into the in-memory vector store before the HTTP service becomes available.</li> </ol>"},{"location":"integration-guides/ai/rag/rag-query/#step-2-create-an-http-service","title":"Step 2: Create an HTTP service","text":"<ol> <li>In the design view, click on the Add Artifact button.</li> <li>Select HTTP Service under the Integration as API category.</li> <li>Choose Create and use the default HTTP listener from the Listener dropdown.</li> <li>Select Design from Scratch as the Service contract option.</li> <li>Specify the Service base path as <code>/</code>.</li> <li> <p>Click Create to create the service.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/rag/rag-query/#step-3-update-the-resource-method","title":"Step 3: Update the resource method","text":"<ol> <li>The service will have a default resource named <code>greeting</code> with the GET method. Click the edit button next to the <code>/greeting</code> resource.</li> <li>Change the HTTP method to POST.</li> <li>Rename the resource to <code>query</code>.</li> <li>Add a payload parameter named <code>userQuery</code> of type <code>string</code>.</li> <li>Keep others set to defaults.</li> <li> <p>Click Save to apply the changes.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/rag/rag-query/#step-4-retrieve-data-from-the-knowledge-base","title":"Step 4: Retrieve data from the knowledge base","text":"<p>Since you're working in the same project where you completed the ingestion tutorial, the vector knowledge base <code>knowledgeBase</code> that you created earlier is already available. You can use it to retrieve relevant chunks based on the user query.</p> <ol> <li>Click on the newly created <code>POST</code> resource to open it in the flow diagram view.</li> <li>Hover over the flow line and click the + icon.</li> <li>Select Vector Knowledge Bases under the AI section.</li> <li>In the Vector Knowledge Bases section, click on <code>knowledgeBase</code>.</li> <li>Click on retrieve to open the configuration panel.</li> <li>Set the Query input to the <code>userQuery</code> variable.</li> <li>Set the Result to <code>context</code> to store the matched chunks in a variable named <code>context</code>.</li> <li> <p>Click Save to complete the retrieval step.</p> <p></p> </li> </ol> <p>Using External Vector Stores</p> <p>If you have an external vector store (Pinecone, Milvus, Weaviate, etc.) with pre-ingested content, you can create a new vector knowledge base by clicking + Add Vector Knowledge Base and following the instructions in Step 5 of the RAG Ingestion Tutorial. Make sure to configure the same vector store and embedding provider settings that were used during ingestion.</p>"},{"location":"integration-guides/ai/rag/rag-query/#step-5-augment-the-user-query-with-retrieved-content","title":"Step 5: Augment the user query with retrieved content","text":"<p>WSO2 Integrator: BI includes a built-in function to augment the user query with retrieved context from the knowledge base. We'll use that in this step.</p> <ol> <li>Hover over the flow line and click the + icon.</li> <li>Select Augment Query under the AI section.</li> <li>Set Context to <code>context</code>.</li> <li>Set Query to <code>userQuery</code>.</li> <li>Set Result to <code>augmentedUserMsg</code>.</li> <li> <p>Click Save to complete the augmentation step.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/rag/rag-query/#step-6-connect-to-an-llm-provider","title":"Step 6: Connect to an LLM provider","text":"<p>After augmenting the query with retrieved context, we can now pass it to an LLM for a grounded response. WSO2 Integrator: BI provides an abstraction called <code>Model Provider</code> to connect with various LLM services.</p> <ol> <li>Hover over the flow line and click the + icon.</li> <li>Select Model Provider under the AI section.</li> <li>Click + Add Model Provider to create a new instance.</li> <li>Select <code>Default Model Provider (WSO2)</code> \u2014 a WSO2-hosted LLM \u2014 for this tutorial.</li> <li>Set the Model Provider Name to <code>defaultModel</code>.</li> <li> <p>Click Save to complete the configuration.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/rag/rag-query/#step-7-generate-the-response","title":"Step 7: Generate the response","text":"<p>Now send the augmented query to the LLM to generate the grounded response.</p> <ol> <li>Click on the <code>defaultModel</code> under the Model Providers section in the side panel.</li> <li>Select the <code>generate</code> action.</li> <li>Set the Prompt to the expression: <code>check augmentedUserMsg.content.ensureType()</code>.</li> <li>Set the Result variable to <code>response</code>.</li> <li>Set the Expected Type to <code>string</code>.</li> <li> <p>Click Save.</p> <p></p> </li> </ol> <p>Understanding the Expression</p> <p>The expression <code>check augmentedUserMsg.content.ensureType()</code> extracts the augmented query content and ensures it's in the correct string format that the LLM expects. The <code>check</code> keyword handles any potential type conversion errors.</p>"},{"location":"integration-guides/ai/rag/rag-query/#step-8-return-the-response-from-the-service-resource","title":"Step 8: Return the response from the service resource","text":"<ol> <li>Hover over the flow line and click the + icon.</li> <li>Under the Control section, click on Return.</li> <li> <p>Set Expression to <code>response</code>.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/rag/rag-query/#step-9-configure-default-wso2-providers-and-run-the-integration","title":"Step 9: Configure default WSO2 providers and run the integration","text":"<ol> <li>As the workflow uses the <code>Default Model Provider (WSO2)</code> and <code>Default Embedding Provider (WSO2)</code>, you need to configure its settings:<ul> <li>Press <code>Ctrl/Cmd + Shift + P</code> to open the VS Code command palette.</li> <li>Run the command: <code>Ballerina: Configure default WSO2 model provider</code>.    This will automatically generate the required configuration entries.</li> </ul> </li> <li>Click the Run button in the top right corner to start the integration.</li> <li>The integration will compile and launch in the embedded Ballerina runtime. The ingestion automation will run first, followed by the HTTP service.</li> <li>You can also test the service using tools like Postman or curl:    <pre><code>curl -X POST http://localhost:9090/query -H \"Content-Type: application/json\" -d '\"Who should I contact for refund approval?\"'\n</code></pre></li> <li> <p>To stop the integration, click the \u23f9\ufe0f button or press <code>Shift + F5</code>.</p> <p></p> </li> </ol>"},{"location":"integration-guides/file-integration/file-integration-with-directory-service/","title":"File Integration With Directory Service","text":"<p>In this section, we will learn how to create a file integration using the WSO2 Integrator: BI. The integration will listen to events in a directory and will be triggered when an file related event occurs.</p>"},{"location":"integration-guides/file-integration/file-integration-with-directory-service/#step-1-create-a-new-integration-project","title":"Step 1: Create a new integration project","text":"<ol> <li>Click on the BI icon on the sidebar.</li> <li>Click on the Create New Integration button.</li> <li>Enter the project name as <code>FileIntegration</code>.</li> <li>Select Project Directory and click on the Select Location button.</li> <li>Click on the Create New Integration button to create the integration project.</li> </ol>"},{"location":"integration-guides/file-integration/file-integration-with-directory-service/#step-2-create-an-directory-service","title":"Step 2: Create an Directory service","text":"<ol> <li>In the design view, click on the Add Artifact button.</li> <li>Select Directory Service under the File Integration category.</li> <li>Enter the listener name as <code>directoryListener</code>.</li> <li>Enter the path to the directory you want to monitor. For example, <code>\"/home/user/Downloads\"</code>.</li> <li>Click on the Next button to create the directory service.</li> <li> <p>Keep the default listener in the Listener Configuration window and click on the Create button to create the directory service.</p> <p></p> </li> </ol>"},{"location":"integration-guides/file-integration/file-integration-with-directory-service/#step-3-configure-file-event-resources","title":"Step 3: Configure file event resources","text":"<ol> <li>Navigate to the <code>directoryListener</code> service  under the Entry Points section and click on the +Function  button.</li> <li>Select onCreate from Available Functions dropdown and click on the Save button.</li> <li>Click on the onCreate function to navigate to the function implementation designer view.</li> <li>Click on + and select Log Info from the node panel under Logging category.</li> <li>Add the log message as <code>\"File created \"+ event.name</code> in the Msg field.</li> <li> <p>Click on the Save button to add the log action to the function.</p> <p></p> </li> <li> <p>Repeat the above steps to add the onDelete and onModify functions to the service.</p> </li> <li>Add the log message as <code>\"File deleted \"+ event.name</code> in the Msg field for the onDelete function.</li> <li>Add the log message as <code>\"File modified \"+ event.name</code> in the Msg field for the onModify function.</li> <li> <p>The final service will look like this:      </p> <p></p> </li> </ol>"},{"location":"integration-guides/file-integration/file-integration-with-directory-service/#step-4-run-the-integration","title":"Step 4: Run the integration","text":"<ol> <li>Click on the Run button in the top-right corner to run the integration.</li> <li>The integration will start listening to the events in the directory specified in step 2. </li> <li>Create a new file in the directory to trigger the onCreate event.</li> <li>Modify the file to trigger the onModify event.</li> <li>Delete the file to trigger the onDelete event.</li> <li> <p>The log messages will be displayed in the console.   </p> <p></p> </li> </ol>"},{"location":"integration-guides/integration-as-api/message-routing/","title":"Content-Based Message Routing","text":""},{"location":"integration-guides/integration-as-api/message-routing/#overview","title":"Overview","text":"<p>In this tutorial, you'll create a service that allows users to reserve appointments at various hospitals. Requests will be directed to the appropriate hospital based on the request payload's content. To accomplish this, you\u2019ll build a REST service with a single resource in WSO2 Integrator: BI extension. The resource will handle user requests, identify the hospital endpoint based on the hospital ID, forward the request to the specified hospital service to make the reservation, and return the reservation details.</p> <p>Here\u2019s an overview of the process flow.</p> <p></p> <ol> <li> <p>Receive a request with a JSON payload similar to the following.</p> <p>ReservationRequest.json<pre><code>{\n\"patient\": {\n\"name\": \"John Doe\",\n\"dob\": \"1940-03-19\",\n\"ssn\": \"234-23-525\",\n\"address\": \"California\",\n\"phone\": \"8770586755\",\n\"email\": \"johndoe@gmail.com\"\n},\n\"doctor\": \"thomas collins\",\n\"hospital\": \"grand oak community hospital\",\n\"hospital_id\": \"grandoak\",\n\"appointment_date\": \"2023-10-02\"\n}\n</code></pre> 2. Extract the <code>hospital_id</code> field and select the corresponding hospital service endpoint.</p> <ul> <li>grandoak -&gt; <code>http://localhost:9090/grandoak/categories</code></li> <li>clemency -&gt; <code>http://localhost:9090/clemency/categories</code></li> <li>pinevalley -&gt; <code>http://localhost:9090/pinevalley/categories</code> </li> </ul> </li> <li> <p>Forward the request to the selected hospital service and retrieve the response which will be similar to the following.</p> ReservationResponse.json<pre><code>{\n\"appointmentNumber\": 8,\n\"doctor\": {\n\"name\": \"thomas collins\",\n\"hospital\": \"grand oak community hospital\",\n\"category\": \"surgery\",\n\"availability\": \"9.00 a.m - 11.00 a.m\",\n\"fee\": 7000.0\n},\n\"patientName\": \"John Doe\",\n\"hospital\": \"grand oak community hospital\",\n\"confirmed\": false,\n\"appointmentDate\": \"2023-10-02\"\n}\n</code></pre> </li> </ol>"},{"location":"integration-guides/integration-as-api/message-routing/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker installed on your machine.</li> </ul>"},{"location":"integration-guides/integration-as-api/message-routing/#step-1-create-a-new-integration-project","title":"Step 1: Create a new integration project","text":"<ol> <li>Click on the BI icon on the sidebar.</li> <li>Click on the Create New Integration button.</li> <li>Enter the project name as <code>MessageRouting</code>.</li> <li>Select Project Directory and click on the Select Location button.</li> <li>Click on the Create New Integration button to create the integration project.</li> </ol>"},{"location":"integration-guides/integration-as-api/message-routing/#step-2-create-an-http-service","title":"Step 2: Create an HTTP service","text":"<ol> <li>In the design view, click on the Add Artifact button.</li> <li>Select HTTP Service under the Integration as API category.</li> <li>Select the + Listeners option from the Listeners dropdown to add a new listener.</li> <li>Enter the listener name as <code>healthListener</code>, <code>8290</code> as the port and click on the Create button. </li> <li>Add the service base path as <code>/healthcare</code> and select the Design from Scratch option as the The contract of the service.</li> <li>Click on the Create button to create the new service with the specified configurations.</li> </ol>"},{"location":"integration-guides/integration-as-api/message-routing/#step-3-define-types","title":"Step 3: Define types","text":"<ol> <li>Click on the Add Artifacts button and select Type in the Other Artifacts section.</li> <li>Click on + Add Type to add a new type</li> <li>Add the Name as <code>ReservationRequest</code> and paste the following JSON payload. Click on the Import button.    <pre><code> {\n\"patient\": {\n\"name\": \"John Doe\",\n\"dob\": \"1940-03-19\",\n\"ssn\": \"234-23-525\",\n\"address\": \"California\",\n\"phone\": \"8770586755\",\n\"email\": \"johndoe@gmail.com\"\n},\n\"doctor\": \"thomas collins\",\n\"hospital\": \"grand oak community hospital\",\n\"hospital_id\": \"grandoak\",\n\"appointment_date\": \"2023-10-02\"\n}\n</code></pre></li> <li>Repeat the above steps to add a new type named <code>ReservationResponse</code> with the following JSON payload.     <pre><code>{\n\"appointmentNumber\": 8,\n\"doctor\": {\n\"name\": \"thomas collins\",\n\"hospital\": \"grand oak community hospital\",\n\"category\": \"surgery\",\n\"availability\": \"9.00 a.m - 11.00 a.m\",\n\"fee\": 7000.0\n},\n\"patientName\": \"John Doe\",\n\"hospital\": \"grand oak community hospital\",\n\"confirmed\": false,\n\"appointmentDate\": \"2023-10-02\"\n}\n</code></pre></li> <li> <p>The final Type diagram will look like below.     </p> <p></p> </li> </ol>"},{"location":"integration-guides/integration-as-api/message-routing/#step-4-add-connectors","title":"Step 4: Add connectors","text":"<ol> <li>Navigate to design view and click on the Add Artifacts button and select Connection in the Other Artifacts section.</li> <li>Search and select the HTTP Client connector.</li> <li>Enter the connector name as <code>grandOakEp</code>, URL as <code>\"http://localhost:9090/grandoak/categories\"</code>.</li> <li> <p>Click on the Save button to create the new connector with the specified configurations.</p> <p> 5. Repeat the above steps to add connectors for the <code>clemency</code> and <code>pinevalley</code> hospitals with the following configurations.</p> Connector Name URL clemencyEp <code>\"http://localhost:9090/clemency/categories\"</code> pineValleyEp <code>\"http://localhost:9090/pinevalley/categories\"</code> </li> <li> <p>The final connectors will look like below.     </p> <p></p> </li> </ol> HTTP Connector<p>To learn more about HTTP client, see Ballerina HTTP Client. See supported advanced client configurations in the HTTP Client Configurations.</p>"},{"location":"integration-guides/integration-as-api/message-routing/#step-5-add-a-resource-method","title":"Step 5: Add a resource method","text":"<ol> <li>The service will have a default resource named <code>greeting</code> with the GET method. Click on three dots appear in front of the <code>/healthCare</code> service resource and select Edit from menu.</li> <li>Then click the edit button in front of <code>/greeting</code> resource to edit the resource.</li> <li>Change the resource HTTP method to POST.</li> <li>Change the resource name as <code>categories/[string category]/reserve</code>.</li> <li>Add a payload parameter named <code>reservation</code> to the resource of type <code>ReservationRequest</code>.</li> <li>Change the 201 response return type to <code>ReservationResponse</code>.</li> <li>Add a new response of type HttpNotFound under the responses.</li> <li> <p>Click on the Save button to update the resource with the specified configurations.</p> <p></p> </li> </ol>"},{"location":"integration-guides/integration-as-api/message-routing/#step-6-add-the-routing-logic","title":"Step 6: Add the routing logic","text":"<ol> <li>Click on the <code>categories/[string category]/reserve</code> resource to navigate to the resource implementation designer view.</li> <li>Delete the default <code>Return</code> action from the resource.</li> <li>Hover to the arrow after start and click the \u2795 button to add a new action to the resource.</li> <li>Select Declare Variable from the node panel on the left. This variable will be used to store the request payload for the hospital service.</li> <li>Change the variable name to <code>hospitalRequset</code>, type as <code>json</code> and expression as below and click Save.     <pre><code>{\n    patient: reservation.patient.toJson(),\n    doctor: reservation.doctor,\n    hospital: reservation.hospital,\n    appointment_date: reservation.appointment_date\n}\n</code></pre></li> <li> <p>Add If from the node panel after <code>hospitalRequest</code> variable. Enter the conditions as If Else If blocks as below for each hospital.</p> <ul> <li>grandOak -&gt; <code>reservation.hospital_id == \"grandoak\"</code></li> <li>clemency -&gt; <code>reservation.hospital_id == \"clemency\"</code></li> <li>pineValley -&gt; <code>reservation.hospital_id == \"pinevalley\"</code> </li> </ul> <p></p> </li> <li> <p>Select the <code>grandOakEP</code> condition true path \u2795 sign and select grandOakEP connector from the node panel.</p> <p></p> </li> <li> <p>Select post from the dropdown. Then, fill in the required fields with the values given below and click Save.</p> Field Value Variable Name <code>oakEPResponse</code> Variable Type <code>ReservationResponse</code> Resource Path <code>string `/${category}/reserve`</code> message <code>hospitalRequset</code> </li> <li> <p>Click on the \u2795 sign again and select Return from the node panel. Select the <code>oakEPResponse</code> variable from the dropdown and click Save.</p> <p></p> </li> <li> <p>The steps above will add the routing logic for the <code>grandoak</code> hospital. A variable named <code>oakEPResponse</code> will store the response from the <code>grandoak</code> hospital service. The response will be returned to the client.</p> </li> <li> <p>Repeat the 7,8,9 steps for the <code>clemency</code> and <code>pinevalley</code> hospitals with the following configurations.</p> <p>clemency:</p> Field Value Variable Name <code>clemencyEPResponse</code> Variable Type <code>ReserveResponse</code> Resource Path <code>string `/${category}/reserve`</code> message <code>hospitalRequset</code> <p>pinevalley:</p> Field Value Variable Name <code>pineValleyEPResponse</code> Variable Type <code>ReserveResponse</code> Resource Path <code>string `/${category}/reserve`</code> message <code>hospitalRequset</code> </li> <li> <p>For the else condition, click on the <code>If</code> condition <code>Else</code> path \u2795 sign and add a Return from the node panel. Enter <code>http:NOT_FOUND</code> as the value and click Save.             </p> </li> <li> <p>The final design will look like below.             </p> <p></p> </li> </ol>"},{"location":"integration-guides/integration-as-api/message-routing/#step-7-run-the-service","title":"Step 7: Run the service","text":"<ol> <li>Start the backend service by executing the following command in a terminal.     <pre><code>docker run --name hospital-backend -p 9090:9090 -d anuruddhal/kola-hospital-backend\n</code></pre></li> <li>Click on the Run on the run button in the top right corner to run the service.</li> <li>The service will start and the service will be available at <code>http://localhost:8290/healthcare/categories/[category]/reserve</code>.</li> <li>Click on the Try it button to open the embedded HTTP client.</li> <li> <p>Replace the {category} with <code>surgery</code> in the resource path and enter the following JSON payload in the request body and click on the \u25b6\ufe0f button to send the request.     <pre><code>{\n\"patient\":{\n\"name\": \"John Doe\",\n\"dob\": \"1940-03-19\",\n\"ssn\": \"234-23-525\",\n\"address\": \"California\",\n\"phone\": \"8770586755\",\n\"email\": \"johndoe@gmail.com\"\n},\n\"doctor\": \"thomas collins\",\n\"hospital_id\": \"grandoak\",\n\"hospital\": \"grand oak community hospital\",\n\"appointment_date\": \"2023-10-02\"\n}\n</code></pre> </p> </li> <li> <p>The response will be similar to the following.    <pre><code>{\n\"appointmentNumber\": 1,\n\"doctor\": {\n\"name\": \"thomas collins\",\n\"hospital\": \"grand oak community hospital\",\n\"category\": \"surgery\",\n\"availability\": \"9.00 a.m - 11.00 a.m\",\n\"fee\": 7000.0\n},\n\"patient\": {\n\"name\": \"John Doe\",\n\"dob\": \"1940-03-19\",\n\"ssn\": \"234-23-525\",\n\"address\": \"California\",\n\"phone\": \"8770586755\",\n\"email\": \"johndoe@gmail.com\"\n},\n\"hospital\": \"grand oak community hospital\",\n\"confirmed\": false,\n\"appointmentDate\": \"2023-10-02\"\n}\n</code></pre></p> </li> <li>Optionally, you can test the service using curl command as below.    <pre><code> curl -X POST \"http://localhost:8290/healthcare/categories/surgery/reserve\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n \"patient\": {\n \"name\": \"John Doe\",\n \"dob\": \"1940-03-19\",\n \"ssn\": \"234-23-525\",\n \"address\": \"California\",\n \"phone\": \"8770586755\",\n \"email\": \"johndoe@gmail.com\"\n },\n \"doctor\": \"thomas collins\",\n \"hospital_id\": \"grandoak\",\n \"hospital\": \"grand oak community hospital\",\n \"appointment_date\": \"2023-10-02\"\n }'\n</code></pre></li> </ol>"},{"location":"integration-guides/integration-as-api/message-routing/#step-8-stop-the-integration","title":"Step 8: Stop the integration","text":"<ol> <li>Click on the Stop button to stop the integration.</li> <li>Stop the hospital backend server by running the following command:    <pre><code>docker stop hospital-backend\n</code></pre></li> </ol>"},{"location":"integration-guides/integration-as-api/message-transformation/","title":"Message Transformation","text":""},{"location":"integration-guides/integration-as-api/message-transformation/#overview","title":"Overview","text":"<p>This guide explains how to create a simple integration to convert a JSON payload to an XML payload using WSO2 Integrator: BI. An HTTP service with a single resource (<code>toXml</code>) will be created to accept a JSON payload and return the XML representation of the payload.</p> <p></p>"},{"location":"integration-guides/integration-as-api/message-transformation/#step-1-create-a-new-integration-project","title":"Step 1: Create a new integration project","text":"<ol> <li>Click on the BI icon on the sidebar.</li> <li>Click on the Create Integration button.</li> <li>Enter the project name as <code>JsonToXml</code>.</li> <li>Select project directory location by clicking on the Select Location button.</li> <li> <p>Click on the Create Integration button to create the integration project.</p> <p></p> </li> </ol>"},{"location":"integration-guides/integration-as-api/message-transformation/#step-2-create-a-http-service","title":"Step 2: Create a HTTP service","text":"<ol> <li>In the design view, click on the Add Artifact button.</li> <li>Select HTTP Service under the Integration as API category.</li> <li>Select the Create and use the default HTTP listener option from the Listener dropdown.</li> <li>Select Design from Scratch option as the The contract of the service.</li> <li>Specify the Service base path as <code>/convert</code>.</li> <li>Click on the Create button to create the new service with the specified configurations.</li> </ol>"},{"location":"integration-guides/integration-as-api/message-transformation/#step-3-update-the-resource-method","title":"Step 3: Update the resource method","text":"<ol> <li>The service will have a default resource named <code>greeting</code> with the GET method. Click on three dots appear in front of the <code>/convert</code> service resource and select Edit from menu.</li> <li> <p>Then click the edit button in front of <code>/greeting</code> resource.  </p> <p></p> </li> <li> <p>Change the resource HTTP method to POST.</p> </li> <li>Change the resource name as <code>toXml</code>.</li> <li>Add a payload parameter named <code>input</code> to the resource of type <code>json</code>. </li> <li>Change the 201 response return type to <code>xml</code>.</li> <li> <p>Click on the Save button to update the resource with the specified configurations.</p> <p></p> </li> </ol> <p>Resource Method</p> <p>To learn more about resources, see Ballerina Resources.</p>"},{"location":"integration-guides/integration-as-api/message-transformation/#step-4-add-the-transformation-logic","title":"Step 4: Add the transformation logic","text":"<ol> <li>Click on the <code>toXml</code> resource to navigate to the resource implementation designer view.</li> <li>Delete the default <code>Return</code> action from the resource.</li> <li>Hover to the arrow after start and click the \u2795 button to add a new action to the resource.</li> <li>Select Function Call from the node panel.</li> <li>Search for <code>json to xml</code> and select the fromJson function from the suggestions.</li> <li>Change the Variable Name to <code>xmlResult</code>, Variable Type as <code>xml</code> and JsonValue to <code>input</code>.</li> <li> <p>Click on the Save button to add the function call to the resource.</p> <p></p> </li> <li> <p>Add a new node after the <code>fromJson</code> function call and select Return from the node panel.</p> </li> <li> <p>Select the <code>xmlResult</code> variable from the dropdown and click Save.</p> <p></p> </li> </ol> <p>JSON to XML Conversion</p> <p>To learn more about json to xml conversion, see Ballerina JSON to XML conversion.</p>"},{"location":"integration-guides/integration-as-api/message-transformation/#step-5-run-the-integration","title":"Step 5: Run the integration","text":"<ol> <li>Click on the Run button in the top-right corner to run the integration.</li> <li>The integration will start and the service will be available at <code>http://localhost:9090/convert</code>.</li> <li>Click on the Try it button to open the embedded HTTP client.</li> <li>Enter the JSON payload in the request body and click on the \u25b6\ufe0f button to send the request.     <pre><code>{\n\"name\": \"John\",\n\"age\": 30,\n\"car\": \"Honda\"\n}\n</code></pre></li> <li> <p>The response will be an XML representation of the JSON payload. <code>&lt;root&gt;         &lt;name&gt;John&lt;/name&gt;         &lt;age&gt;30&lt;/age&gt;         &lt;car&gt;Honda&lt;/car&gt;     &lt;/root&gt;</code> </p> </li> <li> <p>Additionally, the service can be tested using tools like Postman or curl by sending a POST request with a JSON payload to the service endpoint.    <pre><code>curl -X POST \"http://localhost:9090/convert/toXml\" -H \"Content-Type: application/json\" -d '{\"name\":\"John\", \"age\":30, \"car\":\"Honda\"}'\n</code></pre></p> </li> </ol>"},{"location":"integration-guides/integration-as-api/service-orchestration/","title":"Service Orchestration","text":""},{"location":"integration-guides/integration-as-api/service-orchestration/#overview","title":"Overview","text":"<p>In this tutorial, you\u2019ll create a service to process appointment requests for hospitals. The service will call multiple backend services sequentially, using data from each call to inform the next. This approach integrates several services into one, known as service orchestration. To implement this, you\u2019ll build a REST service with a single resource in WSO2 Integrator: BI extension and then run the service. The resource will receive user requests, make the necessary backend calls, and respond with the appointment details.</p> <p>The flow is as follows.</p> <ol> <li>The user sends an appointment request to the service.     <pre><code>  {\n\"patient\": {\n\"name\": \"John Doe\",\n\"dob\": \"1940-03-19\",\n\"ssn\": \"234-23-525\",\n\"address\": \"California\",\n\"phone\": \"8770586755\",\n\"email\": \"johndoe@gmail.com\",\n\"cardNo\": \"7844481124110331\"\n},\n\"doctor\": \"thomas collins\",\n\"hospital_id\": \"grandoaks\",\n\"hospital\": \"grand oak community hospital\",\n\"appointment_date\": \"2024-11-06\"\n}\n</code></pre></li> <li>Extract the necessary details from the request (e.g., hospital, patient, doctor, etc.) and make a call to the hospital backend service to request an appointment. A response similar to the following will be returned from the hospital backend service on success.      <pre><code>  {\n\"appointmentNumber\": 1,\n\"doctor\": {\n\"name\": \"thomas collins\",\n\"hospital\": \"grand oak community hospital\",\n\"category\": \"surgery\",\n\"availability\": \"9.00 a.m - 11.00 a.m\",\n\"fee\": 7000\n},\n\"patient\": {\n\"name\": \"John Doe\",\n\"dob\": \"1940-03-19\",\n\"ssn\": \"234-23-525\",\n\"address\": \"California\",\n\"phone\": \"8770586755\",\n\"email\": \"johndoe@gmail.com\"\n},\n\"hospital\": \"grand oak community hospital\",\n\"confirmed\": false,\n\"appointmentDate\": \"2023-10-02\"\n}\n</code></pre></li> <li>Use the hospital ID and the appointment number and call the hospital backend service to retrieve the fee for the appointment. The response will be similar to the following.     <pre><code>  {\n\"patientName\": \"John Doe\",\n\"doctorName\": \"thomas collins\",\n\"actualFee\": \"7000\"\n}\n</code></pre></li> <li>Finally, call the payment backend service to make the payment and retrieve the reservation status.    <pre><code>  {\n\"appointmentNo\": 2,\n\"doctorName\": \"thomas collins\",\n\"patient\": \"John Doe\",\n\"actualFee\": 7000,\n\"discount\": 20,\n\"discounted\": 5600.0,\n\"paymentID\": \"f130e2ed-a34e-4434-9b40-6a0a8054ee6b\",\n\"status\": \"settled\"\n}\n</code></pre></li> </ol>"},{"location":"integration-guides/integration-as-api/service-orchestration/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker installed on the machine.</li> </ul>"},{"location":"integration-guides/integration-as-api/service-orchestration/#step-1-create-a-new-integration-project","title":"Step 1: Create a new integration project","text":"<ol> <li>Click on the BI icon on the sidebar.</li> <li>Click on the Create New Integration button.</li> <li>Enter the project name as <code>ServiceOrchestration</code>.</li> <li>Select project directory location by clicking on the Select Location button.</li> <li>Click on the Create New Integration button to create the integration project.</li> </ol>"},{"location":"integration-guides/integration-as-api/service-orchestration/#step-2-create-an-http-service","title":"Step 2: Create an HTTP service","text":"<ol> <li>In the design view, click on the Add Artifact button.</li> <li>Select HTTP Service under the Integration as API category.</li> <li>Select the + Listeners option from the Listeners dropdown to add a new listener.</li> <li>Enter the listener name as <code>healthListener</code>, <code>8290</code> as the port and click on the Create button.</li> <li>Add the service base path as <code>/healthcare</code> and select the Design from Scratch option as the The contract of the service.</li> <li> <p>Click on the Create button to create the new service with the specified configurations.</p> <p></p> </li> </ol>"},{"location":"integration-guides/integration-as-api/service-orchestration/#step-3-define-types","title":"Step 3: Define types","text":"<ol> <li> <p>Click on the Add Artifacts button and select Type in the Other Artifacts section.</p> <p></p> </li> <li> <p>Click on + Add Type to add a new type. Use expected JSON samples as follows to create types for the hospital appointment scenario, and make sure to select the JSON option from the format dropdown when creating them. The values are given below.</p> Name Sample JSON value ReservationRequest <code>{\"patient\":{\"name\":\"John Doe\",\"dob\":\"1940-03-19\",\"ssn\":\"234-23-525\",\"address\":\"California\",\"phone\":\"8770586755\",\"email\":\"johndoe@gmail.com\",\"cardNo\":\"7844481124110331\"},\"doctor\":\"thomas collins\",\"hospital_id\":\"grandoaks\",\"hospital\":\"grand oak community hospital\",\"appointment_date\":\"2024-11-06\"}</code> ReservationStatus <code>{\"appointmentNo\":1, \"doctorName\":\"thomas collins\", \"patient\":\"John Doe\", \"actualFee\":7000.0, \"discount\":20, \"discounted\":5600.0, \"paymentID\":\"e560ea82-1c42-4972-a471-af5c1ad4995f\", \"status\":\"settled\"}</code> Appointment <code>{\"appointmentNumber\":12345,\"doctor\":{\"name\":\"Dr. Alice Carter\",\"hospital\":\"Green Valley Hospital\",\"category\":\"Cardiology\",\"availability\":\"Mon-Fri, 9 AM - 5 PM\",\"fee\":200},\"patientName\":\"Emma Johnson\",\"hospital\":\"Green Valley Hospital\",\"confirmed\":true,\"appointmentDate\":\"2024-11-20T10:00:00\"}</code> Fee <code>{\"patientName\":\"Emma Johnson\",\"doctorName\":\"Dr. Alice Carter\",\"actualFee\":\"150.00\"}</code> </li> <li> <p>The final types will look like the following.   </p> <p></p> </li> </ol>"},{"location":"integration-guides/integration-as-api/service-orchestration/#step-4-add-connections","title":"Step 4: Add connections","text":"<ol> <li>Navigate to design view and click on the Add Artifacts button and select Connection in the Other Artifacts section.</li> <li>Search and select the HTTP Client connector.</li> <li> <p>Enter the Url as <code>http://localhost:9090</code>, Connection Name as <code>hospitalEp</code> and click on the Save button.</p> <p></p> </li> <li> <p>Add another connector for the payment backend service with the URL <code>http://localhost:9090/healthcare/payments</code> and the name <code>paymentEp</code>.    </p> <p></p> </li> </ol> HTTP Connector<p>To learn more about HTTP client, see Ballerina HTTP Client. See supported client configurations in the HTTP Client Configurations.</p>"},{"location":"integration-guides/integration-as-api/service-orchestration/#step-5-design-the-resource","title":"Step 5: Design the resource","text":"<ol> <li>The service will have a default resource named <code>greeting</code> with the GET method. Click on the three dots that appear in front of the <code>/healthCare</code> service resource and select Edit from the menu.</li> <li>Change the resource HTTP method to POST.</li> <li>Change the resource name as <code>categories/[string category]/reserve</code>.</li> <li>Add a payload parameter named <code>reservation</code> to the resource of type <code>ReservationRequest</code>.</li> <li>Change the 201 response return type to <code>ReservationStatus</code>.</li> <li> <p>Add a new response of type HttpNotFound under the responses.   </p> <p></p> </li> <li> <p>Click on the Save button to save the resource.   </p> <p></p> </li> </ol>"},{"location":"integration-guides/integration-as-api/service-orchestration/#step-6-make-the-appointment-request","title":"Step 6: Make the appointment request","text":"<ol> <li>Click on the <code>categories/[string category]/reserve</code> resource to navigate to the resource implementation designer view.</li> <li>Delete the default <code>Return</code> action from the resource.</li> <li>Hover to the arrow after start and click the \u2795 button to add a new action to the resource.</li> <li>Select Declare Variable from the node panel on the left. This variable will be used to store the request payload for the hospital service.</li> <li>Change the variable name to <code>hospitalRequest</code>, type as <code>json</code> and expression as below.     <pre><code>     {\n     patient:{\n         name: reservation.patient.name,\n         dob: reservation.patient.dob,\n         ssn: reservation.patient.ssn,\n         address: reservation.patient.address,\n         phone: reservation.patient.phone,\n         email: reservation.patient.email\n      },\n     doctor: reservation.doctor,\n     hospital: reservation.hospital,\n     appointment_date: reservation.appointment_date\n    }\n</code></pre></li> <li> <p>Click on the Save button to add the variable.   </p> <p></p> </li> <li> <p>Click \u2795 sign and select hospitalEp connector from the node panel and select post from the dropdown. Then, fill in the required fields with the values given below and click Save.</p> Field Value Variable Name <code>appointment</code> Variable Type <code>Appointment</code> Resource Path <code>string `/${reservation.hospital_id}/categories/${category}/reserve`</code> message <code>hospitalRequest</code> </li> <li> <p>The connector action will look like the following.   </p> <p> </p> </li> </ol>"},{"location":"integration-guides/integration-as-api/service-orchestration/#step-7-get-the-fee","title":"Step 7: Get the fee","text":"<ol> <li> <p>Declare an int variable named <code>appointmentNumber</code> with expression <code>appointment.appointmentNumber</code> after the hospital service request.  </p> <p> </p> </li> <li> <p>Let's add another connector invocation to get the fee for the appointment. Click on the \u2795 sign and select hospitalServicesEp connector from the node panel.  </p> </li> <li> <p>Select get from the dropdown. Then, fill in the required fields with the values given below and click Save.</p> Field Value Variable Name <code>fee</code> Variable Type <code>Fee</code> Resource Path <code>string `/${reservation.hospital_id}/categories/appointments/${appointmentNumber}/fee`</code> <p></p> </li> </ol>"},{"location":"integration-guides/integration-as-api/service-orchestration/#step-8-make-the-payment","title":"Step 8: Make the payment","text":"<ol> <li>Declare a decimal type variable named <code>actualFee</code> with expression <code>check decimal:fromString(fee.actualFee)</code> after the fee request. </li> <li> <p>Create another new to prepare the payment request. Click on the \u2795 sign and select Declare Variable from the node panel. Add a variable named <code>paymentRequest</code> with the type json and expression as below.    <pre><code>{\n  appointmentNumber: appointmentNumber,\n  doctor: appointment.doctor.toJson(),\n  patient: check hospitalRequest.patient,\n  fee: actualFee,\n  confirmed: false,\n  card_number: reservation.patient.cardNo\n }\n</code></pre> </p> </li> <li> <p>Let's add another connector action to make the payment. Click on the \u2795 sign and select paymentEP connector from the node panel. Select post from the dropdown.   </p> <p></p> </li> <li> <p>Then, fill in the required fields with the values given below and click Save.</p> Field Value Variable Name <code>status</code> Variable Type <code>ReservationStatus</code> Resource Path <code>\"/\"</code> message <code>paymentRequest</code> </li> <li> <p>Click on the \u2795 sign and select Return from the node panel. Add the <code>status</code> variable to the return node.</p> </li> <li> <p>The final integration will look like the following.   </p> <p></p> </li> </ol>"},{"location":"integration-guides/integration-as-api/service-orchestration/#step-9-run-the-service","title":"Step 9: Run the service","text":"<ol> <li>Click on the Run button to start the service.</li> <li>Start the backend service by executing the following command in a terminal.     <pre><code>docker run --name hospital-backend -p 9090:9090 -d anuruddhal/kola-hospital-backend\n</code></pre></li> <li>Click on the Run on the run button (\u25b6\ufe0f) in the top right corner to run the service.</li> <li>The service will start and the service will be available at <code>http://localhost:8290/healthcare/categories/[category]/reserve</code>.</li> <li>Click on the Try it button to open the embedded HTTP client.</li> <li>Replace the {category} with <code>surgery</code> in the resource path and enter the following JSON payload in the request body and click on the \u25b6\ufe0f button to send the request.     <pre><code>    {\n\"patient\": {\n\"name\": \"John Doe\",\n\"dob\": \"1940-03-19\",\n\"ssn\": \"234-23-525\",\n\"address\": \"California\",\n\"phone\": \"8770586755\",\n\"email\": \"johndoe@gmail.com\",\n\"cardNo\": \"7844481124110331\"\n},\n\"doctor\": \"thomas collins\",\n\"hospital_id\": \"grandoak\",\n\"hospital\": \"grand oak community hospital\",\n\"appointment_date\": \"2023-10-02\"\n}\n</code></pre></li> <li> <p>The response will be similar to the following.    <pre><code> {\n\"appointmentNo\": 1,\n\"doctorName\": \"thomas collins\",\n\"patient\": \"John Doe\",\n\"actualFee\": 7000,\n\"discount\": 20,\n\"discounted\": 5600,\n\"paymentID\": \"b219c4ad-5365-4a22-ae35-048bb8e570e7\",\n\"status\": \"settled\"\n}\n</code></pre></p> <p> </p> </li> <li> <p>You can also test the service using the curl command.    <pre><code> curl -X POST \"http://localhost:8290/healthcare/categories/surgery/reserve\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n   \"patient\": {\n     \"name\": \"John Doe\",\n     \"dob\": \"1940-03-19\",\n     \"ssn\": \"234-23-525\",\n     \"address\": \"California\",\n     \"phone\": \"8770586755\",\n     \"email\": \"johndoe@gmail.com\",\n     \"cardNo\": \"7844481124110331\"\n   },\n   \"doctor\": \"thomas collins\",\n   \"hospital_id\": \"grandoak\",\n   \"hospital\": \"grand oak community hospital\",\n   \"appointment_date\": \"2023-10-02\"\n }'\n</code></pre></p> </li> </ol>"},{"location":"integration-guides/integration-as-api/service-orchestration/#step-10-stop-the-integration","title":"Step 10: Stop the integration","text":"<ol> <li>Click on the Stop button to stop the integration or press <code>Shift</code> + <code>F5</code>.</li> <li>Stop the hospital backend server by running the following command:    <pre><code>docker stop hospital-backend\n</code></pre></li> </ol>"},{"location":"observability-and-monitoring/monitoring-with-wso2-integrator-icp/","title":"Monitoring with WSO2 Integrator: ICP","text":"<p>The WSO2 Integrator: ICP monitors the runtime artifacts in a deployment. It provides a graphical view of the integration artifacts that are deployed. In this guide, you will learn how to enable ICP for an integration developed using WSO2 Integrator: BI.</p>"},{"location":"observability-and-monitoring/monitoring-with-wso2-integrator-icp/#prerequisites","title":"Prerequisites","text":"<ol> <li>Java 11 or later versions should be installed on your machine.</li> <li>You must set your <code>JAVA_HOME</code> environment variable to point to the directory where the Java Development Kit (JDK) is installed on the computer.</li> </ol>"},{"location":"observability-and-monitoring/monitoring-with-wso2-integrator-icp/#step-1-download-and-start-icp-server","title":"Step 1: Download and start ICP server","text":"<ol> <li>Go to the WSO2 Integrator: ICP web page. </li> <li>Click Download. </li> <li>Provide the necessary details. </li> <li>Click Zip Archive to download the ICP as a ZIP file. </li> <li>Extract the archive file to a dedicated directory for the ICP, which will hereafter be referred to as <code>&lt;ICP_HOME&gt;</code>.</li> <li>Open a terminal and navigate to the <code>&lt;ICP_HOME&gt;/bin</code> folder.</li> <li>Execute one of the commands given below.</li> </ol> On MacOS/LinuxOn Windows <pre><code>./dashboard.sh\n</code></pre> <pre><code>dashboard.bat\n</code></pre>"},{"location":"observability-and-monitoring/monitoring-with-wso2-integrator-icp/#step-2-access-the-icp-dashboard","title":"Step 2: Access the ICP dashboard","text":"<ol> <li>Open a web browser and navigate to https://localhost:9743/dashboard.</li> <li> <p>Log in using the default credentials: </p> <ul> <li>Username: <code>admin</code></li> <li>Password: <code>admin</code></li> </ul> <p></p> </li> </ol>"},{"location":"observability-and-monitoring/monitoring-with-wso2-integrator-icp/#step-3-deploy-the-integration","title":"Step 3: Deploy the integration","text":"<ol> <li>Navigate to the Visualizer view by clicking on the BI icon on the sidebar.</li> <li> <p>Check Enable ICP under the Integration Control Plane section in the right panel.</p> <p></p> </li> <li> <p>Click on the Run button to start the integration. </p> </li> <li> <p>Click on the Create Config.toml on the prompt to create the <code>Config.toml</code> file.</p> <p></p> </li> <li> <p>Click on the Edit in Config.toml button in the top right corner and, update the <code>Config.toml</code> file with the following entry.</p> <p></p> <pre><code>  [ballerinax.wso2.controlplane.dashboard]\nurl = \"https://localhost:9743/dashboard/api\"\nheartbeatInterval = 10\ngroupId = \"cluster1\"\nmgtApiUrl =\"https://localhost:9264/management/\"\n</code></pre> </li> <li> <p>Click on the Run button to start the integration.  </p> <p></p> </li> <li> <p>A log message will be displayed in the console indicating that the integration is connected to the ICP dashboard.  </p> <pre><code>time=2025-03-17T15:14:59.970+05:30 level=INFO module=ballerinax/wso2.controlplane message=\"Connected to dashboard server https://localhost:9743/dashboard/api\"\n</code></pre> </li> </ol>"},{"location":"observability-and-monitoring/monitoring-with-wso2-integrator-icp/#step-4-view-the-integration-in-the-icp-dashboard","title":"Step 4: View the integration in the ICP dashboard","text":"<ol> <li>Go to the ICP dashboard and log in https://localhost:9743/dashboard.</li> <li>In the dashboard, you will see the integration details.</li> <li> <p>Click on the node to view the node details.   </p> <p></p> </li> <li> <p>Click on the Services to view the listener and resources of the service. </p> <p></p> </li> <li> <p>Click on the Listeners to view details of the listener.</p> <p></p> </li> </ol>"},{"location":"observability-and-monitoring/observability-with-devant/","title":"Observability with Devant","text":"<p>Integrations developed with WSO2 Integrator: BI can be deployed to Devant, where built-in observability tools provide deep insights into service behavior and performance. Refer to the Deploy to Devant guide for instructions on deploying to Devant. The Devant observability dashboard provides a comprehensive interface to visualize and monitor the performance of services deployed on Devant.</p> <p> </p> <p>The Observability dashboard allows you to:</p> <ul> <li>View runtime logs generated over a specific timeframe.</li> <li>Observe the throughput and latencies of requests served over a given period.</li> <li>Observe the CPU and memory usage over a given period.</li> <li>Compare metrics side-by-side to facilitate efficient diagnosis.</li> </ul>"},{"location":"observability-and-monitoring/observability-with-devant/#logs","title":"Logs","text":"<p>The Logs pane serves as a centralized view to observe logs of the integrations you deploy on Devant. This facilitates rigorous troubleshooting and analysis.</p> <p> </p>"},{"location":"observability-and-monitoring/observability-with-devant/#metrics","title":"Metrics","text":"<p>The Metrics pane provides a graphical representation of the following metrics:</p> <ul> <li>Request per minute</li> <li>Latency</li> <li>Memory usage</li> <li>CPU usage</li> <li>Data transfer</li> <li>Disk usage</li> </ul> <p> </p> <p>By default, Devant renders this graph for the data generated within the past 24 hours. You can change the default time window by selecting the time range and zone from the options bar. To expand the graph, click and drag the cursor over the period you want to drill down.</p> <p>You can view the Devant service logs in the Runtime Logs pane below the metrics. Clicking on a graph updates the Runtime Logs view to contain the corresponding log entries generated at that time. You can use these logs to identify the reasons for any anomalies you detect using the graph.</p>"},{"location":"observability-and-monitoring/overview/","title":"Overview of Observability and Monitoring","text":"<p>Observability is a measure of how well the internal states of a system can be understood from its external outputs.</p> <p>In BI, observability is a core feature that helps monitor, debug, and optimize integration services. It focuses on the following three key pillars:</p> <p>Metrics \u2013 Numeric data collected and aggregated over time to monitor system performance.</p> <p>Tracing \u2013 Tracking the flow of requests or messages through various services and components, from entry to exit.</p> <p>Logging \u2013 Text-based records of application behavior, annotated with timestamps and contextual information.</p> <p>Observability platforms allow developers and operators to gain insight into system behavior, troubleshoot issues, and ensure reliability in production deployments.</p>"},{"location":"observability-and-monitoring/overview/#observability-in-bi","title":"Observability in BI","text":"<p>BI provides built-in support for observability across its runtime. Integration services, APIs, and connectors emit rich telemetry data that can be exported to standard monitoring tools.</p>"},{"location":"observability-and-monitoring/overview/#available-observability-options","title":"Available Observability Options","text":"<p>BI supports multiple options for observing and monitoring deployed integrations. Depending on the deployment environment and the level of visibility required, you can choose from the following observability solutions.</p>"},{"location":"observability-and-monitoring/overview/#1-wso2-integrator-icp-integration-control-plane","title":"1. WSO2 Integrator: ICP (Integration Control Plane)","text":"<p>The WSO2 Integrator: ICP provides centralized monitoring and management of runtime artifacts across a deployment. It offers a graphical interface to view deployed integration artifacts and their relationships, enabling teams to,</p> <ul> <li>Track the status and availability of deployed services.</li> <li>View runtime metadata and node-level details.</li> <li>Manage and visualize the health of integration components across environments.</li> </ul> <p>This is ideal for teams that manage integrations across hybrid or distributed environments and require control-plane-level visibility. Refer to Monitoring with WSO2:Integrator ICP for further details.</p>"},{"location":"observability-and-monitoring/overview/#2-devant-by-wso2","title":"2. Devant by WSO2","text":"<p>Devant is WSO2\u2019s AI-powered Integration Platform as a Service (iPaaS). When BI integrations are deployed to Devant, the platform provides built-in observability capabilities, including the following.</p> <ul> <li>A unified dashboard for visualizing service performance and metrics.</li> <li>Insight into request flow, throughput, latency, and error rates.</li> <li>AI-powered analytics to detect anomalies and optimize system performance.</li> </ul> <p>Devant observability is suitable for cloud-native teams looking for a fully managed, intelligent monitoring experience. Refer to Observability with Devant for further details.</p>"},{"location":"observability-and-monitoring/overview/#3-integration-with-third-party-observability-tools","title":"3. Integration with Third-Party Observability Tools","text":"<p>BI is designed to work seamlessly with standard observability stacks. You can integrate your deployments with tools like,</p> <ul> <li>Prometheus and Grafana for metrics collection and visualization.</li> <li>Jaeger for distributed tracing.</li> <li>ELK for centralized logging.</li> </ul> <p>These integrations provide flexibility for teams already invested in their own observability ecosystems and allow for consistent monitoring practices across different services and platforms. Refer to Supported Observability Tools and Platforms for further details.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/datadog/","title":"Observe metrics and tracing using Datadog","text":"<p>The sample shop service will be used in this guide. Follow the steps given below to observe BI tracing and metrics in Datadog.</p> <p>Create a new account in Datadog. Select a billing plan according to your needs (A free plan is also included).</p> <p>Then follow the steps below to set up your Datadog account to view metrics and tracing provided by Ballerina.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/datadog/#step-1-create-a-datadog-account-and-an-api-key","title":"Step 1 - Create a Datadog account and  an API key","text":"<ol> <li> <p>Add Prometheus to the Integrations for your account</p> <p>You need to add Prometheus in the Integrations. Please go to the Integrations tab and search for Prometheus.</p> <p></p> </li> <li> <p>Create an API key</p> <p>You need to create an API key for the Datadog agent. To create an API key, <code>Click Profile \u2192 Organization Settings \u2192 API keys</code></p> <p></p> </li> </ol>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/datadog/#step-2-set-up-the-datadog-agent","title":"Step 2 - Set up the Datadog agent","text":"<p>After setting up your Datadog account, you need to set up a Datadog Agent in your instance.</p> <p>You can follow this documentation to get started with the Datadog agent on your local machine.</p> <p>You need to include the API key you generated in your Datadog account to <code>datadog.yaml</code> in the <code>datadog-agent/etc</code> folder.</p> <p>Then follow the steps below to configure metrics and tracing data publishing to Datadog.</p> <ol> <li> <p>Add configuration for metrics</p> <p>Once you add Prometheus by following <code>step 1</code>, you will get a guide to configure a Datadog agent in your instance.</p> <p></p> <p>You can follow the instructions given in the above configuration to set up a Datadog agent.</p> <p>A sample of the <code>conf.yaml</code> file which you should include in the prometheus.d folder can be found here.</p> <pre><code>```yaml\ninit_config:\n\ninstances:\n- prometheus_url: http://localhost:9797/metrics\n    namespace: ballerina\n    metrics:\n    - response_time_seconds_value\n    - response_time_seconds_max\n    - response_time_seconds_min \n    - response_time_seconds_mean  \n    - response_time_seconds_stdDev\n    - response_time_seconds\n    - response_time_nanoseconds_total_value\n    - requests_total_value\n    - response_errors_total_value \n    - inprogress_requests_value\n    - kafka_publishers_value\n    - kafka_consumers_value\n    - kafka_errors_value  \n    headers:\n    Accept: \"text/plain; version=0.0.4\"\n```</code></pre> </li> <li> <p>Add configuration for tracing</p> <p>You need to use the following configurations in the <code>datadog.yaml</code>.</p> <p>To view traces in Datadog, we need to enable the APM (Application Performance Monitoring) in your Datadog agent.</p> <pre><code>apm_config:\nenabled: true\n</code></pre> <p>BI uses OpenTelemetry to provide traces. Therefore, we need to set up OpenTelemetry configurations as follows.</p> <pre><code>otlp_config:\nreceiver:\nprotocols:\ngrpc:\nendpoint: 0.0.0.0:4317\n</code></pre> </li> </ol>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/datadog/#step-3-import-prometheus-and-jaeger-extensions-for-bi","title":"Step 3 - Import Prometheus and Jaeger extensions for BI","text":"<p>Create the sample shop service. To include the Prometheus and Jaeger extensions into the executable, the <code>ballerinax/prometheus</code> and <code>ballerinax/jaeger</code> modules need to be imported into your BI project. Navigate to file explorer and add the following to the <code>main.bal</code> file.</p> <pre><code>import ballerinax/prometheus as _;\nimport ballerinax/jaeger as _;\n</code></pre> <p>To support Prometheus as the metrics reporter, an HTTP endpoint starts with the context of <code>/metrics</code> in default port 9797 when starting the Ballerina service.</p> <p>Jaeger extension has an <code>Opentelemetry GRPC Span Exporter</code> which will push tracing data as batches to the endpoint (default - http://localhost:4317) in opentelemetry format.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/datadog/#step-4-configure-bi-runtime-configurations","title":"Step 4 - Configure BI runtime configurations","text":"<p>Tracing and metrics can be enabled in your BI project using configurations similar to the following.  Navigate to file explorer and add the following to the <code>Config.toml</code> file.</p> <pre><code>[ballerina.observe]\ntracingEnabled=true\ntracingProvider=\"jaeger\"\nmetricsEnabled=true\nmetricsReporter=\"prometheus\"\n\n[ballerinax.prometheus]\nport=9797\nhost=\"0.0.0.0\"\n\n[ballerinax.jaeger]\nagentHostname=\"localhost\"\nagentPort=4317\nsamplerType=\"const\"\nsamplerParam=1.0\nreporterFlushInterval=2000\nreporterBufferSize=1000\n</code></pre> <p>The table below provides the descriptions of each configuration option and possible values that can be assigned.</p> Configuration key Description Default value Possible values ballerinax.prometheus. port The value of the port to which the '/metrics' service will bind. This service will be used by Prometheus to scrape the information of the Ballerina service. <code>9797</code> Any suitable value for port 0 - 0 - 65535. However, within that range, ports 0 - 1023 are generally reserved for specific purposes, therefore it is advisable to select a port without that range. ballerinax.prometheus. host The name of the host to which the '/metrics' service will bind. This service will be used by Prometheus to scrape the information of the Ballerina service. <code>0.0.0.0</code> IP or Hostname or 0.0.0.0 of the node in which the Ballerina service is running. ballerinax.jaeger. agentHostname Hostname of the Jaeger agent localhost IP or hostname of the Jaeger agent. If it is running on the same node as Ballerina, it can be localhost. ballerinax.jaeger. agentPort Port of the Jaeger agent 4317 The port on which the Jaeger agent is listening. ballerinax.jaeger. samplerType Type of the sampling methods used in the Jaeger tracer. const <code>const</code>, <code>probabilistic</code>, or <code>ratelimiting</code>. ballerinax.jaeger. samplerParam It is a floating value. Based on the sampler type, the effect of the sampler param varies 1.0 For <code>const</code> <code>0</code> (no sampling) or <code>1</code> (sample all spans), for <code>probabilistic</code> <code>0.0</code> to <code>1.0</code>, for <code>ratelimiting</code> any positive integer (rate per second). ballerinax.jaeger. reporterFlushInterval The Jaeger client will be sending the spans to the agent at this interval. 2000 Any positive integer value. ballerinax.jaeger. reporterBufferSize Queue size of the Jaeger client. 1000 Any positive integer value."},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/datadog/#step-5-run-the-service","title":"Step 5 - Run the service","text":"<p>When observability is enabled, the BI runtime collects tracing and metrics data and will be published to Datadog.</p> <p>Start the BI service using the <code>Run</code> option in the top right corner. You will see the following logs.</p> <pre><code>Compiling source\n\nRunning executable\n\nballerina: started Prometheus HTTP listener 0.0.0.0:9797\nballerina: started publishing traces to Jaeger on localhost:4317\n</code></pre>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/datadog/#step-6-send-requests","title":"Step 6 - Send requests","text":"<p>Send requests to http://localhost:8090/shop/products.</p> <p>Example cURL commands:</p> <p><pre><code>$ curl -X GET http://localhost:8090/shop/products\n</code></pre> <pre><code>$ curl -X POST http://localhost:8090/shop/product \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"id\": 4, \n    \"name\": \"Laptop Charger\", \n    \"price\": 50.00\n}'\n</code></pre> <pre><code>$ curl -X POST http://localhost:8090/shop/order \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"productId\": 1, \n    \"quantity\": 1\n}'\n</code></pre> <pre><code>$ curl -X GET http://localhost:8090/shop/order/0\n</code></pre></p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/datadog/#step-7-view-metrics-on-datadog","title":"Step 7 - View metrics on Datadog","text":"<p>You can observe the metrics in the Datadog platform under the <code>Metrics</code> tab in the left navigation.</p> <p></p> <p>You can add filters and use functions in the Datadog to visualize what you want with the metrics provided by BI.</p> <p>Ballerina provides a dashboard in the Datadog to observe metrics in Ballerina applications.</p> <p>You can add a new dashboard in the Datadog under the Dashboards tab in the left navigation. After creating the new dashboard, go to the Configure tab in the dashboard. Import the <code>dashboard.json</code> file provided above.</p> <p></p> <p>The Ballerina Dashboard in the Datadog will be displayed as below.</p> <p></p> <p></p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/datadog/#step-8-view-tracing-on-datadog","title":"Step 8 - View tracing on Datadog","text":"<p>To view traces of the BI application, go to APM \u2192 Traces in the Datadog.</p> <p></p> <p>You can filter the traces with the service name, resource, operation name, span kind, etc.</p> <p></p> <p>Once you select a trace, you can get more information with the tags attached to the span.</p> <p></p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/elastic-stack/","title":"Observe logs using Elastic Stack","text":"<p>In BI, distributed logging and analysis are supported by the Elastic Stack. BI has a log module for logging into the console. To monitor the logs, the BI standard output needs to be redirected to a file.</p> <p>The Elastic Stack comprises the following components.</p> <ol> <li>Beats - Multiple agents that ship data to Logstash or Elasticsearch. In our context, Filebeat will ship the BI logs to Logstash. Filebeat should be a container running on the same host as the BI service. This is so that the log file (ballerina.log) can be mounted to the Filebeat container.</li> <li>Logstash - Used to process and structure the log files received from Filebeat and send them to Elasticsearch.</li> <li>Elasticsearch - Storage and indexing of the logs sent by Logstash.</li> <li>Kibana - Visualizes the data stored in Elasticsearch.</li> </ol> <p>The sample shop service will be used in this guide. Follow the steps given below to observe BI logs in Elastic Stack.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/elastic-stack/#step-1-set-up-elastic-stack","title":"Step 1 - Set up Elastic Stack","text":"<p>Elasticsearch and Kibana are provided as Cloud services. Alternatively, Docker containers can be used to set up Elasticsearch and Kibana as well.</p> <ol> <li> <p>Download the Docker images using the following commands.</p> <pre><code># Elasticsearch Image\n$ docker pull docker.elastic.co/elasticsearch/elasticsearch:8.15.2\n# Kibana Image\n$ docker pull docker.elastic.co/kibana/kibana:8.15.2\n# Filebeat Image\n$ docker pull docker.elastic.co/beats/filebeat:8.15.2\n# Logstash Image\n$ docker pull docker.elastic.co/logstash/logstash:8.15.2\n</code></pre> </li> <li> <p>Start Elasticsearch and Kibana containers by executing the following commands.</p> <pre><code>$ docker run -p 9200:9200 -p 9300:9300 -it -h elasticsearch --name elasticsearch docker.elastic.co/elasticsearch/elasticsearch:8.15.2\n$ docker run -p 5601:5601 -h kibana --name kibana --link elasticsearch:elasticsearch docker.elastic.co/kibana/kibana:8.15.2\n</code></pre> <p>If you are using Linux, you may have to increase the <code>vm.max_map_count</code> for the Elasticsearch container to start.  Execute the following command to do that.</p> <pre><code>$ sudo sysctl -w vm.max_map_count=262144\n</code></pre> </li> <li> <p>Create a <code>logstash.conf</code> file in the <code>/tmp/pipeline/</code> directory and include the following content in the file.</p> <pre><code>input {\n  beats {\n    port =&gt; 5044\n    }\n}\nfilter {\n  grok  {\n    match =&gt; { \"message\" =&gt; \"%{TIMESTAMP_ISO8601:date}%{SPACE}%{WORD:logLevel}%{SPACE}\\[%{GREEDYDATA:module}\\]%{SPACE}\\-%{SPACE}%{GREEDYDATA:logMessage}\"}\n  }\n}\noutput {\n    elasticsearch {\n        hosts =&gt; \"elasticsearch:9200\"\n        index =&gt; \"ballerina\"\n      document_type =&gt; \"ballerina_logs\"\n    }\n}\n</code></pre> <p>Here, the 3 stages are specified in the pipeline. Input is specified as beats and listens to port 5044.  A Grok filter is used to structure the Ballerina logs and the output is specified to push to Elasticsearch on <code>elasticsearch:9200</code>.</p> </li> <li> <p>Start the Logstash container by executing the following command.</p> <pre><code>$ docker run -h logstash --name logstash --link elasticsearch:elasticsearch -it --rm -v /tmp/pipeline:/usr/share/logstash/pipeline/ -p 5044:5044 docker.elastic.co/logstash/logstash:8.15.2\n</code></pre> </li> <li> <p>Configure Filebeat to ship the Ballerina logs. Create a <code>filebeat.yml</code> file in the <code>/tmp/</code> directory and include the following content in the file.</p> <pre><code>filebeat.prospectors:\n- type: log\n  paths:\n    - /usr/share/filebeat/ballerina.log\noutput.logstash:\n  hosts: [\"logstash:5044\"]\n</code></pre> </li> <li> <p>Start the Filebeat container with the following command.</p> <pre><code>$ docker run -v /tmp/filebeat.yml:/usr/share/filebeat/filebeat.yml -v /&lt;path-to-ballerina.log&gt;/ballerina.log:/usr/share/filebeat/ballerina.log --link logstash:logstash docker.elastic.co/beats/filebeat:8.15.2\n</code></pre> <p>The <code>-v</code> flag is used for bind mounting, where the container will read the file from the host machine. Provide the path to the <code>ballerina.log</code> file to be bind-mounted to the filebeat container.</p> </li> </ol>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/elastic-stack/#step-2-run-ballerina-service","title":"Step 2 - Run Ballerina Service","text":"<p>Create the sample shop service and run it using the <code>Run</code> option in BI.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/elastic-stack/#step-3-send-requests","title":"Step 3 - Send requests","text":"<p>Send requests to <code>http://localhost:8090/shop/products</code>.</p> <p>Example cURL commands:</p> <p><pre><code>$ curl -X GET http://localhost:8090/shop/products\n</code></pre> <pre><code>$ curl -X POST http://localhost:8090/shop/product \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"id\": 4, \n    \"name\": \"Laptop Charger\", \n    \"price\": 50.00\n}'\n</code></pre> <pre><code>$ curl -X POST http://localhost:8090/shop/order \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"productId\": 1, \n    \"quantity\": 1\n}'\n</code></pre> <pre><code>$ curl -X GET http://localhost:8090/shop/order/0\n</code></pre></p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/elastic-stack/#step-4-view-logs-on-kibana","title":"Step 4 - View logs on Kibana","text":"<p>Access Kibana to visualize the logs at <code>http://localhost:5601</code>. Add an index named <code>ballerina</code> and click on <code>Discover</code> to visualize the logs.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/jaeger/","title":"Observe tracing using Jaeger","text":"<p>The sample shop service will be used in this guide. Follow the steps given below to observe tracing for BI application in Jaeger.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/jaeger/#step-1-set-up-jaeger","title":"Step 1 - Set up Jaeger","text":"<p>You can configure BI project to support distributed tracing with Jaeger. This section focuses on configuring Jaeger with Docker as a quick installation.</p> Tip<p>There are many possible ways to deploy Jaeger. For more information, see Jaeger Deployment. The easiest option is to use executable binaries listed in Downloads.</p> <p>Install Jaeger via Docker and start the Docker container by executing the command below.</p> <pre><code>$ docker run -d -p 13133:13133 -p 16686:16686 -p 4317:4317 jaegertracing/opentelemetry-all-in-one\n</code></pre>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/jaeger/#step-2-import-ballerina-jaeger-extension","title":"Step 2 - Import Ballerina Jaeger extension","text":"<p>Create the sample shop service. To include the Jaeger extension into the executable, the <code>ballerinax/jaeger</code> module needs to be imported into your Ballerina project <code>main.bal</code> file.</p> <pre><code>import ballerinax/jaeger as _;\n</code></pre> <p>Jaeger extension has an <code>Opentelemetry GRPC Span Exporter</code> which will push tracing data as batches to the Jaeger server endpoint (default - http://localhost:4317) in opentelemetry format.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/jaeger/#step-3-configure-ballerina-runtime-configurations","title":"Step 3 - Configure Ballerina runtime configurations","text":"<p>Tracing can be enabled in your Ballerina project using configurations similar to the following in your <code>Config.toml</code> file.</p> <pre><code>[ballerina.observe]\ntracingEnabled=true\ntracingProvider=\"jaeger\"\n\n[ballerinax.jaeger]\nagentHostname=\"localhost\"\nagentPort=4317\nsamplerType=\"const\"\nsamplerParam=1.0\nreporterFlushInterval=2000\nreporterBufferSize=1000\n</code></pre> <p>The table below provides the descriptions of each configuration option and possible values that can be assigned.</p> Configuration key Description Default value Possible values ballerinax.jaeger. agentHostname Hostname of the Jaeger agent localhost IP or hostname of the Jaeger agent. If it is running on the same node as BI, it can be localhost. ballerinax.jaeger. agentPort Port of the Jaeger agent 4317 The port on which the Jaeger agent is listening. ballerinax.jaeger. samplerType Type of the sampling methods used in the Jaeger tracer. const <code>const</code>, <code>probabilistic</code>, or <code>ratelimiting</code>. ballerinax.jaeger. samplerParam It is a floating value. Based on the sampler type, the effect of the sampler param varies 1.0 For <code>const</code> <code>0</code> (no sampling) or <code>1</code> (sample all spans), for <code>probabilistic</code> <code>0.0</code> to <code>1.0</code>, for <code>ratelimiting</code> any positive integer (rate per second). ballerinax.jaeger. reporterFlushInterval The Jaeger client will be sending the spans to the agent at this interval. 2000 Any positive integer value. ballerinax.jaeger. reporterBufferSize Queue size of the Jaeger client. 1000 Any positive integer value."},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/jaeger/#step-4-run-the-bi-service","title":"Step 4 - Run the BI service","text":"<p>When observability is enabled, the BI runtime collects tracing data and traces will be published to Jaeger.</p> <p>Run the BI service and you will see an output as follows.</p> <pre><code>Compiling source\n\nRunning executable\n\nballerina: started publishing traces to Jaeger on localhost:4317\n</code></pre>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/jaeger/#step-5-send-requests","title":"Step 5 - Send requests","text":"<p>Send requests to http://localhost:8090/shop/products.</p> <p>Example cURL commands:</p> <p><pre><code>$ curl -X GET http://localhost:8090/shop/products\n</code></pre> <pre><code>$ curl -X POST http://localhost:8090/shop/product \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"id\": 4, \n    \"name\": \"Laptop Charger\", \n    \"price\": 50.00\n}'\n</code></pre> <pre><code>$ curl -X POST http://localhost:8090/shop/order \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"productId\": 1, \n    \"quantity\": 1\n}'\n</code></pre> <pre><code>$ curl -X GET http://localhost:8090/shop/order/0\n</code></pre></p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/jaeger/#step-6-view-distributed-tracing-on-the-jaeger-server","title":"Step 6 - View distributed tracing on the Jaeger server","text":"<p>Go to http://localhost:16686 and load the web UI of Jaeger to make sure it is functioning properly. You can select the service for which you need tracing information find traces.</p> <p>The image below is the sample tracing information you can see in Jaeger.</p> <p></p> <p></p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/moesif/","title":"Observe metrics, traces and logs using Moesif","text":"<p>The sample shop service will be used in this guide.</p> <p>Follow the steps given below to view BI metrics, traces and logs in Moesif.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/moesif/#step-1-create-a-moesif-account-and-get-an-application-id","title":"Step 1 - Create a Moesif account and get an application ID","text":"<p>After you log into Moesif Portal, get your <code>Moesif Application ID</code> during the onboarding steps. <code>Application ID</code> can be accessed by following the below steps from Moesif Portal after logging in.</p> <p>Go to Account -&gt; Settings -&gt; API keys -&gt; Collector Application ID.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/moesif/#step-2-set-up-bi-application-for-publishing-traces-and-metrics-to-moesif","title":"Step 2 - Set up BI application for publishing traces and metrics to Moesif","text":"<ul> <li>Create the sample shop service.</li> <li>Navigate to file explorer view and add the following to the <code>main.bal</code> file.</li> </ul> <pre><code>import ballerinax/moesif as _;\n</code></pre> <ul> <li>Navigate to file explorer view and create the <code>Config.toml</code> file in the package directory to set the runtime configurations as follows.</li> </ul> <pre><code>[ballerina.observe]\ntracingEnabled=true\ntracingProvider=\"moesif\"\n\n[ballerinax.moesif]\napplicationId = \"&lt;MOESIF_APPLICATION_ID&gt;\"    # Mandatory Configuration.\nreporterBaseUrl = \"https://api.moesif.net\"   # Optional Configuration. Default value is 'https://api.moesif.net'\ntracingReporterFlushInterval = 1000          # Optional Configuration. Default value is 1000\ntracingReporterBufferSize = 10000            # Optional Configuration. Default value is 10000\nisTraceLoggingEnabled = false                # Optional Configuration. Default value is false\nisPayloadLoggingEnabled = false              # Optional Configuration. Default value is false\n</code></pre> <ul> <li>To enable metrics publishing, add the following to the <code>Config.toml</code>.</li> </ul> <p><pre><code>[ballerina.observe]\nmetricsEnabled=true\nmetricsReporter=\"moesif\"\n\n[ballerinax.moesif]\napplicationId = \"&lt;MOESIF_APPLICATION_ID&gt;\"     # Mandatory Configuration.\nreporterBaseUrl = \"https://api.moesif.net\"   # Optional Configuration. Default value is 'https://api.moesif.net'\nmetricsReporterFlushInterval = 15000         # Optional Configuration. Default value is 15000\nmetricsReporterClientTimeout = 10000         # Optional Configuration. Default value is 10000\nisTraceLoggingEnabled = false                # Optional Configuration. Default value is false\nisPayloadLoggingEnabled = false              # Optional Configuration. Default value is false\n\n# Additional attributes for metrics\n[ballerinax.moesif.additionalAttributes]\nkey1 = \"value1\"\nkey2 = \"value2\"\n</code></pre> * Replace <code>&lt;MOESIF_APPLICATION_ID&gt;</code> with the application ID obtained in Step 1.</p> <p>The table below provides the descriptions of each configuration option and possible values that can be assigned.</p> Configuration key Description Default value Possible values ballerina.observe.tracingEnabled Enables or disables the collection of trace data. <code>false</code> <code>true</code> or <code>false</code> ballerina.observe.tracingProvider Specifies Moesif as the tracing provider. <code>none</code> <code>\"moesif\"</code> ballerina.observe.metricsEnabled Enables or disables the collection of metrics data. <code>false</code> <code>true</code> or <code>false</code> ballerina.observe.metricsReporter Specifies Moesif as the metrics reporter. <code>none</code> <code>\"moesif\"</code> ballerinax.moesif.applicationId Moesif application ID used for authentication. Mandatory configuration. <code>none</code> A valid Moesif application ID string ballerinax.moesif.reporterBaseUrl The base URL of the Moesif API. <code>https://api.moesif.net</code> Any valid Moesif API endpoint URL ballerinax.moesif.tracingReporterFlushInterval Interval (in milliseconds) for flushing trace data to Moesif. <code>1000</code> Any positive integer value ballerinax.moesif.tracingReporterBufferSize Maximum buffer size for trace data before sending to Moesif. <code>10000</code> Any positive integer value ballerinax.moesif.metricsReporterFlushInterval Interval (in milliseconds) for flushing metrics data to Moesif. <code>15000</code> Any positive integer value ballerinax.moesif.metricsReporterClientTimeout Timeout (in milliseconds) for the metrics reporter client requests. <code>10000</code> Any positive integer value ballerinax.moesif.isTraceLoggingEnabled Enables or disables trace logging for debugging purposes. <code>false</code> <code>true</code> or <code>false</code> ballerinax.moesif.isPayloadLoggingEnabled Enables or disables payload logging for debugging purposes. <code>false</code> <code>true</code> or <code>false</code> ballerinax.moesif.additionalAttributes Additional key-value attributes to include with metrics reporting. <code>none</code> Any valid set of key-value pairs.e.g., <code>key1=\"value1\", key2=\"value2\"</code> <p>These configurations enable traces and metrics publishing for the BI application and configure the Moesif exporter.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/moesif/#step-3-publish-bi-application-logs-to-moesif","title":"Step 3 - Publish BI application logs to Moesif","text":"<p>This setup leverages <code>Fluent Bit</code> to forward logs to an <code>OTEL Collector</code>, which then sends the logs to Moesif\u2019s log endpoint.</p> <p>BI \u2192 Fluent Bit \u2192 OTEL Collector \u2192 Moesif</p> <ul> <li>Copy the following configs into a local directory to set up containerized log publishing.</li> </ul> <pre><code>    .\n    |____ docker-compose.yaml\n    |\n    |____ fluent-bit.conf\n    |\n    |____ otelcol.yaml\n</code></pre> <p>docker-compose.yaml \u2013 Container setup for Fluent Bit and OTEL Collector.   fluent-bit.conf \u2013 Reads BI logs and forwards them.   otelcol.yaml \u2013 Processes logs and sends to Moesif.</p> <p>docker-compose.yaml</p> <p>Update the <code>&lt;ballerina-log-path&gt;</code> with the log storage location, and <code>&lt;MOESIF_APPLICATION_ID&gt;</code> with the    application ID obtained in Step 1.</p> <pre><code>services:\notelcol:\nimage: otel/opentelemetry-collector-contrib:0.132.0\ncontainer_name: moesif-otel-collector\ncommand: [\"--config\", \"/etc/otelcol.yaml\"]\nenvironment:\nMOESIF_APP_ID: \"&lt;MOESIF_APPLICATION_ID&gt;\"\nports:\n- \"4317:4317\"\n- \"4318:4318\"\nvolumes:\n- ./otelcol.yaml:/etc/otelcol.yaml:ro\nnetworks:\n- otelnet\n\nfluent-bit:\nimage: fluent/fluent-bit:3.0\ncontainer_name: fluent-bit\ndepends_on:\n- otelcol\nports:\n- \"2020:2020\"\nvolumes:\n- ./fluent-bit.conf:/fluent-bit/etc/fluent-bit.conf:ro\n# Mount the local log directory into the container\n- &lt;ballerina-log-path&gt;:/app/logs:ro\nnetworks:\n- otelnet\n\nnetworks:\notelnet:\ndriver: bridge\n</code></pre> <p>fluent-bit.conf</p> <pre><code>[SERVICE]\n    Flush         1\n    Log_Level     debug\n    Daemon        off\n    HTTP_Server   On\n    HTTP_Listen   0.0.0.0\n    HTTP_Port     2020\n\n# Read logs from local BI app\n[INPUT]\n    Name              tail\n    Path              /app/logs/app.log\n    Tag               bi.*\n    Read_from_Head    true\n    Skip_Long_Lines   On\n    Skip_Empty_Lines  On\n    Refresh_Interval  1\n\n# Add metadata\n[FILTER]\n    Name         modify\n    Match        bi.*\n    Add          service.name ballerina-service\n    Add          deployment.environment prod\n\n# Convert to OTEL format and send to collector\n[OUTPUT]\n    Name          opentelemetry\n    Match         bi.*\n    Host          otelcol\n    Port          4318\n    Logs_uri      /v1/logs\n    Log_response_payload True\n    Tls           Off\n    Tls.verify    Off\n\n# Debug output to see what's being processed\n[OUTPUT]\n    Name          stdout\n    Match         bi.*\n    Format        json_lines\n</code></pre> <p>otelcol.yaml</p> <p>Update the <code>&lt;MOESIF_APPLICATION_ID&gt;</code> with the application ID obtained in Step 1.</p> <pre><code>receivers:\notlp:\nprotocols:\ngrpc:\nendpoint: \"0.0.0.0:4317\"\nhttp:\nendpoint: \"0.0.0.0:4318\"\n\nprocessors:\nresource:\nattributes:\n- key: service.name\nvalue: ballerina-service\naction: upsert\n- key: deployment.environment\nvalue: prod\naction: upsert\n\ntransform/severity_from_message:\nlog_statements:\n- context: log\nstatements:\n# Set default severity to INFO for all logs first\n- set(severity_number, 9) where body != nil\n- set(severity_text, \"INFO\") where body != nil\n\n# Try to parse JSON body, but handle parsing errors gracefully\n- set(cache[\"is_json\"], false)\n- set(cache[\"is_json\"], true) where body != nil and IsMatch(body, \"^\\\\s*\\\\{\")\n\n# For JSON logs, parse and extract level\n- set(cache[\"parsed_body\"], ParseJSON(body)) where cache[\"is_json\"] == true\n\n# Override with specific levels based on JSON level field\n- set(severity_number, 1) where cache[\"is_json\"] == true and cache[\"parsed_body\"][\"level\"] == \"TRACE\"\n- set(severity_text, \"TRACE\") where cache[\"is_json\"] == true and cache[\"parsed_body\"][\"level\"] == \"TRACE\"\n- set(severity_number, 5) where cache[\"is_json\"] == true and cache[\"parsed_body\"][\"level\"] == \"DEBUG\"\n- set(severity_text, \"DEBUG\") where cache[\"is_json\"] == true and cache[\"parsed_body\"][\"level\"] == \"DEBUG\"\n- set(severity_number, 9) where cache[\"is_json\"] == true and cache[\"parsed_body\"][\"level\"] == \"INFO\"\n- set(severity_text, \"INFO\") where cache[\"is_json\"] == true and cache[\"parsed_body\"][\"level\"] == \"INFO\"\n- set(severity_number, 13) where cache[\"is_json\"] == true and cache[\"parsed_body\"][\"level\"] == \"WARN\"\n- set(severity_text, \"WARN\") where cache[\"is_json\"] == true and cache[\"parsed_body\"][\"level\"] == \"WARN\"\n- set(severity_number, 17) where cache[\"is_json\"] == true and cache[\"parsed_body\"][\"level\"] == \"ERROR\"\n- set(severity_text, \"ERROR\") where cache[\"is_json\"] == true and cache[\"parsed_body\"][\"level\"] == \"ERROR\"\n- set(severity_number, 21) where cache[\"is_json\"] == true and cache[\"parsed_body\"][\"level\"] == \"FATAL\"\n- set(severity_text, \"FATAL\") where cache[\"is_json\"] == true and cache[\"parsed_body\"][\"level\"] == \"FATAL\"\n\nbatch: {}\n\nexporters:\n# OTLP over HTTP to Moesif\notlphttp:\nendpoint: \"https://api.moesif.net\"\nlogs_endpoint: \"https://api.moesif.net/v1/logs\"\nheaders:\nX-Moesif-Application-Id: \"&lt;MOESIF_APPLICATION_ID&gt;\"\ncompression: none\ntimeout: 10s\nsending_queue:\nenabled: true\nnum_consumers: 2\nqueue_size: 512\nretry_on_failure:\nenabled: true\ninitial_interval: 1s\nmax_interval: 10s\nmax_elapsed_time: 0s\n\nservice:\ntelemetry:\nlogs:\nlevel: debug\npipelines:\nlogs:\nreceivers:  [otlp]\nprocessors: [resource, transform/severity_from_message, batch]\nexporters:  [otlphttp]\n</code></pre> <ul> <li> <p>Run the above components stack using the following command.    <code>docker compose up</code></p> </li> <li> <p>Navigate to file explorer view and Create the <code>Config.toml</code> file in the package directory with the following content to log to a file in <code>json</code> format.</p> </li> </ul> <pre><code>[ballerina.log]\nformat = \"json\"\n\n[[ballerina.log.destinations]]\n# Replace /path/to/your/bi/logs with the absolute path to the BI application's log directory\npath = \"/path/to/your/bi/logs/app.log\"\n</code></pre>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/moesif/#step-4-run-the-bi-project","title":"Step 4 - Run the BI project","text":"<p>When observability is enabled, the BI runtime collects metrics, logs and traces.</p> <p>Start the service in BI.</p> <pre><code>$ bal run\n\nCompiling source\n\nRunning executable\n\nballerina: started publishing traces to Moesif HTTP endpoint at https://api.moesif.net/v1/traces\nballerina: started publishing metrics to Moesif endpoint: https://api.moesif.net/v1/actions/batch with 2 additional attributes\n</code></pre>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/moesif/#step-5-send-requests","title":"Step 5 - Send requests","text":"<p>Send requests to http://localhost:8090/shop.</p> <p>Example cURL commands:</p> <p><pre><code>$ curl -X GET http://localhost:8090/shop/products\n</code></pre> <pre><code>$ curl -X POST http://localhost:8090/shop/product \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"id\": 4, \n    \"name\": \"Laptop Charger\", \n    \"price\": 50.00\n}'\n</code></pre> <pre><code>$ curl -X POST http://localhost:8090/shop/order \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"productId\": 1, \n    \"quantity\": 1\n}'\n</code></pre> <pre><code>$ curl -X GET http://localhost:8090/shop/order/0\n</code></pre></p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/moesif/#step-6-visualize-the-observability-data-in-moesif-dashboards","title":"Step 6 - Visualize the observability data in Moesif dashboards","text":"<p>Traces, metrics, and logs are published to Moesif as events and can be explored in the Live Event Log for real-time monitoring. Moesif provides a set of pre-built dashboards that help visualize and analyze this data effectively. In addition, custom dashboards can be created to gain deeper, domain-specific insights.</p> <p>The following sample dashboards illustrate how different types of observability data can be monitored and analyzed.</p> <ul> <li>Traces Dashboard</li> </ul> <p>Used to filter and view incoming requests. You can drill down into each request to track its related traces in detail.</p> <p></p> <ul> <li>Metrics Dashboard</li> </ul> <p>Provides visibility into key performance indicators such as latency, throughput, and error rates.</p> <p></p> <ul> <li>Logs Dashboard</li> </ul> <p>Displays log events captured from the application.</p> <p></p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/new-relic/","title":"Observe metrics and tracing using New Relic","text":"<p>The sample shop service will be used in this guide. Follow the steps given below to observe BI tracing and metrics in New Relic.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/new-relic/#step-1-create-a-new-relic-account-and-an-api-key","title":"Step 1 - Create a New Relic account and  an API key","text":"<p>Sign up and Generate an API Key in New Relic.</p> <p>To configure the API key in Newrelic:</p> <p>Go to Profile -&gt; API keys -&gt; Insights Insert key -&gt; Insert keys to create an account in New Relic.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/new-relic/#step-2-import-the-new-relic-extension","title":"Step 2 - Import the New Relic extension","text":"<p>Create the sample shop service. To include the New Relic extension into the executable, the <code>ballerinax/newrelic</code> module needs to be imported into your BI project. Navigate to file explorer and add the following to <code>main.bal</code> file.</p> <pre><code>import ballerinax/newrelic as _;\n</code></pre> <p>New Relic extension has an <code>Opentelemetry GRPC Span Exporter</code> which will push tracing data as batches to the New Relic server endpoint (https://otlp.nr-data.net:4317) in opentelemetry format.</p> <p>New Relic extension pushes metrics in New Relic metric format to the New Relic server endpoint (https://metric-api.newrelic.com/metric/v1).</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/new-relic/#step-3-configure-runtime-configurations-for-observability","title":"Step 3 - Configure runtime configurations for Observability","text":"<p>Tracing and metrics can be enabled in your BI project using configurations similar to the following. Navigate to file explorer and add the following to <code>Config.toml</code> file.</p> <pre><code>[ballerina.observe]\ntracingEnabled=true\ntracingProvider=\"newrelic\"\nmetricsEnabled=true\nmetricsReporter=\"newrelic\"\n\n[ballerinax.newrelic]\napiKey=\"&lt;NEW_RELIC_LICENSE_KEY&gt;\"    tracingSamplerType=\"const\"          tracingSamplerParam=1               tracingReporterFlushInterval=15000  tracingReporterBufferSize=10000     metricReporterFlushInterval=15000   metricReporterClientTimeout=10000\n</code></pre> <p>The table below provides the descriptions of each configuration option and possible values that can be assigned.</p> Configuration key Description Default value Possible values ballerinax.newrelic. apiKey API key generated by the user in the New Relic platform. This configuration is mandatory. <code>None</code> ballerinax.newrelic. tracingSamplerType Type of the sampling methods used in the New Relic tracer. const <code>const</code>, <code>probabilistic</code>, or <code>ratelimiting</code>. ballerinax.newrelic. tracingSamplerParam It is a floating value. Based on the sampler type, the effect of the sampler param varies 1.0 For <code>const</code> <code>0</code> (no sampling) or <code>1</code> (sample all spans), for <code>probabilistic</code> <code>0.0</code> to <code>1.0</code>, for <code>ratelimiting</code> any positive integer (rate per second). ballerinax.newrelic. tracingReporterFlushInterval The New Relic tracing client will be sending the spans to the agent at this interval. 15000 Any positive integer value. ballerinax.newrelic. tracingReporterBufferSize Queue size of the New Relic tracing client. 10000 Any positive integer value. ballerinax.newrelic. metricReporterFlushInterval The New Relic client will be sending the metrics to the agent at this interval. 15000 Any positive integer value. ballerinax.newrelic. metricReporterClientTimeout Queue size of the New Relic metric client. 10000 Any positive integer value."},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/new-relic/#step-4-run-the-bi-service","title":"Step 4 - Run the BI service","text":"<p>When observability is enabled, the BI runtime collects tracing and metrics data and both metrics and traces will be published to New Relic.</p> <p>Start the service.</p> <pre><code>Compiling source\n\nRunning executable\n\nballerina: started publishing traces to New Relic on https://otlp.nr-data.net:4317\nballerina: started publishing metrics to New Relic on https://metric-api.newrelic.com/metric/v1\n</code></pre>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/new-relic/#step-5-send-requests","title":"Step 5 - Send requests","text":"<p>Send requests to http://localhost:8090/shop/products.</p> <p>Example cURL commands:</p> <p><pre><code>$ curl -X GET http://localhost:8090/shop/products\n</code></pre> <pre><code>$ curl -X POST http://localhost:8090/shop/product \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"id\": 4, \n    \"name\": \"Laptop Charger\", \n    \"price\": 50.00\n}'\n</code></pre> <pre><code>$ curl -X POST http://localhost:8090/shop/order \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"productId\": 1, \n    \"quantity\": 1\n}'\n</code></pre> <pre><code>$ curl -X GET http://localhost:8090/shop/order/0\n</code></pre></p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/new-relic/#step-6-view-metrics-on-the-new-relic-platform","title":"Step 6 - View metrics on the New Relic platform","text":"<p>You can view the metrics that were published to the New Relic platform in the New Relic query builder. You can view the metrics query data in graphical format, as shown below.</p> <p></p> <p>You can create a dashboard from the metrics provided by BI in the New Relic platform.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/new-relic/#step-7-view-tracing-on-the-new-relic-platform","title":"Step 7 - View tracing on the New Relic platform","text":"<p>You can view the traces that were published to the New Relic platform in New Relic traces. </p> <p></p> <p></p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/opensearch/","title":"Observe metrics, traces, and logs using OpenSearch","text":"<p>The sample shop service will be used in this guide. Follow the steps given below to observe BI tracing, metrics, and logs in OpenSearch.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/opensearch/#step-1-set-up-opensearch-deployment","title":"Step 1 - Set up OpenSearch Deployment","text":"<ul> <li> <p>Main components:</p> <ul> <li>Sample Service: service application that is being observed.</li> <li>OpenSearch: stores and indexes logs/traces; exposes API and metrics ports.</li> <li>OpenSearch Dashboards: visualizes data from OpenSearch via web UI.</li> <li>Data Prepper: receives and processes OpenTelemetry data, sends it to OpenSearch.</li> <li>Fluent Bit: collects app logs and forwards them for indexing.</li> <li>Setup Container: automates initial setup \u2014 creates index templates and imports dashboards.</li> </ul> </li> <li> <p>Download and unzip the opensearch-observability-dashboard.zip in your local machine.</p> </li> <li> <p>The structure of the <code>opensearch-observability-dashboard</code> directory is as follows.</p> </li> </ul> <pre><code>    .\n    |____config\n    |       |____dashboards\n    |       |       |____opensearch_dashboards.yml\n    |       |____data-prepper\n    |       |     |____pipelines.yaml\n    |       |____fluent-bit\n    |       |      |____fluent-bit.conf\n    |       |      |____parser.conf\n    |       |      |____scripts\n    |       |            |____scripts.lua\n    |       |____.env\n    |\n    |____logs\n    |         |____ballerina\n    |\n    |____setup\n    |       |____opensearch-dashboards-template.ndjson\n    |       |____index-template-request.json\n    |\n    |____docker-compose.yml\n</code></pre> <ul> <li>Update OPENSEARCH_INITIAL_ADMIN_PASSWORD in the <code>path/to/opensearch-observability-dashboard/config/.env</code> file.</li> </ul> <pre><code>OPENSEARCH_INITIAL_ADMIN_PASSWORD=&lt;PASSWORD&gt; # Password for the OpenSearch admin user\n</code></pre> <p>This password will be used to access the OpenSearch server.</p> <ul> <li>Navigate to the <code>path/to/opensearch-observability-dashboard</code> directory and run the following <code>docker compose</code> command in the terminal to start the OpenSearch deployment along with the BI application.</li> </ul> <pre><code>docker compose -f docker-compose.yml up -d\n</code></pre>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/opensearch/#step-2-set-up-bi-application-for-observability","title":"Step 2 - Set up BI application for observability","text":"<ul> <li> <p>Create the sample shop service.</p> </li> <li> <p>Navigate to file explorer view and add the following to <code>main.bal</code>.</p> <pre><code>import ballerinax/metrics.logs as _;\nimport ballerinax/jaeger as _;\n</code></pre> </li> <li> <p>Navigate to file explorer view and create the <code>Config.toml</code> file in the package directory to set the runtime configurations as follows.</p> <pre><code>[ballerina.observe]\nmetricsLogsEnabled = true\ntracingEnabled = true\ntracingProvider = \"jaeger\"\n\n[ballerinax.jaeger]\nagentHostname = \"localhost\"\nagentPort = 4317\nsamplerType = \"const\"\nsamplerParam = 1.0\nreporterFlushInterval = 2000\nreporterBufferSize = 1000\n\n[ballerinax.metrics.logs]\nlogFilePath = \"&lt;PATH&gt;/&lt;TO&gt;/opensearch-observability-dashboard/logs/ballerina/&lt;SERVICE_NAME&gt;/app.log\"\n</code></pre> </li> </ul> <p>These configurations enable metrics logs and traces in the BI application and configures the Jaeger exporter.</p> <p>The table below provides the descriptions of each configuration option and possible values that can be assigned.</p> Configuration key Description Default value Possible values ballerinax.jaeger. agentHostname Hostname of the Jaeger agent localhost IP or hostname of the Jaeger agent. Can be localhost if running on same node as Ballerina. ballerinax.jaeger. agentPort Port of the Jaeger agent 4317 The port on which the Jaeger agent is listening. ballerinax.jaeger. samplerType Type of sampling methods used in Jaeger tracer const <code>const</code>, <code>probabilistic</code>, or <code>ratelimiting</code> ballerinax.jaeger. samplerParam Floating value parameter for sampler 1.0 const: <code>0</code> (no sampling) or <code>1</code> (sample all)probabilistic: <code>0.0</code> to <code>1.0</code>ratelimiting: positive integer (rate/sec) ballerinax.jaeger. reporterFlushInterval Interval for sending spans to agent 2000 Any positive integer value ballerinax.jaeger. reporterBufferSize Queue size of Jaeger client 1000 Any positive integer value ballerinax.metrics.logs. logFilePath Path to application log file <code>none</code> <code>PATH/TO/opensearch-observability-dashboard/logs/ballerina/&lt;SERVICE_NAME&gt;/app.log</code>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/opensearch/#step-3-run-the-bi-project","title":"Step 3 - Run the BI project","text":"<p>When observability is enabled, the BI runtime collects metrics logs and traces.</p> <p>Start the service in BI.</p> <pre><code>$ bal run\n\nCompiling source\n\nRunning executable\n\nballerina: started publishing traces to Jaeger on localhost:4317\n</code></pre>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/opensearch/#step-4-send-requests","title":"Step 4 - Send requests","text":"<p>Send requests to http://localhost:8090/shop/products.</p> <p>Example cURL commands:</p> <p><pre><code>$ curl -X GET http://localhost:8090/shop/products\n</code></pre> <pre><code>$ curl -X POST http://localhost:8090/shop/product \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"id\": 4, \n    \"name\": \"Laptop Charger\", \n    \"price\": 50.00\n}'\n</code></pre> <pre><code>$ curl -X POST http://localhost:8090/shop/order \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"productId\": 1, \n    \"quantity\": 1\n}'\n</code></pre> <pre><code>$ curl -X GET http://localhost:8090/shop/order/0\n</code></pre></p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/opensearch/#step-5-view-distributed-tracing-on-the-opensearch-dashboard","title":"Step 5 - View distributed tracing on the OpenSearch Dashboard","text":"<p>Open the OpenSearch Dashboard in your browser at http://localhost:5601 and navigate to the <code>Traces</code> tab within the <code>Observability</code> section.</p> <ul> <li> <p>The following image shows a sample of the tracing information available in OpenSearch.</p> <p></p> </li> <li> <p>The following image shows the span details in OpenSearch.</p> <p></p> </li> <li> <p>The service map shows the relationship between different services in the system.</p> <p></p> </li> <li> <p>The following image shows the service details.</p> <p></p> </li> </ul>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/opensearch/#step-6-view-metrics-on-opensearch-dashboard","title":"Step 6 - View metrics on OpenSearch Dashboard","text":"<p>Open the OpenSearch Dashboard in your browser at <code>http://localhost:5601</code> and navigate to the Dashboards tab under OpenSearch Dashboards section.</p> <p>Then click on the Integration metrics dashboard to view the metrics.</p> <p></p> <p></p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/opensearch/#step-7-view-logs-on-opensearch-dashboard","title":"Step 7 - View logs on OpenSearch Dashboard","text":"<p>Open the OpenSearch Dashboard in your browser at http://localhost:5601 and navigate to the Dashboards tab under OpenSearch Dashboards section.</p> <p>Then click on the Integration logs dashboard to view the integration logs.</p> <p></p> <p></p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/overview/","title":"Supported Observability Tools and Platforms","text":"<p>Observability is a measure of how well the internal states of a system can be understood from its external outputs.</p> <p>In BI, observability is a core feature that helps monitor, debug, and optimize integration services. It focuses on the following three key pillars:</p> <p>Metrics \u2013 Numeric data collected and aggregated over time to monitor system performance.</p> <p>Tracing \u2013 Tracking the flow of requests or messages through various services and components, from entry to exit.</p> <p>Logging \u2013 Text-based records of application behavior, annotated with timestamps and contextual information.</p> <p>Observability platforms allow developers and operators to gain insight into system behavior, troubleshoot issues, and ensure reliability in production deployments.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/overview/#observability-in-bi","title":"Observability in BI","text":"<p>BI provides built-in support for observability across its runtime. Integration services, APIs, and connectors emit rich telemetry data that can be exported to standard monitoring tools.</p> <p>This guide explains how to enable and configure observability in BI using a simplified integration example. This integration sample is used to demonstrate the supported observability and monitoring tools in the next sections.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/overview/#example-observing-a-sample-integration-service","title":"Example: Observing a Sample Integration Service","text":""},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/overview/#create-a-sample-service","title":"Create a sample service","text":"<p>Let\u2019s consider an example where an integration service handles product management and ordering. The goal is to observe how it behaves under real-world usage.</p> <ol> <li>Create a new integration on BI</li> <li> <p>Define types to hold the <code>Product</code>, <code>Order</code> and <code>OrderRequest</code></p> <p>You can do this by navigating to the <code>types.bal</code> from the file explorer view and copying the following content.</p> <pre><code>type Product record {|\n    int id;\n    string name;\n    float price;\n|};\n\ntype OrderRequest record {|\n    int productId;\n    int quantity;\n|};\n\ntype Order record {|\n    int orderId;\n    int productId;\n    int quantity;\n    float totalPrice;\n|};\n</code></pre> </li> <li> <p>Create an HTTP service with base path <code>/shop</code> that has the following resources.</p> <ul> <li>List available products <code>get products()</code></li> <li>Add a new product <code>post product(Product product)</code></li> <li>Place a new order <code>'order(OrderRequest orderRequest)</code></li> <li>Get order details by ID <code>'order/[int orderId]()</code></li> </ul> <p>You can add the service related logic by navigating to the <code>main.bal</code> from the file explorer view and copying the following content. </p> <pre><code>import ballerina/http;\nimport ballerina/log;\n\n// Sample data\nmap&lt;Product&gt; products = {\n    \"1\": {id: 1, name: \"Laptop\", price: 1200.00},\n    \"2\": {id: 2, name: \"Smartphone\", price: 800.00},\n    \"3\": {id: 3, name: \"Headphones\", price: 150.00}\n};\n\nmap&lt;Order&gt; orders = {};\nint orderCount = 0;\n\n@display {\n    label: \"Shopping Service\"\n}\nservice /shop on new http:Listener(8090) {\n\n    // List available products.\n    resource function get products() returns Product[] {\n        log:printInfo(\"Fetching product list\");\n        return products.toArray();\n    }\n\n    // Add a new product.\n    resource function post product(Product product) returns http:Created|http:Conflict|error? {\n        log:printInfo(\"Adding a new product\");\n\n        if products.hasKey(product.id.toString()) {\n            log:printError(\"Product already exists with product ID\", id =product.id);\n            http:Conflict errorResponse = {\n                body:  string `Product already exists with product ID: ${product.id}`\n            };\n            return errorResponse;\n        }\n\n        products[product.id.toString()] = product;\n        log:printInfo(\"Product added successfully.\", product = product);\n        http:Created response = {\n            body: string `Product added successfully with product ID: ${product.id}`\n        };\n        return response;   \n    }\n\n    // Place a new order.\n    resource function post 'order(OrderRequest orderRequest) returns http:Accepted|http:NotFound|error? {\n        log:printInfo(\"Received order request\");\n\n        if !products.hasKey(orderRequest.productId.toString()) {\n            log:printError(\"Product not found with product ID\", id = orderRequest.productId);\n            http:NotFound errorResponse = {\n                body:  string `Product not found with product ID: ${orderRequest.productId.toString()}`\n            };\n            return errorResponse;\n        }\n        Product product = products.get(orderRequest.productId.toString());\n        Order newOrder = {orderId: orderCount, productId: orderRequest.productId, quantity: orderRequest.quantity, totalPrice: product.price * orderRequest.quantity};\n        orders[orderCount.toString()] = newOrder;\n        orderCount += 1;\n\n        log:printInfo(\"Order placed successfully.\", 'order = newOrder);\n        http:Accepted response = {\n            body:  newOrder\n        };\n        return response;\n    }\n\n    // Get order details by ID.\n    resource function get 'order/[int orderId]() returns http:Ok|http:NotFound|error? {\n        log:printInfo(\"Fetching order details\");\n\n        if !orders.hasKey(orderId.toString()) {\n            log:printError(\"Order not found with order ID\", id = orderId);\n            http:NotFound errorResponse = {\n                body: string `Order not found with order ID: ${orderId}`\n            };\n            return errorResponse;\n        }\n\n        Order 'order =  orders.get(orderId.toString());\n        log:printInfo(\"Order details fetched successfully\", 'order = 'order);\n        http:Ok response = {\n            body:  'order\n        };\n        return response;\n    }\n}\n</code></pre> </li> </ol> <p></p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/overview/#enable-observability-for-the-project","title":"Enable Observability for the project","text":"<p>Observability can be enabled in a BI project by adding the following section to the <code>Ballerina.toml</code> file by navigating to the file explorer view.</p> <pre><code>[build-options]\nobservabilityIncluded=true\n</code></pre>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/overview/#setting-up-runtime-configurations-for-observability","title":"Setting up runtime configurations for Observability","text":"<p>To enable observability (both metrics and tracing) in the BI runtime, use the following configurations in the <code>Ballerina.toml</code> file.</p> <pre><code>[ballerina.observe]\nenabled = true\nprovider = &lt;PROVIDER&gt;\n</code></pre> <p>Metrics and tracing can be enabled separately as well by using the following configurations. Add additional configurations specific to the tool or platform you are using.</p> <pre><code>[ballerina.observe]\nmetricsEnabled=true\nmetricsReporter=&lt;METRICS_REPORTER&gt;\ntracingEnabled=true\ntracingProvider=&lt;TRACING_PROVIDER&gt;\n</code></pre> Configuration key Description Default value Possible values <code>ballerina.observe.metricsEnabled</code> Whether metrics monitoring is enabled (true) or disabled (false) false <code>true</code> or <code>false</code> <code>ballerina.observe.metricsReporter</code> Reporter name that reports the collected Metrics to the remote metrics server. This is only required to be modified if a custom reporter is implemented and needs to be used. <code>None</code> <code>prometheus</code>, <code>newrelic</code>, or if any custom implementation, the name of the reporter. <code>ballerina.observe.tracingEnabled</code> Whether tracing is enabled (true) or disabled (false) false <code>true</code> or <code>false</code> <code>ballerina.observe.tracingProvider</code> The tracer name, which implements the tracer interface. <code>None</code> <code>jaeger</code>, <code>zipkin</code>, <code>newrelic</code> or the name of the tracer of any custom implementation."},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/overview/#observability-tools-and-platforms-supported-by-bi","title":"Observability tools and platforms supported by BI","text":"<p>This outlines how to enable and configure observability in BI for various tools and platforms. It provides a step-by-step guide for setting up monitoring, tracing, and logging using widely used observability solutions.</p> <p>Observability tools and platforms help monitor and analyze application performance, identify issues, and ensure reliability. The following are the main observability tools and platforms supported by BI:</p> <ul> <li> <p>Prometheus: A monitoring system and time-series database for metrics collection and alerting.</p> </li> <li> <p>Jaeger: A distributed tracing platform for monitoring and debugging microservices.</p> </li> <li> <p>Zipkin: A distributed tracing system to collect and look up trace data.</p> </li> <li> <p>New Relic: A full-stack observability platform for application performance monitoring (APM) and telemetry.</p> </li> <li> <p>Datadog: A cloud-based observability service offering monitoring, metrics, traces, and logging.</p> </li> <li> <p>Elastic Stack: A collection of tools (Elasticsearch, Logstash, Kibana) for centralized logging and analytics.</p> </li> </ul> <p>The following sections contain guides to set up and observe BI programs in each of the observability tools or platforms mentioned above.</p> <ul> <li>Observe metrics using Prometheus</li> <li>Observe tracing using Jaeger</li> <li>Observe tracing using Zipkin</li> <li>Observe metrics and tracing using New Relic</li> <li>Observe metrics and tracing using Datadog</li> <li>Observe logs using Elastic Stack</li> <li>Observe metrics, traces and logs using OpenSearch</li> <li>Observe metrics, traces and logs using Moesif</li> </ul>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/prometheus/","title":"Observe metrics using Prometheus","text":"<p>The sample shop service will be used in this guide. Follow the steps given below to observe BI metrics in Prometheus.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/prometheus/#step-1-set-up-prometheus","title":"Step 1 - Set up Prometheus","text":"<p>Prometheus is used as the monitoring system, which pulls out the metrics collected from the <code>/metrics</code> service exposed by BI runtime. This section focuses on the quick installation of Prometheus with Docker and the configuration required to collect metrics from the metrics service with the default configurations. Follow the steps below to configure Prometheus. </p> Tip<p>There are many other ways to install Prometheus and you can find possible options from the installation guide. The easiest option is to use precompiled binaries listed in Downloads.</p> <ol> <li> <p>Create a <code>prometheus.yml</code> file in a directory.</p> </li> <li> <p>Add the following content to the <code>prometheus.yml</code> file.</p> <pre><code>global:\nscrape_interval:     15s\nevaluation_interval: 15s\n\nscrape_configs:\n- job_name: 'prometheus'\nstatic_configs:\n- targets: ['a.b.c.d:9797']\n</code></pre> <p>Here, the <code>'a.b.c.d:9797'</code> targets should contain the host and port of the <code>/metrics</code> service that is exposed from  BI runtime for metrics collection. Add the IP of the host in which the BI service is running as <code>a.b.c.d</code> and its port (default <code>9797</code>). If you need more information, go to the Prometheus documentation. If your BI metrics service is running on localhost and Prometheus in a Docker container, add the target as <code>host.docker.internal:9797</code> to access the localhost from Docker.</p> </li> <li> <p>Start the Prometheus server in a Docker container with the command below.</p> <pre><code>$ docker run -p 9090:9090 -v &lt;path_to_prometheus.yml&gt;:/etc/prometheus/ prom/prometheus\n</code></pre> </li> </ol>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/prometheus/#step-2-import-prometheus-extension-for-bi","title":"Step 2 - Import Prometheus extension for BI","text":"<p>Create the sample shop service. To include the Prometheus extension into the executable, the <code>ballerinax/prometheus</code> module needs to be imported into your BI project. Navigate to file explorer and add the following to the <code>main.bal</code> file.</p> <pre><code>import ballerinax/prometheus as _;\n</code></pre> <p>To support Prometheus as the metrics reporter, an HTTP endpoint starts with the context of <code>/metrics</code> in the default port <code>9797</code> when starting the service in BI.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/prometheus/#step-3-configure-runtime-configurations-for-observability","title":"Step 3 - Configure runtime configurations for observability","text":"<p>You can set up Prometheus for your BI project using configurations similar to the following in the <code>Config.toml</code> file. Navigate to file explorer and add the following to the <code>Config.toml</code> file.</p> <pre><code>[ballerina.observe]\nmetricsEnabled=true\nmetricsReporter=\"prometheus\"\n\n[ballerinax.prometheus]\nport=9797\nhost=\"0.0.0.0\"\n</code></pre> Configuration key Description Default value Possible values <code>ballerinax.prometheus.port</code> The value of the port to which the '/metrics' service will bind. This service will be used by Prometheus to scrape the information of the BI service. <code>9797</code> Any suitable value for port 0 - 0 - 65535. However, within that range, ports <code>0</code> - <code>1023</code> are generally reserved for specific purposes. Therefore, it is advisable to select a port outside that range. <code>ballerinax.prometheus.host</code> The name of the host to which the '/metrics' service will bind. This service will be used by Prometheus to scrape the information of the BI service. <code>0.0.0.0</code> IP or Hostname or <code>0.0.0.0</code> of the node in which the BI service is running."},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/prometheus/#step-4-run-the-bi-service","title":"Step 4 - Run the BI service","text":"<p>When observability is enabled, the BI runtime exposes internal metrics via an HTTP endpoint (<code>/metrics</code>) for metrics monitoring, and the metrics will be published to Prometheus. Prometheus should be configured to scrape metrics from the metrics HTTP endpoint in BI.</p> <p>Start the BI service and you'll notice an output similar to the following.</p> <pre><code>Compiling source\n\nRunning executable\n\nballerina: started Prometheus HTTP listener 0.0.0.0:9797\n</code></pre>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/prometheus/#step-5-send-requests","title":"Step 5 - Send requests","text":"<p>Send requests to <code>http://localhost:8090/shop/products</code>.</p> <p>Example cURL commands:</p> <p><pre><code>$ curl -X GET http://localhost:8090/shop/products\n</code></pre> <pre><code>$ curl -X POST http://localhost:8090/shop/product \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"id\": 4, \n    \"name\": \"Laptop Charger\", \n    \"price\": 50.00\n}'\n</code></pre> <pre><code>$ curl -X POST http://localhost:8090/shop/order \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"productId\": 1, \n    \"quantity\": 1\n}'\n</code></pre> <pre><code>$ curl -X GET http://localhost:8090/shop/order/0\n</code></pre></p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/prometheus/#step-6-view-metrics-on-the-prometheus-server","title":"Step 6 - View metrics on the Prometheus server","text":"<p>Go to http://localhost:19090/ and check whether you can see the Prometheus graph. BI metrics should appear in the Prometheus graph's metrics list when the BI service is started.</p> <p></p> <p></p> <p>You can also use the following command to get the metrics.</p> <pre><code>$ curl http://localhost:9797/metrics\n</code></pre>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/prometheus/#set-up-grafana","title":"Set up Grafana","text":"<p>Grafana can be used to visualize BI metrics provided for Prometheus. First, users need to set up the BI project to observe metrics in Prometheus and follow the steps mentioned above.</p> <p>Let\u2019s use Grafana to visualize metrics in a dashboard. For this, we need to install Grafana and configure Prometheus as a data source. Follow the steps below to configure Grafana.</p> <ol> <li> <p>Start Grafana as a Docker container with the command below.</p> <p><pre><code>$ docker run -d --name=grafana -p 3000:3000 grafana/grafana\n</code></pre> For more information, go to Grafana in Docker Hub.</p> </li> <li> <p>Go to http://localhost:3000/ to access the Grafana dashboard running on Docker.</p> </li> <li> <p>Login to the dashboard with the default user, username: <code>admin</code> and password: <code>admin</code></p> </li> <li> <p>Add Prometheus as a data source with the <code>Browser</code> access configuration as provided below.</p> </li> </ol> <p></p> <ol> <li>Import the Grafana dashboard designed to visualize BI metrics from https://grafana.com/dashboards/5841 as shown below.</li> </ol> <p></p> <p>This dashboard consists of service and client invocation level metrics in near real-time view. </p> <p>The BI HTTP service metrics dashboard panel will be as shown below.</p> <p></p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/zipkin/","title":"Observe tracing using Zipkin","text":"<p>The sample shop service will be used in this guide. Follow the steps given below to observe BI tracing in Zipkin.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/zipkin/#step-1-set-up-zipkin","title":"Step 1 - Set up Zipkin","text":"<p>You can configure BI to support distributed tracing with Zipkin. This section focuses on configuring Zipkin with Docker as a quick installation.</p> Tip<p>There are many possible ways to deploy Zipkin. For more information, see Zipkin Quickstart.</p> <p>Install Zipkin via Docker and start the Docker container by executing the command below.</p> <pre><code>$ docker run -d -p 9411:9411 openzipkin/zipkin\n</code></pre>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/zipkin/#step-2-import-ballerina-zipkin-extension","title":"Step 2 - Import Ballerina Zipkin extension","text":"<p>Create the sample shop service. To include the Zipkin extension into the executable, the <code>ballerinax/zipkin</code> module needs to be imported into your BI project by navigating to file explorer and adding the following to <code>main.bal</code> file.</p> <pre><code>import ballerinax/zipkin as _;\n</code></pre> <p>Zipkin extension has a <code>Zipkin Span Exporter</code> which will push tracing data as batches to the Zipkin server endpoint (default - http://localhost:9411) in Zipkin format.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/zipkin/#step-3-configure-runtime-configurations-for-observability","title":"Step 3 - Configure runtime configurations for observability","text":"<p>Tracing can be enabled in your BI project using configurations similar to the following in your <code>Config.toml</code> file.</p> <pre><code>[ballerina.observe]\ntracingEnabled=true\ntracingProvider=\"zipkin\"\n\n[ballerinax.zipkin]\nagentHostname=\"localhost\"\nagentPort=9411\nsamplerType=\"const\"\nsamplerParam=1.0\nreporterFlushInterval=1000\nreporterBufferSize=10000\n</code></pre> <p>The table below provides the descriptions of each configuration option and possible values that can be assigned.</p> Configuration key Description Default value Possible values ballerinax.zipkin. agentHostname Hostname of the Zipkin agent localhost IP or hostname of the Zipkin agent. If it is running on the same node as Ballerina, it can be localhost. ballerinax.zipkin. agentPort Port of the Zipkin agent 4317 The port on which the Zipkin agent is listening. ballerinax.zipkin. samplerType Type of the sampling methods used in the Zipkin tracer. const <code>const</code>, <code>probabilistic</code>, or <code>ratelimiting</code>. ballerinax.zipkin. samplerParam It is a floating value. Based on the sampler type, the effect of the sampler param varies 1.0 For <code>const</code> <code>0</code> (no sampling) or <code>1</code> (sample all spans), for <code>probabilistic</code> <code>0.0</code> to <code>1.0</code>, for <code>ratelimiting</code> any positive integer (rate per second). ballerinax.zipkin. reporterFlushInterval The Zipkin client will be sending the spans to the agent at this interval. 2000 Any positive integer value. ballerinax.zipkin. reporterBufferSize Queue size of the Zipkin client. 2000 Any positive integer value."},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/zipkin/#step-4-run-the-bi-service","title":"Step 4 - Run the BI service","text":"<p>When BI observability is enabled, the BI runtime collects tracing data and traces will be published to Zipkin.</p> <p>Run the the BI service. </p> <pre><code>Compiling source\n\nRunning executable\n\nballerina: started publishing traces to Zipkin on http://localhost:9411\n</code></pre>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/zipkin/#step-5-send-requests","title":"Step 5 - Send requests","text":"<p>Send requests to http://localhost:8090/shop/products.</p> <p>Example cURL commands:</p> <p><pre><code>$ curl -X GET http://localhost:8090/shop/products\n</code></pre> <pre><code>$ curl -X POST http://localhost:8090/shop/product \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"id\": 4, \n    \"name\": \"Laptop Charger\", \n    \"price\": 50.00\n}'\n</code></pre> <pre><code>$ curl -X POST http://localhost:8090/shop/order \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"productId\": 1, \n    \"quantity\": 1\n}'\n</code></pre> <pre><code>$ curl -X GET http://localhost:8090/shop/order/0\n</code></pre></p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/zipkin/#step-6-view-distributed-tracing-on-the-zipkin-server","title":"Step 6 - View distributed tracing on the Zipkin server","text":"<p>Go to http://localhost:9411 and load the web UI of Zipkin to make sure it is functioning properly. You can select the service for which you need tracing information find traces.</p> <p>The image below is the sample tracing information you can see in Zipkin.</p> <p></p>"},{"location":"references/ai-usage-and-data-handling-guidelines/","title":"AI Usage and Data Handling Guidelines","text":"<p>WSO2 Integrator: BI provides an AI-powered Copilot to enhance developer productivity. This page explains how the Copilot works, how user data is handled, and what best practices organizations should follow when using AI features.  </p> <p>These guidelines are designed to ensure transparency, security, and compliance when using AI-powered assistance in enterprise environments.</p>"},{"location":"references/ai-usage-and-data-handling-guidelines/#macro-architecture","title":"Macro architecture","text":"<p>The AI Copilot is integrated into the WSO2 Integrator: BI developer experience. It works as follows:</p> <p></p> <ul> <li>AI Copilot Code: Delivered as a Visual Studio Code (VS Code) extension, providing in-editor assistance such as code completion, explanations, and suggestions.  </li> <li>Language Server: Powers intelligent features inside the IDE, including syntax awareness and integration with Copilot services.  </li> <li>BI Intelligence Endpoint: A lightweight intermediary service that connects the extension to Anthropic or Bedrock models. This service does not retain data.  </li> <li>Anthropic or Bedrock Integration: The endpoint forwards user prompts and context to the selected Large Language Model (LLM) provider for processing.</li> </ul>"},{"location":"references/ai-usage-and-data-handling-guidelines/#authentication","title":"Authentication","text":"<p>To maintain security, all AI Copilot features require authentication:</p> <ul> <li>Users must log in to enable Copilot functionality.  </li> <li>Social login options are supported for ease of use.  </li> <li>Authentication and session management are handled by Asgardeo, WSO2\u2019s identity provider.  </li> </ul> <p>This ensures that only authorized users in your organization can access Copilot features.</p>"},{"location":"references/ai-usage-and-data-handling-guidelines/#data-flow","title":"Data flow","text":"<p>The movement of data through the Copilot is designed for zero-retention at the intermediary layer:</p> <p></p> <ul> <li>Direct Forwarding: BI Intelligence forwards user data directly to Anthropic for processing</li> <li>No Local Storage: BI Intelligence does not store any user data locally</li> <li>Real-time Processing: All data handling occurs in real-time without persistent storage at the BI Intelligence layer</li> </ul>"},{"location":"references/ai-usage-and-data-handling-guidelines/#bring-your-own-key-byok","title":"Bring your own key (BYOK)","text":"<p>Organizations can configure the Copilot to run using their own model provider accounts. This ensures enterprise-level control over data governance and billing.</p>"},{"location":"references/ai-usage-and-data-handling-guidelines/#anthropic-deployment","title":"Anthropic deployment","text":"<ul> <li>Copilot can connect directly to Anthropic\u2019s public deployments.  </li> <li>Requires an Anthropic API key that you provide.  </li> <li>This setup ensures that data flows directly between your environment and Anthropic without WSO2 retaining it.  </li> </ul>"},{"location":"references/ai-usage-and-data-handling-guidelines/#amazon-bedrock","title":"Amazon Bedrock","text":"<ul> <li>Copilot can also run using Claude models deployed on Amazon Bedrock.  </li> <li>Requires an active Claude deployment in your Amazon Bedrock environment.  </li> <li>Users must provide their own access keys for connectivity.</li> </ul>"},{"location":"references/ai-usage-and-data-handling-guidelines/#ballerina-copilot-code","title":"Ballerina copilot code","text":"<p>The Copilot is open source, enabling transparency and community contribution:</p> <ul> <li>The full source code is available for inspection, download, and modification.  </li> <li>This allows organizations to validate the behavior of the Copilot.  </li> <li>Enterprises can also extend the code to adapt to custom compliance needs.  </li> </ul> <p>This openness ensures that security-conscious users can audit how prompts and data are handled.</p>"},{"location":"references/ai-usage-and-data-handling-guidelines/#feedback-data","title":"Feedback data","text":"<p>To improve the Copilot experience, user feedback may be collected. </p> <p>Retention period</p> <ul> <li>Feedback data (such as thumbs up/down ratings) is retained for 1 week only.  </li> <li>After 1 week, feedback records are permanently deleted.  </li> </ul> <p>Collection scope</p> <ul> <li>Feedback is collected only when a user explicitly provides it.  </li> <li>No hidden or passive data collection is performed.  </li> </ul> <p>Transparency</p> <ul> <li>The feedback interface clearly explains what is being collected and why.  </li> <li>Users always have control over whether to provide feedback.</li> </ul>"},{"location":"references/ai-usage-and-data-handling-guidelines/#guidelines","title":"Guidelines","text":"<p>When using AI features, organizations must apply standard security and compliance practices.</p>"},{"location":"references/ai-usage-and-data-handling-guidelines/#data-usage-policies","title":"Data usage policies","text":"<ul> <li>All operations are subject to the Anthropic Data Usage Policy or the chosen model provider\u2019s terms.  </li> <li>WSO2 ensures that the Copilot does not bypass these policies.  </li> </ul>"},{"location":"references/ai-usage-and-data-handling-guidelines/#organizational-data-storage","title":"Organizational data storage","text":"<p>How long do we store your organization's data?</p> <p>We follow a zero-retention policy at the BI Intelligence level - your organizational data is not stored by our intermediate services.</p>"},{"location":"references/ai-usage-and-data-handling-guidelines/#best-practices","title":"Best practices","text":"<p>To ensure maximum security and privacy, we recommend avoiding sending organizational-specific details such as:</p> <ul> <li>Customer personal information</li> <li>Passwords or authentication credentials</li> <li>Proprietary business data</li> <li>Sensitive internal communications</li> </ul> <p>General Copilot Best Practices are as follows. </p> <ul> <li>Review all AI-generated code before implementation</li> <li>Be mindful of what information you include in prompts</li> <li>Use generic examples rather than real data when possible</li> <li>Follow your organization's data governance policies</li> </ul>"},{"location":"references/ai-usage-and-data-handling-guidelines/#data-retention-summary","title":"Data retention summary","text":"Data Type Retention Period Notes Code Prompts &amp; Responses Not stored by BI Intelligence Forwarded directly to Anthropic or Bedrock User Feedback 1 week Retained only when explicitly provided by the user Authentication Tokens Session-based Managed securely by Asgardeo Organizational Data Not stored Zero-retention policy at BI Intelligence"},{"location":"references/enterprise-integrations-patterns/","title":"Enterprise Integrations Patterns","text":"<p>The WSO2 Integrator: BI supports the implementation of key Enterprise Integration Patterns (EIPs), enabling you to build robust and scalable integrations based on proven architectural best practices. These patterns\u2014originally defined in Enterprise Integration Patterns by Gregor Hohpe and Bobby Woolf\u2014provide reusable solutions for common messaging and system integration challenges. This guide demonstrates how to implement each core pattern using the low-code capabilities and visual tools of the WSO2 Integrator: BI, helping you design clear, maintainable, and standards-based integration flows.</p> Enterprise Integration Patterns with Ballerina<p>For a code-centric implementation of Enterprise Integration Patterns using the Ballerina language, refer to the Ballerina EIP guide.</p>"},{"location":"references/enterprise-integrations-patterns/#messaging-systems","title":"Messaging systems","text":"Message How can two applications connected by a message channel exchange a piece of information Message Endpoint How an application connects to a messaging channel to send and receive messages Message Translator How systems using different data formats communicate with each other using messaging Message Router How to decouple individual processing steps so that messages can be passed to different filters depending on a set of conditions Pipes and Filters How to perform complex processing on a message while maintaining independence and flexibility"},{"location":"references/enterprise-integrations-patterns/#messaging-channels","title":"Messaging channels","text":"Channel Adapter How can two applications connected by a message channel exchange a piece of information Messaging Bridge How an application connects to a messaging channel to send and receive messages Point to Point Channel How systems using different data formats communicate with each other using messaging"},{"location":"references/enterprise-integrations-patterns/#message-construction","title":"Message construction","text":"Command Message How messaging can be used to invoke a procedure in another application Document Message How messaging can be used to transfer data between applications. Event Message How messaging can be used to transmit events from one application to another Format Indicator How a message\u2019s data format can be designed to allow for possible future changes Message Sequence How messaging can transmit an arbitrarily large amount of data"},{"location":"references/enterprise-integrations-patterns/#message-routing","title":"Message routing","text":"Content-Based Router How to handle a situation where the implementation of a single logical function is spread across multiple physical systems Aggregator How to combine the results of individual, but related messages so that they can be processed as a whole Message Filter How a component avoids receiving uninteresting messages Process Manager How to route a message through multiple processing steps, when the required steps may not be known at design time and may not be sequential Routing Slip How to route a message consecutively through a series of steps when the sequence of the steps is not known at design time and may vary for each message Splitter How to process a message if it contains multiple elements, each of which may have to be processed in a different way"},{"location":"references/enterprise-integrations-patterns/#message-transformation","title":"Message transformation","text":"Content Enricher How to communicate with another system if the message originator does not have all the required data items available Content Filter How to simplify dealing with a large message when you are interested only in a few data items Normalizer How to process messages that are semantically equivalent but arrive in a different format"},{"location":"references/enterprise-integrations-patterns/#messaging-endpoints","title":"Messaging Endpoints","text":"Idempotent Receiver How can a message receiver deal with duplicate messages"},{"location":"references/enterprise-integrations-patterns/#system-management","title":"System Management","text":"Message Store How to report against message information without disturbing the loosely coupled and transient nature of a messaging system"},{"location":"references/system-requirements/","title":"WSO2 Integrator: BI System requirements","text":"<p>Prior to installing WSO2 Integrator: BI, make sure that the appropriate prerequisites are fulfilled.</p> Minimum <p>(Suitable for smaller integrations)</p> <ul> <li>           0.2 core (compute units with at least 1.0-1.2 GHz Opteron/Xeon processor)         </li> <li>           512 MB heap size         </li> </ul> Recommended <p>(Suitable for larger integrations)</p> <ul> <li>           1 core (compute units with at least 1.0-1.2 GHz Opteron/Xeon processor)         </li> <li>           1 GB heap size         </li> </ul>"},{"location":"references/system-requirements/#environment-compatibility","title":"Environment compatibility","text":"<p>The details of the tested environments for the WSO2 Integrator: BI are given below.</p>"},{"location":"references/system-requirements/#tested-operating-systems","title":"Tested operating systems","text":"<p>The WSO2 Integrator: BI runtime is tested with the following operating systems:</p> Operating System Versions Windows 10+ Ubuntu 24.04 Red Hat Enterprise Linux 9 MacOS 14.6"},{"location":"references/system-requirements/#tested-java-runtime-environments","title":"Tested Java Runtime Environments","text":"<p>The WSO2 Integrator: BI runtime is tested with the following JREs:</p> <p>A compatible JRE version will be automatically installed during the Ballerina installation process if one is not already available in the environment.</p> JRE Versions CorrettoJRE 21 AdoptOpenJRE 21 OpenJRE 21 Oracle JRE 21"},{"location":"references/system-requirements/#arm-compatibility","title":"ARM compatibility","text":"<p>WSO2 Integrator: BI is compatible with ARM processors. It can run on ARM-based systems, such as those with Apple Silicon or ARM-based Linux distributions.</p>"}]}